{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQlvTfdkZvEO",
        "outputId": "795a034b-643b-4d58-e7be-c39aea5d8993"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.19.1)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.27.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.25.5)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.10.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.19.2)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch wandb huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeohHq1WZuJn",
        "outputId": "7611608f-7c8a-419a-aa13-adf1fd42e6e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Set HF_TOKEN from colab secrets.\n",
            "Set wandb from colab secrets.\n",
            "hf_token: True\n",
            "wandb_key: True\n",
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "##################################################\n",
        "# 1) Imports & Basic Setup\n",
        "##################################################\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Attempt to load secrets from colab\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    # 1) HF_TOKEN\n",
        "    hf_tok = userdata.get(\"HF_TOKEN\")\n",
        "    if hf_tok:\n",
        "        os.environ[\"HF_TOKEN\"] = hf_tok\n",
        "        print(\"Set HF_TOKEN from colab secrets.\")\n",
        "    # 2) W&B\n",
        "    wandb_key = userdata.get(\"wandb\")\n",
        "    if wandb_key:\n",
        "        os.environ[\"wandb\"] = wandb_key\n",
        "        print(\"Set wandb from colab secrets.\")\n",
        "except:\n",
        "    pass\n",
        "\n",
        "hf_token  = os.environ.get(\"HF_TOKEN\", None)\n",
        "wandb_key = os.environ.get(\"wandb\", None)\n",
        "print(\"hf_token:\", bool(hf_token))\n",
        "print(\"wandb_key:\", bool(wandb_key))\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "##################################################\n",
        "# 2) Larger MLP (~9.6k params)\n",
        "##################################################\n",
        "class LargeMLP(nn.Module):\n",
        "    \"\"\"\n",
        "    We'll downsample MNIST to 16x16 => input dim=256\n",
        "    Then 2 hidden layers of 32 each => total ~9.6k parameters.\n",
        "\n",
        "    Calculation:\n",
        "      fc1: (256 * 32) + 32 = 8192 + 32 = 8224\n",
        "      fc2: (32 * 32) + 32  = 1024 + 32 = 1056\n",
        "      fc3: (32 * 10) + 10  = 320 + 10 = 330\n",
        "      total => 8224 + 1056 + 330 = 9610\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(256, 32)\n",
        "        self.fc2 = nn.Linear(32, 32)\n",
        "        self.fc3 = nn.Linear(32, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: [B,1,16,16]\n",
        "        x = x.view(x.size(0), -1)  # => [B,256]\n",
        "        x = torch.relu(self.fc1(x)) # => [B,32]\n",
        "        x = torch.relu(self.fc2(x)) # => [B,32]\n",
        "        x = self.fc3(x)             # => [B,10]\n",
        "        return x\n",
        "\n",
        "##################################################\n",
        "# 3) Naive Newton Optimizer\n",
        "##################################################\n",
        "class NaiveNewtonOptimizer(torch.optim.Optimizer):\n",
        "    \"\"\"\n",
        "    Dense Hessian => O(N^3). Must call step(closure).\n",
        "    Great for demonstration with small networks only.\n",
        "    \"\"\"\n",
        "    def __init__(self, params, lr=1.0, tol=1e-6):\n",
        "        defaults = dict(lr=lr, tol=tol)\n",
        "        super().__init__(params, defaults)\n",
        "\n",
        "    def step(self, closure=None):\n",
        "        if closure is None:\n",
        "            raise RuntimeError(\"NaiveNewtonOptimizer needs a closure returning the loss (tensor).\")\n",
        "\n",
        "        loss = closure()\n",
        "        loss.backward(create_graph=True)\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            lr = group['lr']\n",
        "            tol = group['tol']\n",
        "\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                grad = p.grad.view(-1)\n",
        "                if grad.norm() < tol:\n",
        "                    continue\n",
        "\n",
        "                n = grad.numel()\n",
        "                # Build Hessian\n",
        "                H = []\n",
        "                for i in range(n):\n",
        "                    g_i = grad[i]\n",
        "                    p.grad = None\n",
        "                    g_i.backward(retain_graph=True)\n",
        "                    H_i = p.grad.view(-1).clone()\n",
        "                    H.append(H_i)\n",
        "                    p.grad = None\n",
        "                H = torch.stack(H, dim=1)  # => [n, n]\n",
        "\n",
        "                # Solve H dx = grad\n",
        "                try:\n",
        "                    dx, _ = torch.solve(grad.unsqueeze(1), H)\n",
        "                    dx = dx.squeeze(1)\n",
        "                except RuntimeError:\n",
        "                    dx = grad  # fallback\n",
        "\n",
        "                # Safely do in-place update using .data\n",
        "                p.data.sub_((lr * dx).view(p.shape))\n",
        "\n",
        "        return loss\n",
        "\n",
        "##################################################\n",
        "# 3) Naive Gradient Descent Optimizer\n",
        "##################################################\n",
        "class NaiveGradientDescent(torch.optim.Optimizer):\n",
        "    \"\"\"\n",
        "    A pure \"vanilla\" Gradient Descent:\n",
        "    p <- p - lr * grad(p)\n",
        "\n",
        "    Must call step(closure) where the closure:\n",
        "      - zeroes grads\n",
        "      - does forward pass\n",
        "      - returns the loss (tensor)\n",
        "    Then we do normal .backward() for the first derivative only.\n",
        "    \"\"\"\n",
        "    def __init__(self, params, lr=0.01):\n",
        "        defaults = dict(lr=lr)\n",
        "        super().__init__(params, defaults)\n",
        "\n",
        "    def step(self, closure=None):\n",
        "        if closure is None:\n",
        "            raise RuntimeError(\"NaiveGradientDescent needs a closure returning the loss (tensor).\")\n",
        "\n",
        "        # 1) Recompute the forward pass\n",
        "        loss = closure()\n",
        "        # 2) Normal backward => first derivatives\n",
        "        loss.backward()\n",
        "\n",
        "        # 3) Update\n",
        "        for group in self.param_groups:\n",
        "            lr = group['lr']\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                p.data.sub_(lr * p.grad)\n",
        "\n",
        "        return loss\n",
        "\n",
        "\n",
        "##################################################\n",
        "# 4) DataLoaders with downsampling to 16x16\n",
        "##################################################\n",
        "def get_mnist_loaders(batch_size=64):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((16,16)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))\n",
        "    ])\n",
        "    train_ds = datasets.MNIST(root=\".\", train=True, download=True, transform=transform)\n",
        "    test_ds  = datasets.MNIST(root=\".\", train=False, download=True, transform=transform)\n",
        "    train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "    test_loader  = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n",
        "    return train_loader, test_loader\n",
        "\n",
        "##################################################\n",
        "# 5) Train function\n",
        "##################################################\n",
        "def train_model(\n",
        "    optimizer_name: str = \"\",\n",
        "    learning_rate: float = 1e-2,\n",
        "    epochs: int = 2,\n",
        "    batch_size: int = 64,\n",
        "    wandb_project: str = \"\"\n",
        "):\n",
        "    \"\"\"\n",
        "    We'll:\n",
        "      - Create ~9.6k param MLP (16x16 input => 2 hidden layers of 32)\n",
        "      - Use \"gd\", \"newton\", or \"sgd\"\n",
        "      - Possibly log each step to wandb\n",
        "    \"\"\"\n",
        "    model = LargeMLP().to(device)\n",
        "    train_loader, test_loader = get_mnist_loaders(batch_size)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # W&B\n",
        "    wandb_key = os.environ.get(\"wandb\", None)\n",
        "    do_wandb = (wandb_project != \"\") and (wandb_key is not None)\n",
        "    if do_wandb:\n",
        "        import wandb\n",
        "        wandb.login(key=wandb_key)\n",
        "        wandb.init(project=wandb_project, config={\n",
        "            \"optimizer_name\": optimizer_name,\n",
        "            \"learning_rate\": learning_rate,\n",
        "            \"epochs\": epochs,\n",
        "            \"batch_size\": batch_size\n",
        "        })\n",
        "\n",
        "    # pick optimizer\n",
        "    if optimizer_name.lower() == \"gd\":\n",
        "        opt = NaiveGradientDescent(model.parameters(), lr=learning_rate)\n",
        "    elif optimizer_name.lower() == \"newton\":\n",
        "        opt = NaiveNewtonOptimizer(model.parameters(), lr=learning_rate)\n",
        "    elif optimizer_name.lower() == \"sgd\":\n",
        "        opt = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown optimizer {optimizer_name}\")\n",
        "\n",
        "    global_step = 0\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "\n",
        "        for batch_idx, (data, targets) in enumerate(train_loader):\n",
        "            data, targets = data.to(device), targets.to(device)\n",
        "\n",
        "            def closure():\n",
        "                # We do zero_grad INSIDE closure for both newton & naive GD\n",
        "                opt.zero_grad()\n",
        "                outputs = model(data)\n",
        "                loss_t = criterion(outputs, targets)\n",
        "                return loss_t\n",
        "\n",
        "            # FIX => always use step(closure=closure)\n",
        "            # so that naive GD also gets the closure\n",
        "            loss_tensor = opt.step(closure=closure)\n",
        "            loss_val = loss_tensor.item()\n",
        "\n",
        "            total_loss += loss_val\n",
        "            global_step += 1\n",
        "\n",
        "            # Print every training step\n",
        "            print(f\"Epoch[{epoch}/{epochs}] Step[{global_step}] Loss={loss_val:.4f}\")\n",
        "\n",
        "            if do_wandb:\n",
        "                import wandb\n",
        "                wandb.log({\"train_loss\": loss_val}, step=global_step)\n",
        "\n",
        "        # Evaluate\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        test_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for data, targets in test_loader:\n",
        "                data, targets = data.to(device), targets.to(device)\n",
        "                out = model(data)\n",
        "                l = criterion(out, targets)\n",
        "                test_loss += l.item() * data.size(0)\n",
        "                _, pred = out.max(1)\n",
        "                correct += pred.eq(targets).sum().item()\n",
        "        test_loss /= len(test_loader.dataset)\n",
        "        accuracy = 100.*correct / len(test_loader.dataset)\n",
        "        epoch_loss = total_loss / len(train_loader)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} => TrainLoss={epoch_loss:.4f} TestLoss={test_loss:.4f} Acc={accuracy:.2f}%\")\n",
        "\n",
        "        if do_wandb:\n",
        "            wandb.log({\n",
        "                \"epoch\": epoch,\n",
        "                \"train_loss_epoch\": epoch_loss,\n",
        "                \"test_loss\": test_loss,\n",
        "                \"test_accuracy\": accuracy\n",
        "            }, step=global_step)\n",
        "\n",
        "    if do_wandb:\n",
        "        import wandb\n",
        "        wandb.finish()\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "QBCCYTXFlrkV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b78cb002-ace2-4f0e-c49a-11ced16cb160"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HF token: True\n",
            "W&B key: True\n",
            "Using gd with ~9.6k param model. LR=0.01, epochs=2, batch_size=16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250115_132045-7s6krwl6</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/marlborough-college-malaysia/AAH-IA__gradient-descent__/runs/7s6krwl6' target=\"_blank\">lucky-river-6</a></strong> to <a href='https://wandb.ai/marlborough-college-malaysia/AAH-IA__gradient-descent__' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/marlborough-college-malaysia/AAH-IA__gradient-descent__' target=\"_blank\">https://wandb.ai/marlborough-college-malaysia/AAH-IA__gradient-descent__</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/marlborough-college-malaysia/AAH-IA__gradient-descent__/runs/7s6krwl6' target=\"_blank\">https://wandb.ai/marlborough-college-malaysia/AAH-IA__gradient-descent__/runs/7s6krwl6</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch[0/2] Step[2503] Loss=0.7506\n",
            "Epoch[0/2] Step[2504] Loss=0.8466\n",
            "Epoch[0/2] Step[2505] Loss=0.4546\n",
            "Epoch[0/2] Step[2506] Loss=0.2943\n",
            "Epoch[0/2] Step[2507] Loss=0.6110\n",
            "Epoch[0/2] Step[2508] Loss=0.4485\n",
            "Epoch[0/2] Step[2509] Loss=0.2769\n",
            "Epoch[0/2] Step[2510] Loss=0.6344\n",
            "Epoch[0/2] Step[2511] Loss=0.2812\n",
            "Epoch[0/2] Step[2512] Loss=0.5307\n",
            "Epoch[0/2] Step[2513] Loss=0.1942\n",
            "Epoch[0/2] Step[2514] Loss=0.8236\n",
            "Epoch[0/2] Step[2515] Loss=0.4240\n",
            "Epoch[0/2] Step[2516] Loss=0.5177\n",
            "Epoch[0/2] Step[2517] Loss=0.4554\n",
            "Epoch[0/2] Step[2518] Loss=0.2865\n",
            "Epoch[0/2] Step[2519] Loss=0.4628\n",
            "Epoch[0/2] Step[2520] Loss=0.4715\n",
            "Epoch[0/2] Step[2521] Loss=0.2599\n",
            "Epoch[0/2] Step[2522] Loss=0.2047\n",
            "Epoch[0/2] Step[2523] Loss=0.5134\n",
            "Epoch[0/2] Step[2524] Loss=0.6395\n",
            "Epoch[0/2] Step[2525] Loss=0.3021\n",
            "Epoch[0/2] Step[2526] Loss=0.3673\n",
            "Epoch[0/2] Step[2527] Loss=0.2934\n",
            "Epoch[0/2] Step[2528] Loss=0.1952\n",
            "Epoch[0/2] Step[2529] Loss=0.9152\n",
            "Epoch[0/2] Step[2530] Loss=0.3189\n",
            "Epoch[0/2] Step[2531] Loss=0.1727\n",
            "Epoch[0/2] Step[2532] Loss=0.3190\n",
            "Epoch[0/2] Step[2533] Loss=0.1852\n",
            "Epoch[0/2] Step[2534] Loss=0.7396\n",
            "Epoch[0/2] Step[2535] Loss=0.3076\n",
            "Epoch[0/2] Step[2536] Loss=0.2819\n",
            "Epoch[0/2] Step[2537] Loss=0.2656\n",
            "Epoch[0/2] Step[2538] Loss=0.4473\n",
            "Epoch[0/2] Step[2539] Loss=0.1338\n",
            "Epoch[0/2] Step[2540] Loss=0.3141\n",
            "Epoch[0/2] Step[2541] Loss=0.1859\n",
            "Epoch[0/2] Step[2542] Loss=0.3510\n",
            "Epoch[0/2] Step[2543] Loss=0.1647\n",
            "Epoch[0/2] Step[2544] Loss=0.4376\n",
            "Epoch[0/2] Step[2545] Loss=0.6356\n",
            "Epoch[0/2] Step[2546] Loss=0.1767\n",
            "Epoch[0/2] Step[2547] Loss=0.2410\n",
            "Epoch[0/2] Step[2548] Loss=0.8335\n",
            "Epoch[0/2] Step[2549] Loss=0.2808\n",
            "Epoch[0/2] Step[2550] Loss=0.2402\n",
            "Epoch[0/2] Step[2551] Loss=0.4519\n",
            "Epoch[0/2] Step[2552] Loss=0.5819\n",
            "Epoch[0/2] Step[2553] Loss=0.3313\n",
            "Epoch[0/2] Step[2554] Loss=0.2813\n",
            "Epoch[0/2] Step[2555] Loss=0.3251\n",
            "Epoch[0/2] Step[2556] Loss=0.4993\n",
            "Epoch[0/2] Step[2557] Loss=0.5821\n",
            "Epoch[0/2] Step[2558] Loss=0.6069\n",
            "Epoch[0/2] Step[2559] Loss=0.2976\n",
            "Epoch[0/2] Step[2560] Loss=0.4450\n",
            "Epoch[0/2] Step[2561] Loss=0.2799\n",
            "Epoch[0/2] Step[2562] Loss=0.1565\n",
            "Epoch[0/2] Step[2563] Loss=0.3358\n",
            "Epoch[0/2] Step[2564] Loss=0.1871\n",
            "Epoch[0/2] Step[2565] Loss=0.5403\n",
            "Epoch[0/2] Step[2566] Loss=0.5441\n",
            "Epoch[0/2] Step[2567] Loss=0.5747\n",
            "Epoch[0/2] Step[2568] Loss=0.2176\n",
            "Epoch[0/2] Step[2569] Loss=1.0436\n",
            "Epoch[0/2] Step[2570] Loss=0.4164\n",
            "Epoch[0/2] Step[2571] Loss=0.7578\n",
            "Epoch[0/2] Step[2572] Loss=0.5130\n",
            "Epoch[0/2] Step[2573] Loss=0.5434\n",
            "Epoch[0/2] Step[2574] Loss=0.3273\n",
            "Epoch[0/2] Step[2575] Loss=0.2167\n",
            "Epoch[0/2] Step[2576] Loss=0.3130\n",
            "Epoch[0/2] Step[2577] Loss=0.2999\n",
            "Epoch[0/2] Step[2578] Loss=0.3871\n",
            "Epoch[0/2] Step[2579] Loss=0.9730\n",
            "Epoch[0/2] Step[2580] Loss=0.7336\n",
            "Epoch[0/2] Step[2581] Loss=0.5341\n",
            "Epoch[0/2] Step[2582] Loss=0.3672\n",
            "Epoch[0/2] Step[2583] Loss=0.4162\n",
            "Epoch[0/2] Step[2584] Loss=0.1807\n",
            "Epoch[0/2] Step[2585] Loss=0.4014\n",
            "Epoch[0/2] Step[2586] Loss=0.2134\n",
            "Epoch[0/2] Step[2587] Loss=0.4565\n",
            "Epoch[0/2] Step[2588] Loss=0.1681\n",
            "Epoch[0/2] Step[2589] Loss=0.2338\n",
            "Epoch[0/2] Step[2590] Loss=0.4020\n",
            "Epoch[0/2] Step[2591] Loss=0.7571\n",
            "Epoch[0/2] Step[2592] Loss=0.2028\n",
            "Epoch[0/2] Step[2593] Loss=0.2020\n",
            "Epoch[0/2] Step[2594] Loss=0.4101\n",
            "Epoch[0/2] Step[2595] Loss=0.2018\n",
            "Epoch[0/2] Step[2596] Loss=0.5578\n",
            "Epoch[0/2] Step[2597] Loss=0.3321\n",
            "Epoch[0/2] Step[2598] Loss=0.2847\n",
            "Epoch[0/2] Step[2599] Loss=0.6354\n",
            "Epoch[0/2] Step[2600] Loss=0.6765\n",
            "Epoch[0/2] Step[2601] Loss=0.2532\n",
            "Epoch[0/2] Step[2602] Loss=0.1955\n",
            "Epoch[0/2] Step[2603] Loss=0.1479\n",
            "Epoch[0/2] Step[2604] Loss=0.5645\n",
            "Epoch[0/2] Step[2605] Loss=0.3568\n",
            "Epoch[0/2] Step[2606] Loss=0.2327\n",
            "Epoch[0/2] Step[2607] Loss=0.2295\n",
            "Epoch[0/2] Step[2608] Loss=0.2464\n",
            "Epoch[0/2] Step[2609] Loss=0.4679\n",
            "Epoch[0/2] Step[2610] Loss=0.6091\n",
            "Epoch[0/2] Step[2611] Loss=0.6975\n",
            "Epoch[0/2] Step[2612] Loss=0.3325\n",
            "Epoch[0/2] Step[2613] Loss=0.1263\n",
            "Epoch[0/2] Step[2614] Loss=0.4808\n",
            "Epoch[0/2] Step[2615] Loss=0.1486\n",
            "Epoch[0/2] Step[2616] Loss=0.0751\n",
            "Epoch[0/2] Step[2617] Loss=0.5675\n",
            "Epoch[0/2] Step[2618] Loss=0.2203\n",
            "Epoch[0/2] Step[2619] Loss=0.8290\n",
            "Epoch[0/2] Step[2620] Loss=0.7332\n",
            "Epoch[0/2] Step[2621] Loss=0.2110\n",
            "Epoch[0/2] Step[2622] Loss=0.3570\n",
            "Epoch[0/2] Step[2623] Loss=0.4145\n",
            "Epoch[0/2] Step[2624] Loss=0.9530\n",
            "Epoch[0/2] Step[2625] Loss=0.7402\n",
            "Epoch[0/2] Step[2626] Loss=0.3073\n",
            "Epoch[0/2] Step[2627] Loss=0.7342\n",
            "Epoch[0/2] Step[2628] Loss=0.1195\n",
            "Epoch[0/2] Step[2629] Loss=0.5194\n",
            "Epoch[0/2] Step[2630] Loss=1.1097\n",
            "Epoch[0/2] Step[2631] Loss=0.4847\n",
            "Epoch[0/2] Step[2632] Loss=0.7821\n",
            "Epoch[0/2] Step[2633] Loss=0.4404\n",
            "Epoch[0/2] Step[2634] Loss=0.6366\n",
            "Epoch[0/2] Step[2635] Loss=0.3230\n",
            "Epoch[0/2] Step[2636] Loss=0.2190\n",
            "Epoch[0/2] Step[2637] Loss=0.3100\n",
            "Epoch[0/2] Step[2638] Loss=0.1486\n",
            "Epoch[0/2] Step[2639] Loss=0.4083\n",
            "Epoch[0/2] Step[2640] Loss=0.1276\n",
            "Epoch[0/2] Step[2641] Loss=0.2146\n",
            "Epoch[0/2] Step[2642] Loss=0.5545\n",
            "Epoch[0/2] Step[2643] Loss=0.7872\n",
            "Epoch[0/2] Step[2644] Loss=0.1897\n",
            "Epoch[0/2] Step[2645] Loss=0.4158\n",
            "Epoch[0/2] Step[2646] Loss=0.4944\n",
            "Epoch[0/2] Step[2647] Loss=0.9172\n",
            "Epoch[0/2] Step[2648] Loss=0.5746\n",
            "Epoch[0/2] Step[2649] Loss=0.4214\n",
            "Epoch[0/2] Step[2650] Loss=0.3874\n",
            "Epoch[0/2] Step[2651] Loss=0.4807\n",
            "Epoch[0/2] Step[2652] Loss=0.3024\n",
            "Epoch[0/2] Step[2653] Loss=0.6433\n",
            "Epoch[0/2] Step[2654] Loss=0.3383\n",
            "Epoch[0/2] Step[2655] Loss=0.3641\n",
            "Epoch[0/2] Step[2656] Loss=0.6326\n",
            "Epoch[0/2] Step[2657] Loss=0.3687\n",
            "Epoch[0/2] Step[2658] Loss=0.2160\n",
            "Epoch[0/2] Step[2659] Loss=0.5374\n",
            "Epoch[0/2] Step[2660] Loss=0.4610\n",
            "Epoch[0/2] Step[2661] Loss=0.2930\n",
            "Epoch[0/2] Step[2662] Loss=0.4139\n",
            "Epoch[0/2] Step[2663] Loss=0.2038\n",
            "Epoch[0/2] Step[2664] Loss=0.5560\n",
            "Epoch[0/2] Step[2665] Loss=0.4680\n",
            "Epoch[0/2] Step[2666] Loss=0.5566\n",
            "Epoch[0/2] Step[2667] Loss=0.6834\n",
            "Epoch[0/2] Step[2668] Loss=0.2421\n",
            "Epoch[0/2] Step[2669] Loss=0.2838\n",
            "Epoch[0/2] Step[2670] Loss=0.2489\n",
            "Epoch[0/2] Step[2671] Loss=0.4946\n",
            "Epoch[0/2] Step[2672] Loss=0.7984\n",
            "Epoch[0/2] Step[2673] Loss=0.4246\n",
            "Epoch[0/2] Step[2674] Loss=0.1912\n",
            "Epoch[0/2] Step[2675] Loss=0.5218\n",
            "Epoch[0/2] Step[2676] Loss=0.4042\n",
            "Epoch[0/2] Step[2677] Loss=0.3074\n",
            "Epoch[0/2] Step[2678] Loss=0.1955\n",
            "Epoch[0/2] Step[2679] Loss=0.3679\n",
            "Epoch[0/2] Step[2680] Loss=0.4958\n",
            "Epoch[0/2] Step[2681] Loss=0.2759\n",
            "Epoch[0/2] Step[2682] Loss=0.4317\n",
            "Epoch[0/2] Step[2683] Loss=0.7058\n",
            "Epoch[0/2] Step[2684] Loss=0.1985\n",
            "Epoch[0/2] Step[2685] Loss=0.3306\n",
            "Epoch[0/2] Step[2686] Loss=0.1328\n",
            "Epoch[0/2] Step[2687] Loss=0.4214\n",
            "Epoch[0/2] Step[2688] Loss=0.2842\n",
            "Epoch[0/2] Step[2689] Loss=0.7257\n",
            "Epoch[0/2] Step[2690] Loss=0.4240\n",
            "Epoch[0/2] Step[2691] Loss=0.3666\n",
            "Epoch[0/2] Step[2692] Loss=0.3316\n",
            "Epoch[0/2] Step[2693] Loss=0.2727\n",
            "Epoch[0/2] Step[2694] Loss=0.2095\n",
            "Epoch[0/2] Step[2695] Loss=0.7989\n",
            "Epoch[0/2] Step[2696] Loss=0.1182\n",
            "Epoch[0/2] Step[2697] Loss=0.2706\n",
            "Epoch[0/2] Step[2698] Loss=0.3871\n",
            "Epoch[0/2] Step[2699] Loss=0.1423\n",
            "Epoch[0/2] Step[2700] Loss=0.2217\n",
            "Epoch[0/2] Step[2701] Loss=0.0886\n",
            "Epoch[0/2] Step[2702] Loss=0.2603\n",
            "Epoch[0/2] Step[2703] Loss=0.1624\n",
            "Epoch[0/2] Step[2704] Loss=0.2786\n",
            "Epoch[0/2] Step[2705] Loss=0.4863\n",
            "Epoch[0/2] Step[2706] Loss=0.2411\n",
            "Epoch[0/2] Step[2707] Loss=0.1347\n",
            "Epoch[0/2] Step[2708] Loss=0.2127\n",
            "Epoch[0/2] Step[2709] Loss=0.1248\n",
            "Epoch[0/2] Step[2710] Loss=0.6233\n",
            "Epoch[0/2] Step[2711] Loss=0.1760\n",
            "Epoch[0/2] Step[2712] Loss=0.5271\n",
            "Epoch[0/2] Step[2713] Loss=0.2700\n",
            "Epoch[0/2] Step[2714] Loss=0.3790\n",
            "Epoch[0/2] Step[2715] Loss=0.5298\n",
            "Epoch[0/2] Step[2716] Loss=0.4175\n",
            "Epoch[0/2] Step[2717] Loss=0.5747\n",
            "Epoch[0/2] Step[2718] Loss=0.6873\n",
            "Epoch[0/2] Step[2719] Loss=0.2148\n",
            "Epoch[0/2] Step[2720] Loss=0.2282\n",
            "Epoch[0/2] Step[2721] Loss=0.1989\n",
            "Epoch[0/2] Step[2722] Loss=0.4008\n",
            "Epoch[0/2] Step[2723] Loss=0.5133\n",
            "Epoch[0/2] Step[2724] Loss=0.3098\n",
            "Epoch[0/2] Step[2725] Loss=0.7236\n",
            "Epoch[0/2] Step[2726] Loss=0.1870\n",
            "Epoch[0/2] Step[2727] Loss=0.7502\n",
            "Epoch[0/2] Step[2728] Loss=0.4105\n",
            "Epoch[0/2] Step[2729] Loss=0.2415\n",
            "Epoch[0/2] Step[2730] Loss=0.7543\n",
            "Epoch[0/2] Step[2731] Loss=0.2882\n",
            "Epoch[0/2] Step[2732] Loss=0.1363\n",
            "Epoch[0/2] Step[2733] Loss=0.3710\n",
            "Epoch[0/2] Step[2734] Loss=0.2772\n",
            "Epoch[0/2] Step[2735] Loss=0.3194\n",
            "Epoch[0/2] Step[2736] Loss=0.3600\n",
            "Epoch[0/2] Step[2737] Loss=0.5996\n",
            "Epoch[0/2] Step[2738] Loss=0.4370\n",
            "Epoch[0/2] Step[2739] Loss=0.1392\n",
            "Epoch[0/2] Step[2740] Loss=0.1961\n",
            "Epoch[0/2] Step[2741] Loss=0.3387\n",
            "Epoch[0/2] Step[2742] Loss=0.3995\n",
            "Epoch[0/2] Step[2743] Loss=0.2981\n",
            "Epoch[0/2] Step[2744] Loss=0.5998\n",
            "Epoch[0/2] Step[2745] Loss=0.6227\n",
            "Epoch[0/2] Step[2746] Loss=0.1905\n",
            "Epoch[0/2] Step[2747] Loss=0.3833\n",
            "Epoch[0/2] Step[2748] Loss=0.7023\n",
            "Epoch[0/2] Step[2749] Loss=0.6254\n",
            "Epoch[0/2] Step[2750] Loss=0.6116\n",
            "Epoch[0/2] Step[2751] Loss=0.3335\n",
            "Epoch[0/2] Step[2752] Loss=0.1466\n",
            "Epoch[0/2] Step[2753] Loss=0.4852\n",
            "Epoch[0/2] Step[2754] Loss=0.3138\n",
            "Epoch[0/2] Step[2755] Loss=0.5484\n",
            "Epoch[0/2] Step[2756] Loss=0.3491\n",
            "Epoch[0/2] Step[2757] Loss=0.3128\n",
            "Epoch[0/2] Step[2758] Loss=0.6228\n",
            "Epoch[0/2] Step[2759] Loss=1.0266\n",
            "Epoch[0/2] Step[2760] Loss=0.7144\n",
            "Epoch[0/2] Step[2761] Loss=0.2578\n",
            "Epoch[0/2] Step[2762] Loss=0.4463\n",
            "Epoch[0/2] Step[2763] Loss=0.1498\n",
            "Epoch[0/2] Step[2764] Loss=0.2453\n",
            "Epoch[0/2] Step[2765] Loss=0.2476\n",
            "Epoch[0/2] Step[2766] Loss=0.5661\n",
            "Epoch[0/2] Step[2767] Loss=0.6572\n",
            "Epoch[0/2] Step[2768] Loss=0.2088\n",
            "Epoch[0/2] Step[2769] Loss=0.0680\n",
            "Epoch[0/2] Step[2770] Loss=0.2901\n",
            "Epoch[0/2] Step[2771] Loss=0.1543\n",
            "Epoch[0/2] Step[2772] Loss=1.0086\n",
            "Epoch[0/2] Step[2773] Loss=0.1959\n",
            "Epoch[0/2] Step[2774] Loss=0.2292\n",
            "Epoch[0/2] Step[2775] Loss=0.2135\n",
            "Epoch[0/2] Step[2776] Loss=0.3878\n",
            "Epoch[0/2] Step[2777] Loss=0.3170\n",
            "Epoch[0/2] Step[2778] Loss=0.6094\n",
            "Epoch[0/2] Step[2779] Loss=0.3106\n",
            "Epoch[0/2] Step[2780] Loss=0.5536\n",
            "Epoch[0/2] Step[2781] Loss=0.3500\n",
            "Epoch[0/2] Step[2782] Loss=0.2242\n",
            "Epoch[0/2] Step[2783] Loss=0.1982\n",
            "Epoch[0/2] Step[2784] Loss=0.5214\n",
            "Epoch[0/2] Step[2785] Loss=0.3980\n",
            "Epoch[0/2] Step[2786] Loss=0.4222\n",
            "Epoch[0/2] Step[2787] Loss=0.2912\n",
            "Epoch[0/2] Step[2788] Loss=0.4390\n",
            "Epoch[0/2] Step[2789] Loss=0.7991\n",
            "Epoch[0/2] Step[2790] Loss=0.3205\n",
            "Epoch[0/2] Step[2791] Loss=0.1723\n",
            "Epoch[0/2] Step[2792] Loss=0.9786\n",
            "Epoch[0/2] Step[2793] Loss=0.4821\n",
            "Epoch[0/2] Step[2794] Loss=0.3527\n",
            "Epoch[0/2] Step[2795] Loss=0.3281\n",
            "Epoch[0/2] Step[2796] Loss=0.1803\n",
            "Epoch[0/2] Step[2797] Loss=0.1736\n",
            "Epoch[0/2] Step[2798] Loss=0.7704\n",
            "Epoch[0/2] Step[2799] Loss=0.2007\n",
            "Epoch[0/2] Step[2800] Loss=0.1533\n",
            "Epoch[0/2] Step[2801] Loss=0.2829\n",
            "Epoch[0/2] Step[2802] Loss=0.4629\n",
            "Epoch[0/2] Step[2803] Loss=0.7414\n",
            "Epoch[0/2] Step[2804] Loss=0.5451\n",
            "Epoch[0/2] Step[2805] Loss=0.7893\n",
            "Epoch[0/2] Step[2806] Loss=0.5983\n",
            "Epoch[0/2] Step[2807] Loss=0.3574\n",
            "Epoch[0/2] Step[2808] Loss=0.4299\n",
            "Epoch[0/2] Step[2809] Loss=0.8246\n",
            "Epoch[0/2] Step[2810] Loss=0.2816\n",
            "Epoch[0/2] Step[2811] Loss=0.6840\n",
            "Epoch[0/2] Step[2812] Loss=0.1255\n",
            "Epoch[0/2] Step[2813] Loss=0.1750\n",
            "Epoch[0/2] Step[2814] Loss=0.1548\n",
            "Epoch[0/2] Step[2815] Loss=0.3685\n",
            "Epoch[0/2] Step[2816] Loss=0.5614\n",
            "Epoch[0/2] Step[2817] Loss=0.1181\n",
            "Epoch[0/2] Step[2818] Loss=0.1426\n",
            "Epoch[0/2] Step[2819] Loss=0.2941\n",
            "Epoch[0/2] Step[2820] Loss=0.2186\n",
            "Epoch[0/2] Step[2821] Loss=0.2478\n",
            "Epoch[0/2] Step[2822] Loss=0.2849\n",
            "Epoch[0/2] Step[2823] Loss=0.3008\n",
            "Epoch[0/2] Step[2824] Loss=0.1489\n",
            "Epoch[0/2] Step[2825] Loss=0.1207\n",
            "Epoch[0/2] Step[2826] Loss=0.2279\n",
            "Epoch[0/2] Step[2827] Loss=0.2385\n",
            "Epoch[0/2] Step[2828] Loss=0.8893\n",
            "Epoch[0/2] Step[2829] Loss=0.3448\n",
            "Epoch[0/2] Step[2830] Loss=0.2135\n",
            "Epoch[0/2] Step[2831] Loss=0.2911\n",
            "Epoch[0/2] Step[2832] Loss=0.4955\n",
            "Epoch[0/2] Step[2833] Loss=0.3783\n",
            "Epoch[0/2] Step[2834] Loss=0.2128\n",
            "Epoch[0/2] Step[2835] Loss=0.1281\n",
            "Epoch[0/2] Step[2836] Loss=0.3976\n",
            "Epoch[0/2] Step[2837] Loss=0.6897\n",
            "Epoch[0/2] Step[2838] Loss=0.7204\n",
            "Epoch[0/2] Step[2839] Loss=0.3076\n",
            "Epoch[0/2] Step[2840] Loss=0.2753\n",
            "Epoch[0/2] Step[2841] Loss=0.3357\n",
            "Epoch[0/2] Step[2842] Loss=0.4006\n",
            "Epoch[0/2] Step[2843] Loss=0.2461\n",
            "Epoch[0/2] Step[2844] Loss=0.1635\n",
            "Epoch[0/2] Step[2845] Loss=0.5861\n",
            "Epoch[0/2] Step[2846] Loss=0.0749\n",
            "Epoch[0/2] Step[2847] Loss=1.0938\n",
            "Epoch[0/2] Step[2848] Loss=0.4491\n",
            "Epoch[0/2] Step[2849] Loss=0.5143\n",
            "Epoch[0/2] Step[2850] Loss=0.5761\n",
            "Epoch[0/2] Step[2851] Loss=0.4452\n",
            "Epoch[0/2] Step[2852] Loss=0.7628\n",
            "Epoch[0/2] Step[2853] Loss=0.9051\n",
            "Epoch[0/2] Step[2854] Loss=0.1829\n",
            "Epoch[0/2] Step[2855] Loss=0.2955\n",
            "Epoch[0/2] Step[2856] Loss=0.4553\n",
            "Epoch[0/2] Step[2857] Loss=0.2130\n",
            "Epoch[0/2] Step[2858] Loss=0.4822\n",
            "Epoch[0/2] Step[2859] Loss=0.4651\n",
            "Epoch[0/2] Step[2860] Loss=0.2869\n",
            "Epoch[0/2] Step[2861] Loss=0.2618\n",
            "Epoch[0/2] Step[2862] Loss=0.6892\n",
            "Epoch[0/2] Step[2863] Loss=0.5633\n",
            "Epoch[0/2] Step[2864] Loss=0.1630\n",
            "Epoch[0/2] Step[2865] Loss=0.3113\n",
            "Epoch[0/2] Step[2866] Loss=1.6747\n",
            "Epoch[0/2] Step[2867] Loss=0.3627\n",
            "Epoch[0/2] Step[2868] Loss=0.5103\n",
            "Epoch[0/2] Step[2869] Loss=0.9719\n",
            "Epoch[0/2] Step[2870] Loss=0.6567\n",
            "Epoch[0/2] Step[2871] Loss=0.1290\n",
            "Epoch[0/2] Step[2872] Loss=0.3381\n",
            "Epoch[0/2] Step[2873] Loss=0.4458\n",
            "Epoch[0/2] Step[2874] Loss=0.5757\n",
            "Epoch[0/2] Step[2875] Loss=0.3141\n",
            "Epoch[0/2] Step[2876] Loss=0.7649\n",
            "Epoch[0/2] Step[2877] Loss=0.2877\n",
            "Epoch[0/2] Step[2878] Loss=0.3304\n",
            "Epoch[0/2] Step[2879] Loss=0.6310\n",
            "Epoch[0/2] Step[2880] Loss=0.2199\n",
            "Epoch[0/2] Step[2881] Loss=0.4155\n",
            "Epoch[0/2] Step[2882] Loss=0.3462\n",
            "Epoch[0/2] Step[2883] Loss=0.2835\n",
            "Epoch[0/2] Step[2884] Loss=0.5506\n",
            "Epoch[0/2] Step[2885] Loss=0.1092\n",
            "Epoch[0/2] Step[2886] Loss=0.6570\n",
            "Epoch[0/2] Step[2887] Loss=0.2806\n",
            "Epoch[0/2] Step[2888] Loss=1.8033\n",
            "Epoch[0/2] Step[2889] Loss=0.1870\n",
            "Epoch[0/2] Step[2890] Loss=0.3435\n",
            "Epoch[0/2] Step[2891] Loss=0.1825\n",
            "Epoch[0/2] Step[2892] Loss=0.1417\n",
            "Epoch[0/2] Step[2893] Loss=0.2740\n",
            "Epoch[0/2] Step[2894] Loss=0.2932\n",
            "Epoch[0/2] Step[2895] Loss=0.4417\n",
            "Epoch[0/2] Step[2896] Loss=0.3885\n",
            "Epoch[0/2] Step[2897] Loss=0.2492\n",
            "Epoch[0/2] Step[2898] Loss=0.1912\n",
            "Epoch[0/2] Step[2899] Loss=0.3866\n",
            "Epoch[0/2] Step[2900] Loss=0.4748\n",
            "Epoch[0/2] Step[2901] Loss=0.1903\n",
            "Epoch[0/2] Step[2902] Loss=0.4071\n",
            "Epoch[0/2] Step[2903] Loss=0.2820\n",
            "Epoch[0/2] Step[2904] Loss=0.6418\n",
            "Epoch[0/2] Step[2905] Loss=0.1275\n",
            "Epoch[0/2] Step[2906] Loss=0.2533\n",
            "Epoch[0/2] Step[2907] Loss=0.4916\n",
            "Epoch[0/2] Step[2908] Loss=0.2758\n",
            "Epoch[0/2] Step[2909] Loss=1.0219\n",
            "Epoch[0/2] Step[2910] Loss=0.3531\n",
            "Epoch[0/2] Step[2911] Loss=0.1935\n",
            "Epoch[0/2] Step[2912] Loss=0.7250\n",
            "Epoch[0/2] Step[2913] Loss=0.5131\n",
            "Epoch[0/2] Step[2914] Loss=0.3825\n",
            "Epoch[0/2] Step[2915] Loss=0.4853\n",
            "Epoch[0/2] Step[2916] Loss=0.4678\n",
            "Epoch[0/2] Step[2917] Loss=0.4629\n",
            "Epoch[0/2] Step[2918] Loss=0.6976\n",
            "Epoch[0/2] Step[2919] Loss=0.5323\n",
            "Epoch[0/2] Step[2920] Loss=0.2470\n",
            "Epoch[0/2] Step[2921] Loss=0.6725\n",
            "Epoch[0/2] Step[2922] Loss=0.1693\n",
            "Epoch[0/2] Step[2923] Loss=0.2060\n",
            "Epoch[0/2] Step[2924] Loss=0.4626\n",
            "Epoch[0/2] Step[2925] Loss=0.4326\n",
            "Epoch[0/2] Step[2926] Loss=1.0539\n",
            "Epoch[0/2] Step[2927] Loss=0.6058\n",
            "Epoch[0/2] Step[2928] Loss=0.3876\n",
            "Epoch[0/2] Step[2929] Loss=0.8423\n",
            "Epoch[0/2] Step[2930] Loss=0.3063\n",
            "Epoch[0/2] Step[2931] Loss=0.3504\n",
            "Epoch[0/2] Step[2932] Loss=0.7131\n",
            "Epoch[0/2] Step[2933] Loss=0.5229\n",
            "Epoch[0/2] Step[2934] Loss=0.4279\n",
            "Epoch[0/2] Step[2935] Loss=0.3963\n",
            "Epoch[0/2] Step[2936] Loss=0.3894\n",
            "Epoch[0/2] Step[2937] Loss=0.4978\n",
            "Epoch[0/2] Step[2938] Loss=0.4369\n",
            "Epoch[0/2] Step[2939] Loss=0.5121\n",
            "Epoch[0/2] Step[2940] Loss=0.1767\n",
            "Epoch[0/2] Step[2941] Loss=0.3547\n",
            "Epoch[0/2] Step[2942] Loss=0.4650\n",
            "Epoch[0/2] Step[2943] Loss=0.2023\n",
            "Epoch[0/2] Step[2944] Loss=0.1313\n",
            "Epoch[0/2] Step[2945] Loss=0.5421\n",
            "Epoch[0/2] Step[2946] Loss=0.3313\n",
            "Epoch[0/2] Step[2947] Loss=0.4305\n",
            "Epoch[0/2] Step[2948] Loss=0.3201\n",
            "Epoch[0/2] Step[2949] Loss=0.4033\n",
            "Epoch[0/2] Step[2950] Loss=0.4735\n",
            "Epoch[0/2] Step[2951] Loss=0.4320\n",
            "Epoch[0/2] Step[2952] Loss=0.6720\n",
            "Epoch[0/2] Step[2953] Loss=1.0393\n",
            "Epoch[0/2] Step[2954] Loss=0.5644\n",
            "Epoch[0/2] Step[2955] Loss=0.5341\n",
            "Epoch[0/2] Step[2956] Loss=1.0108\n",
            "Epoch[0/2] Step[2957] Loss=0.4384\n",
            "Epoch[0/2] Step[2958] Loss=0.1843\n",
            "Epoch[0/2] Step[2959] Loss=0.4491\n",
            "Epoch[0/2] Step[2960] Loss=0.1030\n",
            "Epoch[0/2] Step[2961] Loss=0.2794\n",
            "Epoch[0/2] Step[2962] Loss=0.3770\n",
            "Epoch[0/2] Step[2963] Loss=0.5790\n",
            "Epoch[0/2] Step[2964] Loss=0.4707\n",
            "Epoch[0/2] Step[2965] Loss=0.4634\n",
            "Epoch[0/2] Step[2966] Loss=0.3577\n",
            "Epoch[0/2] Step[2967] Loss=0.4538\n",
            "Epoch[0/2] Step[2968] Loss=0.2672\n",
            "Epoch[0/2] Step[2969] Loss=0.4070\n",
            "Epoch[0/2] Step[2970] Loss=0.4361\n",
            "Epoch[0/2] Step[2971] Loss=0.7544\n",
            "Epoch[0/2] Step[2972] Loss=0.5056\n",
            "Epoch[0/2] Step[2973] Loss=0.1990\n",
            "Epoch[0/2] Step[2974] Loss=0.2214\n",
            "Epoch[0/2] Step[2975] Loss=0.3671\n",
            "Epoch[0/2] Step[2976] Loss=0.1440\n",
            "Epoch[0/2] Step[2977] Loss=0.5122\n",
            "Epoch[0/2] Step[2978] Loss=0.1452\n",
            "Epoch[0/2] Step[2979] Loss=0.1906\n",
            "Epoch[0/2] Step[2980] Loss=0.1287\n",
            "Epoch[0/2] Step[2981] Loss=0.4139\n",
            "Epoch[0/2] Step[2982] Loss=0.3730\n",
            "Epoch[0/2] Step[2983] Loss=0.6216\n",
            "Epoch[0/2] Step[2984] Loss=0.4975\n",
            "Epoch[0/2] Step[2985] Loss=0.4791\n",
            "Epoch[0/2] Step[2986] Loss=0.1937\n",
            "Epoch[0/2] Step[2987] Loss=0.3526\n",
            "Epoch[0/2] Step[2988] Loss=0.4730\n",
            "Epoch[0/2] Step[2989] Loss=0.2637\n",
            "Epoch[0/2] Step[2990] Loss=0.5426\n",
            "Epoch[0/2] Step[2991] Loss=0.3712\n",
            "Epoch[0/2] Step[2992] Loss=0.5234\n",
            "Epoch[0/2] Step[2993] Loss=0.1698\n",
            "Epoch[0/2] Step[2994] Loss=0.2013\n",
            "Epoch[0/2] Step[2995] Loss=0.7720\n",
            "Epoch[0/2] Step[2996] Loss=0.3493\n",
            "Epoch[0/2] Step[2997] Loss=0.3213\n",
            "Epoch[0/2] Step[2998] Loss=0.4707\n",
            "Epoch[0/2] Step[2999] Loss=0.1142\n",
            "Epoch[0/2] Step[3000] Loss=0.1404\n",
            "Epoch[0/2] Step[3001] Loss=0.1572\n",
            "Epoch[0/2] Step[3002] Loss=0.1611\n",
            "Epoch[0/2] Step[3003] Loss=0.6667\n",
            "Epoch[0/2] Step[3004] Loss=0.3149\n",
            "Epoch[0/2] Step[3005] Loss=0.2493\n",
            "Epoch[0/2] Step[3006] Loss=0.1890\n",
            "Epoch[0/2] Step[3007] Loss=0.4752\n",
            "Epoch[0/2] Step[3008] Loss=0.1981\n",
            "Epoch[0/2] Step[3009] Loss=0.2824\n",
            "Epoch[0/2] Step[3010] Loss=0.6909\n",
            "Epoch[0/2] Step[3011] Loss=0.4665\n",
            "Epoch[0/2] Step[3012] Loss=0.2012\n",
            "Epoch[0/2] Step[3013] Loss=0.2296\n",
            "Epoch[0/2] Step[3014] Loss=0.5362\n",
            "Epoch[0/2] Step[3015] Loss=0.2243\n",
            "Epoch[0/2] Step[3016] Loss=0.2093\n",
            "Epoch[0/2] Step[3017] Loss=0.2724\n",
            "Epoch[0/2] Step[3018] Loss=0.4219\n",
            "Epoch[0/2] Step[3019] Loss=0.4903\n",
            "Epoch[0/2] Step[3020] Loss=0.3603\n",
            "Epoch[0/2] Step[3021] Loss=0.1310\n",
            "Epoch[0/2] Step[3022] Loss=0.4677\n",
            "Epoch[0/2] Step[3023] Loss=0.3808\n",
            "Epoch[0/2] Step[3024] Loss=0.7062\n",
            "Epoch[0/2] Step[3025] Loss=0.8288\n",
            "Epoch[0/2] Step[3026] Loss=0.0886\n",
            "Epoch[0/2] Step[3027] Loss=0.1110\n",
            "Epoch[0/2] Step[3028] Loss=0.6994\n",
            "Epoch[0/2] Step[3029] Loss=0.1349\n",
            "Epoch[0/2] Step[3030] Loss=0.5188\n",
            "Epoch[0/2] Step[3031] Loss=0.2976\n",
            "Epoch[0/2] Step[3032] Loss=0.5374\n",
            "Epoch[0/2] Step[3033] Loss=0.2933\n",
            "Epoch[0/2] Step[3034] Loss=0.5123\n",
            "Epoch[0/2] Step[3035] Loss=0.2115\n",
            "Epoch[0/2] Step[3036] Loss=0.1028\n",
            "Epoch[0/2] Step[3037] Loss=0.4737\n",
            "Epoch[0/2] Step[3038] Loss=0.4249\n",
            "Epoch[0/2] Step[3039] Loss=0.3986\n",
            "Epoch[0/2] Step[3040] Loss=0.2120\n",
            "Epoch[0/2] Step[3041] Loss=0.5393\n",
            "Epoch[0/2] Step[3042] Loss=0.5132\n",
            "Epoch[0/2] Step[3043] Loss=0.3408\n",
            "Epoch[0/2] Step[3044] Loss=0.4508\n",
            "Epoch[0/2] Step[3045] Loss=0.4939\n",
            "Epoch[0/2] Step[3046] Loss=0.5194\n",
            "Epoch[0/2] Step[3047] Loss=0.1425\n",
            "Epoch[0/2] Step[3048] Loss=0.7267\n",
            "Epoch[0/2] Step[3049] Loss=0.5240\n",
            "Epoch[0/2] Step[3050] Loss=0.3798\n",
            "Epoch[0/2] Step[3051] Loss=0.2086\n",
            "Epoch[0/2] Step[3052] Loss=0.2723\n",
            "Epoch[0/2] Step[3053] Loss=0.2391\n",
            "Epoch[0/2] Step[3054] Loss=0.1934\n",
            "Epoch[0/2] Step[3055] Loss=0.2786\n",
            "Epoch[0/2] Step[3056] Loss=0.2979\n",
            "Epoch[0/2] Step[3057] Loss=0.3457\n",
            "Epoch[0/2] Step[3058] Loss=0.7438\n",
            "Epoch[0/2] Step[3059] Loss=0.7127\n",
            "Epoch[0/2] Step[3060] Loss=0.1433\n",
            "Epoch[0/2] Step[3061] Loss=0.6611\n",
            "Epoch[0/2] Step[3062] Loss=0.2139\n",
            "Epoch[0/2] Step[3063] Loss=0.1635\n",
            "Epoch[0/2] Step[3064] Loss=0.1947\n",
            "Epoch[0/2] Step[3065] Loss=0.4452\n",
            "Epoch[0/2] Step[3066] Loss=0.2410\n",
            "Epoch[0/2] Step[3067] Loss=0.3666\n",
            "Epoch[0/2] Step[3068] Loss=0.2071\n",
            "Epoch[0/2] Step[3069] Loss=0.2119\n",
            "Epoch[0/2] Step[3070] Loss=0.2557\n",
            "Epoch[0/2] Step[3071] Loss=0.4467\n",
            "Epoch[0/2] Step[3072] Loss=0.3841\n",
            "Epoch[0/2] Step[3073] Loss=0.1898\n",
            "Epoch[0/2] Step[3074] Loss=0.5186\n",
            "Epoch[0/2] Step[3075] Loss=0.1870\n",
            "Epoch[0/2] Step[3076] Loss=0.4821\n",
            "Epoch[0/2] Step[3077] Loss=0.6622\n",
            "Epoch[0/2] Step[3078] Loss=0.2869\n",
            "Epoch[0/2] Step[3079] Loss=0.5810\n",
            "Epoch[0/2] Step[3080] Loss=0.5295\n",
            "Epoch[0/2] Step[3081] Loss=0.5717\n",
            "Epoch[0/2] Step[3082] Loss=0.3492\n",
            "Epoch[0/2] Step[3083] Loss=0.2167\n",
            "Epoch[0/2] Step[3084] Loss=0.6036\n",
            "Epoch[0/2] Step[3085] Loss=0.1054\n",
            "Epoch[0/2] Step[3086] Loss=0.9050\n",
            "Epoch[0/2] Step[3087] Loss=0.1540\n",
            "Epoch[0/2] Step[3088] Loss=0.9656\n",
            "Epoch[0/2] Step[3089] Loss=0.3905\n",
            "Epoch[0/2] Step[3090] Loss=0.2170\n",
            "Epoch[0/2] Step[3091] Loss=0.1806\n",
            "Epoch[0/2] Step[3092] Loss=0.4403\n",
            "Epoch[0/2] Step[3093] Loss=0.1811\n",
            "Epoch[0/2] Step[3094] Loss=0.0879\n",
            "Epoch[0/2] Step[3095] Loss=0.1707\n",
            "Epoch[0/2] Step[3096] Loss=0.3701\n",
            "Epoch[0/2] Step[3097] Loss=0.8297\n",
            "Epoch[0/2] Step[3098] Loss=0.2656\n",
            "Epoch[0/2] Step[3099] Loss=0.1830\n",
            "Epoch[0/2] Step[3100] Loss=0.4619\n",
            "Epoch[0/2] Step[3101] Loss=0.6816\n",
            "Epoch[0/2] Step[3102] Loss=0.1682\n",
            "Epoch[0/2] Step[3103] Loss=0.2470\n",
            "Epoch[0/2] Step[3104] Loss=0.1218\n",
            "Epoch[0/2] Step[3105] Loss=0.3008\n",
            "Epoch[0/2] Step[3106] Loss=0.0984\n",
            "Epoch[0/2] Step[3107] Loss=0.2445\n",
            "Epoch[0/2] Step[3108] Loss=0.3263\n",
            "Epoch[0/2] Step[3109] Loss=0.1447\n",
            "Epoch[0/2] Step[3110] Loss=0.4745\n",
            "Epoch[0/2] Step[3111] Loss=0.6473\n",
            "Epoch[0/2] Step[3112] Loss=0.5433\n",
            "Epoch[0/2] Step[3113] Loss=0.3763\n",
            "Epoch[0/2] Step[3114] Loss=0.4017\n",
            "Epoch[0/2] Step[3115] Loss=0.3666\n",
            "Epoch[0/2] Step[3116] Loss=0.3002\n",
            "Epoch[0/2] Step[3117] Loss=0.5068\n",
            "Epoch[0/2] Step[3118] Loss=1.2215\n",
            "Epoch[0/2] Step[3119] Loss=0.1145\n",
            "Epoch[0/2] Step[3120] Loss=0.4550\n",
            "Epoch[0/2] Step[3121] Loss=0.2283\n",
            "Epoch[0/2] Step[3122] Loss=0.1750\n",
            "Epoch[0/2] Step[3123] Loss=0.7674\n",
            "Epoch[0/2] Step[3124] Loss=0.5458\n",
            "Epoch[0/2] Step[3125] Loss=0.5550\n",
            "Epoch[0/2] Step[3126] Loss=0.7738\n",
            "Epoch[0/2] Step[3127] Loss=0.1323\n",
            "Epoch[0/2] Step[3128] Loss=0.5776\n",
            "Epoch[0/2] Step[3129] Loss=0.1434\n",
            "Epoch[0/2] Step[3130] Loss=0.4011\n",
            "Epoch[0/2] Step[3131] Loss=0.2432\n",
            "Epoch[0/2] Step[3132] Loss=0.5886\n",
            "Epoch[0/2] Step[3133] Loss=0.4675\n",
            "Epoch[0/2] Step[3134] Loss=0.4567\n",
            "Epoch[0/2] Step[3135] Loss=0.2887\n",
            "Epoch[0/2] Step[3136] Loss=0.3912\n",
            "Epoch[0/2] Step[3137] Loss=0.2163\n",
            "Epoch[0/2] Step[3138] Loss=0.3091\n",
            "Epoch[0/2] Step[3139] Loss=0.2297\n",
            "Epoch[0/2] Step[3140] Loss=0.4603\n",
            "Epoch[0/2] Step[3141] Loss=0.2202\n",
            "Epoch[0/2] Step[3142] Loss=0.2901\n",
            "Epoch[0/2] Step[3143] Loss=0.4855\n",
            "Epoch[0/2] Step[3144] Loss=0.3005\n",
            "Epoch[0/2] Step[3145] Loss=0.5750\n",
            "Epoch[0/2] Step[3146] Loss=0.3874\n",
            "Epoch[0/2] Step[3147] Loss=0.3054\n",
            "Epoch[0/2] Step[3148] Loss=0.2031\n",
            "Epoch[0/2] Step[3149] Loss=0.1673\n",
            "Epoch[0/2] Step[3150] Loss=0.0969\n",
            "Epoch[0/2] Step[3151] Loss=0.4559\n",
            "Epoch[0/2] Step[3152] Loss=0.1295\n",
            "Epoch[0/2] Step[3153] Loss=0.2040\n",
            "Epoch[0/2] Step[3154] Loss=0.1432\n",
            "Epoch[0/2] Step[3155] Loss=0.1939\n",
            "Epoch[0/2] Step[3156] Loss=0.3368\n",
            "Epoch[0/2] Step[3157] Loss=1.3102\n",
            "Epoch[0/2] Step[3158] Loss=0.6327\n",
            "Epoch[0/2] Step[3159] Loss=0.7096\n",
            "Epoch[0/2] Step[3160] Loss=0.1922\n",
            "Epoch[0/2] Step[3161] Loss=0.2592\n",
            "Epoch[0/2] Step[3162] Loss=0.4883\n",
            "Epoch[0/2] Step[3163] Loss=0.6067\n",
            "Epoch[0/2] Step[3164] Loss=0.5286\n",
            "Epoch[0/2] Step[3165] Loss=0.2210\n",
            "Epoch[0/2] Step[3166] Loss=0.3801\n",
            "Epoch[0/2] Step[3167] Loss=0.2191\n",
            "Epoch[0/2] Step[3168] Loss=0.1555\n",
            "Epoch[0/2] Step[3169] Loss=0.3867\n",
            "Epoch[0/2] Step[3170] Loss=0.6678\n",
            "Epoch[0/2] Step[3171] Loss=0.6745\n",
            "Epoch[0/2] Step[3172] Loss=0.3000\n",
            "Epoch[0/2] Step[3173] Loss=0.4333\n",
            "Epoch[0/2] Step[3174] Loss=0.4705\n",
            "Epoch[0/2] Step[3175] Loss=0.2110\n",
            "Epoch[0/2] Step[3176] Loss=0.1814\n",
            "Epoch[0/2] Step[3177] Loss=0.4606\n",
            "Epoch[0/2] Step[3178] Loss=0.1048\n",
            "Epoch[0/2] Step[3179] Loss=0.3123\n",
            "Epoch[0/2] Step[3180] Loss=0.2558\n",
            "Epoch[0/2] Step[3181] Loss=0.4308\n",
            "Epoch[0/2] Step[3182] Loss=0.1482\n",
            "Epoch[0/2] Step[3183] Loss=0.7559\n",
            "Epoch[0/2] Step[3184] Loss=0.8053\n",
            "Epoch[0/2] Step[3185] Loss=0.2183\n",
            "Epoch[0/2] Step[3186] Loss=0.3763\n",
            "Epoch[0/2] Step[3187] Loss=0.2102\n",
            "Epoch[0/2] Step[3188] Loss=0.6825\n",
            "Epoch[0/2] Step[3189] Loss=0.8012\n",
            "Epoch[0/2] Step[3190] Loss=0.4496\n",
            "Epoch[0/2] Step[3191] Loss=0.7044\n",
            "Epoch[0/2] Step[3192] Loss=0.1579\n",
            "Epoch[0/2] Step[3193] Loss=0.1754\n",
            "Epoch[0/2] Step[3194] Loss=0.3116\n",
            "Epoch[0/2] Step[3195] Loss=0.2538\n",
            "Epoch[0/2] Step[3196] Loss=0.6079\n",
            "Epoch[0/2] Step[3197] Loss=0.3219\n",
            "Epoch[0/2] Step[3198] Loss=0.1954\n",
            "Epoch[0/2] Step[3199] Loss=0.5526\n",
            "Epoch[0/2] Step[3200] Loss=0.8863\n",
            "Epoch[0/2] Step[3201] Loss=0.4809\n",
            "Epoch[0/2] Step[3202] Loss=0.2866\n",
            "Epoch[0/2] Step[3203] Loss=0.7991\n",
            "Epoch[0/2] Step[3204] Loss=0.1913\n",
            "Epoch[0/2] Step[3205] Loss=0.2919\n",
            "Epoch[0/2] Step[3206] Loss=0.0783\n",
            "Epoch[0/2] Step[3207] Loss=0.3969\n",
            "Epoch[0/2] Step[3208] Loss=0.2474\n",
            "Epoch[0/2] Step[3209] Loss=0.8208\n",
            "Epoch[0/2] Step[3210] Loss=0.2683\n",
            "Epoch[0/2] Step[3211] Loss=0.4123\n",
            "Epoch[0/2] Step[3212] Loss=0.7889\n",
            "Epoch[0/2] Step[3213] Loss=0.2957\n",
            "Epoch[0/2] Step[3214] Loss=0.2001\n",
            "Epoch[0/2] Step[3215] Loss=0.1084\n",
            "Epoch[0/2] Step[3216] Loss=0.1459\n",
            "Epoch[0/2] Step[3217] Loss=0.3564\n",
            "Epoch[0/2] Step[3218] Loss=0.3643\n",
            "Epoch[0/2] Step[3219] Loss=0.3238\n",
            "Epoch[0/2] Step[3220] Loss=0.7634\n",
            "Epoch[0/2] Step[3221] Loss=0.2580\n",
            "Epoch[0/2] Step[3222] Loss=0.3272\n",
            "Epoch[0/2] Step[3223] Loss=0.4549\n",
            "Epoch[0/2] Step[3224] Loss=0.3231\n",
            "Epoch[0/2] Step[3225] Loss=0.1713\n",
            "Epoch[0/2] Step[3226] Loss=0.6536\n",
            "Epoch[0/2] Step[3227] Loss=0.4321\n",
            "Epoch[0/2] Step[3228] Loss=0.3197\n",
            "Epoch[0/2] Step[3229] Loss=0.6516\n",
            "Epoch[0/2] Step[3230] Loss=0.3959\n",
            "Epoch[0/2] Step[3231] Loss=0.2022\n",
            "Epoch[0/2] Step[3232] Loss=0.1972\n",
            "Epoch[0/2] Step[3233] Loss=0.4485\n",
            "Epoch[0/2] Step[3234] Loss=0.2028\n",
            "Epoch[0/2] Step[3235] Loss=0.3331\n",
            "Epoch[0/2] Step[3236] Loss=0.2249\n",
            "Epoch[0/2] Step[3237] Loss=0.6386\n",
            "Epoch[0/2] Step[3238] Loss=0.0500\n",
            "Epoch[0/2] Step[3239] Loss=0.2006\n",
            "Epoch[0/2] Step[3240] Loss=0.4331\n",
            "Epoch[0/2] Step[3241] Loss=0.4137\n",
            "Epoch[0/2] Step[3242] Loss=0.3410\n",
            "Epoch[0/2] Step[3243] Loss=0.3090\n",
            "Epoch[0/2] Step[3244] Loss=0.7105\n",
            "Epoch[0/2] Step[3245] Loss=0.2086\n",
            "Epoch[0/2] Step[3246] Loss=0.5565\n",
            "Epoch[0/2] Step[3247] Loss=0.3289\n",
            "Epoch[0/2] Step[3248] Loss=0.4686\n",
            "Epoch[0/2] Step[3249] Loss=0.2886\n",
            "Epoch[0/2] Step[3250] Loss=0.5979\n",
            "Epoch[0/2] Step[3251] Loss=1.3221\n",
            "Epoch[0/2] Step[3252] Loss=0.2513\n",
            "Epoch[0/2] Step[3253] Loss=0.1532\n",
            "Epoch[0/2] Step[3254] Loss=0.5700\n",
            "Epoch[0/2] Step[3255] Loss=0.2602\n",
            "Epoch[0/2] Step[3256] Loss=0.2815\n",
            "Epoch[0/2] Step[3257] Loss=0.4056\n",
            "Epoch[0/2] Step[3258] Loss=1.1047\n",
            "Epoch[0/2] Step[3259] Loss=0.1953\n",
            "Epoch[0/2] Step[3260] Loss=0.3902\n",
            "Epoch[0/2] Step[3261] Loss=0.3407\n",
            "Epoch[0/2] Step[3262] Loss=0.4344\n",
            "Epoch[0/2] Step[3263] Loss=0.3448\n",
            "Epoch[0/2] Step[3264] Loss=0.5998\n",
            "Epoch[0/2] Step[3265] Loss=0.5086\n",
            "Epoch[0/2] Step[3266] Loss=0.6811\n",
            "Epoch[0/2] Step[3267] Loss=0.7396\n",
            "Epoch[0/2] Step[3268] Loss=0.3033\n",
            "Epoch[0/2] Step[3269] Loss=0.4586\n",
            "Epoch[0/2] Step[3270] Loss=0.3132\n",
            "Epoch[0/2] Step[3271] Loss=0.5248\n",
            "Epoch[0/2] Step[3272] Loss=0.1393\n",
            "Epoch[0/2] Step[3273] Loss=0.4606\n",
            "Epoch[0/2] Step[3274] Loss=0.1683\n",
            "Epoch[0/2] Step[3275] Loss=0.2183\n",
            "Epoch[0/2] Step[3276] Loss=0.4399\n",
            "Epoch[0/2] Step[3277] Loss=0.1988\n",
            "Epoch[0/2] Step[3278] Loss=0.1718\n",
            "Epoch[0/2] Step[3279] Loss=0.1919\n",
            "Epoch[0/2] Step[3280] Loss=0.3859\n",
            "Epoch[0/2] Step[3281] Loss=0.2020\n",
            "Epoch[0/2] Step[3282] Loss=0.1897\n",
            "Epoch[0/2] Step[3283] Loss=0.5318\n",
            "Epoch[0/2] Step[3284] Loss=1.1381\n",
            "Epoch[0/2] Step[3285] Loss=0.6024\n",
            "Epoch[0/2] Step[3286] Loss=0.4154\n",
            "Epoch[0/2] Step[3287] Loss=0.2268\n",
            "Epoch[0/2] Step[3288] Loss=0.3791\n",
            "Epoch[0/2] Step[3289] Loss=0.8796\n",
            "Epoch[0/2] Step[3290] Loss=0.2571\n",
            "Epoch[0/2] Step[3291] Loss=0.2743\n",
            "Epoch[0/2] Step[3292] Loss=0.1420\n",
            "Epoch[0/2] Step[3293] Loss=0.1123\n",
            "Epoch[0/2] Step[3294] Loss=0.5232\n",
            "Epoch[0/2] Step[3295] Loss=0.5379\n",
            "Epoch[0/2] Step[3296] Loss=0.2800\n",
            "Epoch[0/2] Step[3297] Loss=0.4529\n",
            "Epoch[0/2] Step[3298] Loss=0.2039\n",
            "Epoch[0/2] Step[3299] Loss=0.5457\n",
            "Epoch[0/2] Step[3300] Loss=0.7466\n",
            "Epoch[0/2] Step[3301] Loss=0.4802\n",
            "Epoch[0/2] Step[3302] Loss=0.6132\n",
            "Epoch[0/2] Step[3303] Loss=0.5946\n",
            "Epoch[0/2] Step[3304] Loss=0.2007\n",
            "Epoch[0/2] Step[3305] Loss=0.1965\n",
            "Epoch[0/2] Step[3306] Loss=0.1710\n",
            "Epoch[0/2] Step[3307] Loss=0.1850\n",
            "Epoch[0/2] Step[3308] Loss=0.6349\n",
            "Epoch[0/2] Step[3309] Loss=0.7175\n",
            "Epoch[0/2] Step[3310] Loss=0.8414\n",
            "Epoch[0/2] Step[3311] Loss=0.1193\n",
            "Epoch[0/2] Step[3312] Loss=0.8345\n",
            "Epoch[0/2] Step[3313] Loss=0.6545\n",
            "Epoch[0/2] Step[3314] Loss=0.2539\n",
            "Epoch[0/2] Step[3315] Loss=0.2666\n",
            "Epoch[0/2] Step[3316] Loss=0.4435\n",
            "Epoch[0/2] Step[3317] Loss=0.2107\n",
            "Epoch[0/2] Step[3318] Loss=0.5511\n",
            "Epoch[0/2] Step[3319] Loss=0.2749\n",
            "Epoch[0/2] Step[3320] Loss=0.0724\n",
            "Epoch[0/2] Step[3321] Loss=0.8798\n",
            "Epoch[0/2] Step[3322] Loss=0.7552\n",
            "Epoch[0/2] Step[3323] Loss=0.7353\n",
            "Epoch[0/2] Step[3324] Loss=0.5900\n",
            "Epoch[0/2] Step[3325] Loss=0.3139\n",
            "Epoch[0/2] Step[3326] Loss=0.2312\n",
            "Epoch[0/2] Step[3327] Loss=0.2547\n",
            "Epoch[0/2] Step[3328] Loss=0.3796\n",
            "Epoch[0/2] Step[3329] Loss=0.3571\n",
            "Epoch[0/2] Step[3330] Loss=0.2192\n",
            "Epoch[0/2] Step[3331] Loss=0.3202\n",
            "Epoch[0/2] Step[3332] Loss=0.3617\n",
            "Epoch[0/2] Step[3333] Loss=0.6535\n",
            "Epoch[0/2] Step[3334] Loss=0.7303\n",
            "Epoch[0/2] Step[3335] Loss=0.1302\n",
            "Epoch[0/2] Step[3336] Loss=0.2739\n",
            "Epoch[0/2] Step[3337] Loss=0.1571\n",
            "Epoch[0/2] Step[3338] Loss=0.1293\n",
            "Epoch[0/2] Step[3339] Loss=0.1357\n",
            "Epoch[0/2] Step[3340] Loss=0.3250\n",
            "Epoch[0/2] Step[3341] Loss=0.4277\n",
            "Epoch[0/2] Step[3342] Loss=0.3896\n",
            "Epoch[0/2] Step[3343] Loss=0.3221\n",
            "Epoch[0/2] Step[3344] Loss=0.6568\n",
            "Epoch[0/2] Step[3345] Loss=0.0932\n",
            "Epoch[0/2] Step[3346] Loss=0.5765\n",
            "Epoch[0/2] Step[3347] Loss=0.4928\n",
            "Epoch[0/2] Step[3348] Loss=0.4160\n",
            "Epoch[0/2] Step[3349] Loss=0.3585\n",
            "Epoch[0/2] Step[3350] Loss=0.7340\n",
            "Epoch[0/2] Step[3351] Loss=0.2398\n",
            "Epoch[0/2] Step[3352] Loss=0.1870\n",
            "Epoch[0/2] Step[3353] Loss=0.1539\n",
            "Epoch[0/2] Step[3354] Loss=0.4791\n",
            "Epoch[0/2] Step[3355] Loss=0.0844\n",
            "Epoch[0/2] Step[3356] Loss=0.2468\n",
            "Epoch[0/2] Step[3357] Loss=0.3394\n",
            "Epoch[0/2] Step[3358] Loss=0.2611\n",
            "Epoch[0/2] Step[3359] Loss=0.2508\n",
            "Epoch[0/2] Step[3360] Loss=0.5701\n",
            "Epoch[0/2] Step[3361] Loss=0.4012\n",
            "Epoch[0/2] Step[3362] Loss=0.5197\n",
            "Epoch[0/2] Step[3363] Loss=0.6526\n",
            "Epoch[0/2] Step[3364] Loss=0.5622\n",
            "Epoch[0/2] Step[3365] Loss=0.3792\n",
            "Epoch[0/2] Step[3366] Loss=0.6256\n",
            "Epoch[0/2] Step[3367] Loss=0.1319\n",
            "Epoch[0/2] Step[3368] Loss=0.5783\n",
            "Epoch[0/2] Step[3369] Loss=0.4550\n",
            "Epoch[0/2] Step[3370] Loss=0.3233\n",
            "Epoch[0/2] Step[3371] Loss=0.4522\n",
            "Epoch[0/2] Step[3372] Loss=0.2219\n",
            "Epoch[0/2] Step[3373] Loss=0.1105\n",
            "Epoch[0/2] Step[3374] Loss=0.1540\n",
            "Epoch[0/2] Step[3375] Loss=0.3650\n",
            "Epoch[0/2] Step[3376] Loss=0.5905\n",
            "Epoch[0/2] Step[3377] Loss=0.4002\n",
            "Epoch[0/2] Step[3378] Loss=0.4491\n",
            "Epoch[0/2] Step[3379] Loss=0.3977\n",
            "Epoch[0/2] Step[3380] Loss=0.6706\n",
            "Epoch[0/2] Step[3381] Loss=0.2020\n",
            "Epoch[0/2] Step[3382] Loss=0.4466\n",
            "Epoch[0/2] Step[3383] Loss=0.2171\n",
            "Epoch[0/2] Step[3384] Loss=0.2122\n",
            "Epoch[0/2] Step[3385] Loss=0.3624\n",
            "Epoch[0/2] Step[3386] Loss=0.7558\n",
            "Epoch[0/2] Step[3387] Loss=0.9967\n",
            "Epoch[0/2] Step[3388] Loss=0.2359\n",
            "Epoch[0/2] Step[3389] Loss=0.5254\n",
            "Epoch[0/2] Step[3390] Loss=0.4062\n",
            "Epoch[0/2] Step[3391] Loss=0.1969\n",
            "Epoch[0/2] Step[3392] Loss=0.2810\n",
            "Epoch[0/2] Step[3393] Loss=0.3105\n",
            "Epoch[0/2] Step[3394] Loss=0.1536\n",
            "Epoch[0/2] Step[3395] Loss=0.3366\n",
            "Epoch[0/2] Step[3396] Loss=0.1160\n",
            "Epoch[0/2] Step[3397] Loss=0.3003\n",
            "Epoch[0/2] Step[3398] Loss=0.2527\n",
            "Epoch[0/2] Step[3399] Loss=0.0896\n",
            "Epoch[0/2] Step[3400] Loss=0.2951\n",
            "Epoch[0/2] Step[3401] Loss=0.3358\n",
            "Epoch[0/2] Step[3402] Loss=0.4686\n",
            "Epoch[0/2] Step[3403] Loss=0.2227\n",
            "Epoch[0/2] Step[3404] Loss=0.3883\n",
            "Epoch[0/2] Step[3405] Loss=0.1802\n",
            "Epoch[0/2] Step[3406] Loss=0.2846\n",
            "Epoch[0/2] Step[3407] Loss=0.7160\n",
            "Epoch[0/2] Step[3408] Loss=0.3068\n",
            "Epoch[0/2] Step[3409] Loss=0.6126\n",
            "Epoch[0/2] Step[3410] Loss=0.5465\n",
            "Epoch[0/2] Step[3411] Loss=0.3384\n",
            "Epoch[0/2] Step[3412] Loss=1.2035\n",
            "Epoch[0/2] Step[3413] Loss=0.2100\n",
            "Epoch[0/2] Step[3414] Loss=0.3226\n",
            "Epoch[0/2] Step[3415] Loss=0.8218\n",
            "Epoch[0/2] Step[3416] Loss=0.1268\n",
            "Epoch[0/2] Step[3417] Loss=0.3643\n",
            "Epoch[0/2] Step[3418] Loss=0.4082\n",
            "Epoch[0/2] Step[3419] Loss=0.2291\n",
            "Epoch[0/2] Step[3420] Loss=0.0978\n",
            "Epoch[0/2] Step[3421] Loss=0.2989\n",
            "Epoch[0/2] Step[3422] Loss=0.6004\n",
            "Epoch[0/2] Step[3423] Loss=0.3995\n",
            "Epoch[0/2] Step[3424] Loss=0.3254\n",
            "Epoch[0/2] Step[3425] Loss=0.4185\n",
            "Epoch[0/2] Step[3426] Loss=0.2296\n",
            "Epoch[0/2] Step[3427] Loss=0.1335\n",
            "Epoch[0/2] Step[3428] Loss=0.3703\n",
            "Epoch[0/2] Step[3429] Loss=0.3629\n",
            "Epoch[0/2] Step[3430] Loss=0.2548\n",
            "Epoch[0/2] Step[3431] Loss=0.5474\n",
            "Epoch[0/2] Step[3432] Loss=0.4534\n",
            "Epoch[0/2] Step[3433] Loss=0.6335\n",
            "Epoch[0/2] Step[3434] Loss=0.6322\n",
            "Epoch[0/2] Step[3435] Loss=0.3047\n",
            "Epoch[0/2] Step[3436] Loss=0.3373\n",
            "Epoch[0/2] Step[3437] Loss=0.2754\n",
            "Epoch[0/2] Step[3438] Loss=0.4349\n",
            "Epoch[0/2] Step[3439] Loss=0.4437\n",
            "Epoch[0/2] Step[3440] Loss=0.4709\n",
            "Epoch[0/2] Step[3441] Loss=0.5204\n",
            "Epoch[0/2] Step[3442] Loss=0.3058\n",
            "Epoch[0/2] Step[3443] Loss=0.2230\n",
            "Epoch[0/2] Step[3444] Loss=0.1763\n",
            "Epoch[0/2] Step[3445] Loss=0.6863\n",
            "Epoch[0/2] Step[3446] Loss=0.1863\n",
            "Epoch[0/2] Step[3447] Loss=0.4074\n",
            "Epoch[0/2] Step[3448] Loss=0.4375\n",
            "Epoch[0/2] Step[3449] Loss=0.1319\n",
            "Epoch[0/2] Step[3450] Loss=0.2005\n",
            "Epoch[0/2] Step[3451] Loss=0.1779\n",
            "Epoch[0/2] Step[3452] Loss=0.5401\n",
            "Epoch[0/2] Step[3453] Loss=0.5174\n",
            "Epoch[0/2] Step[3454] Loss=0.4973\n",
            "Epoch[0/2] Step[3455] Loss=0.2605\n",
            "Epoch[0/2] Step[3456] Loss=0.3835\n",
            "Epoch[0/2] Step[3457] Loss=0.2224\n",
            "Epoch[0/2] Step[3458] Loss=0.6224\n",
            "Epoch[0/2] Step[3459] Loss=0.2177\n",
            "Epoch[0/2] Step[3460] Loss=0.0751\n",
            "Epoch[0/2] Step[3461] Loss=0.3164\n",
            "Epoch[0/2] Step[3462] Loss=0.1517\n",
            "Epoch[0/2] Step[3463] Loss=0.3297\n",
            "Epoch[0/2] Step[3464] Loss=0.0605\n",
            "Epoch[0/2] Step[3465] Loss=0.5074\n",
            "Epoch[0/2] Step[3466] Loss=0.6069\n",
            "Epoch[0/2] Step[3467] Loss=0.4581\n",
            "Epoch[0/2] Step[3468] Loss=0.4979\n",
            "Epoch[0/2] Step[3469] Loss=0.6854\n",
            "Epoch[0/2] Step[3470] Loss=0.6909\n",
            "Epoch[0/2] Step[3471] Loss=0.3156\n",
            "Epoch[0/2] Step[3472] Loss=0.1427\n",
            "Epoch[0/2] Step[3473] Loss=0.8901\n",
            "Epoch[0/2] Step[3474] Loss=0.7288\n",
            "Epoch[0/2] Step[3475] Loss=0.2384\n",
            "Epoch[0/2] Step[3476] Loss=0.8191\n",
            "Epoch[0/2] Step[3477] Loss=0.4547\n",
            "Epoch[0/2] Step[3478] Loss=0.9199\n",
            "Epoch[0/2] Step[3479] Loss=0.2369\n",
            "Epoch[0/2] Step[3480] Loss=0.2773\n",
            "Epoch[0/2] Step[3481] Loss=0.1544\n",
            "Epoch[0/2] Step[3482] Loss=0.7539\n",
            "Epoch[0/2] Step[3483] Loss=0.2457\n",
            "Epoch[0/2] Step[3484] Loss=0.4222\n",
            "Epoch[0/2] Step[3485] Loss=0.1996\n",
            "Epoch[0/2] Step[3486] Loss=0.1320\n",
            "Epoch[0/2] Step[3487] Loss=0.2395\n",
            "Epoch[0/2] Step[3488] Loss=0.4899\n",
            "Epoch[0/2] Step[3489] Loss=0.2683\n",
            "Epoch[0/2] Step[3490] Loss=0.3289\n",
            "Epoch[0/2] Step[3491] Loss=0.2163\n",
            "Epoch[0/2] Step[3492] Loss=0.1307\n",
            "Epoch[0/2] Step[3493] Loss=0.5333\n",
            "Epoch[0/2] Step[3494] Loss=0.4485\n",
            "Epoch[0/2] Step[3495] Loss=0.3238\n",
            "Epoch[0/2] Step[3496] Loss=0.3126\n",
            "Epoch[0/2] Step[3497] Loss=0.2301\n",
            "Epoch[0/2] Step[3498] Loss=0.2082\n",
            "Epoch[0/2] Step[3499] Loss=0.1540\n",
            "Epoch[0/2] Step[3500] Loss=0.2367\n",
            "Epoch[0/2] Step[3501] Loss=0.2624\n",
            "Epoch[0/2] Step[3502] Loss=1.0118\n",
            "Epoch[0/2] Step[3503] Loss=0.3633\n",
            "Epoch[0/2] Step[3504] Loss=0.4313\n",
            "Epoch[0/2] Step[3505] Loss=0.2714\n",
            "Epoch[0/2] Step[3506] Loss=0.4323\n",
            "Epoch[0/2] Step[3507] Loss=0.1142\n",
            "Epoch[0/2] Step[3508] Loss=0.7482\n",
            "Epoch[0/2] Step[3509] Loss=0.4519\n",
            "Epoch[0/2] Step[3510] Loss=0.2978\n",
            "Epoch[0/2] Step[3511] Loss=0.1944\n",
            "Epoch[0/2] Step[3512] Loss=0.6408\n",
            "Epoch[0/2] Step[3513] Loss=0.7649\n",
            "Epoch[0/2] Step[3514] Loss=0.2729\n",
            "Epoch[0/2] Step[3515] Loss=0.3700\n",
            "Epoch[0/2] Step[3516] Loss=0.2810\n",
            "Epoch[0/2] Step[3517] Loss=0.3727\n",
            "Epoch[0/2] Step[3518] Loss=0.4420\n",
            "Epoch[0/2] Step[3519] Loss=0.3145\n",
            "Epoch[0/2] Step[3520] Loss=0.2103\n",
            "Epoch[0/2] Step[3521] Loss=0.3003\n",
            "Epoch[0/2] Step[3522] Loss=0.5646\n",
            "Epoch[0/2] Step[3523] Loss=0.3852\n",
            "Epoch[0/2] Step[3524] Loss=0.8772\n",
            "Epoch[0/2] Step[3525] Loss=0.3962\n",
            "Epoch[0/2] Step[3526] Loss=0.2673\n",
            "Epoch[0/2] Step[3527] Loss=0.2344\n",
            "Epoch[0/2] Step[3528] Loss=0.3556\n",
            "Epoch[0/2] Step[3529] Loss=0.1929\n",
            "Epoch[0/2] Step[3530] Loss=0.2155\n",
            "Epoch[0/2] Step[3531] Loss=0.3045\n",
            "Epoch[0/2] Step[3532] Loss=0.4759\n",
            "Epoch[0/2] Step[3533] Loss=0.2536\n",
            "Epoch[0/2] Step[3534] Loss=0.2678\n",
            "Epoch[0/2] Step[3535] Loss=0.2662\n",
            "Epoch[0/2] Step[3536] Loss=0.6576\n",
            "Epoch[0/2] Step[3537] Loss=0.3653\n",
            "Epoch[0/2] Step[3538] Loss=0.4862\n",
            "Epoch[0/2] Step[3539] Loss=0.1520\n",
            "Epoch[0/2] Step[3540] Loss=0.2406\n",
            "Epoch[0/2] Step[3541] Loss=0.6768\n",
            "Epoch[0/2] Step[3542] Loss=0.4095\n",
            "Epoch[0/2] Step[3543] Loss=0.6600\n",
            "Epoch[0/2] Step[3544] Loss=0.3644\n",
            "Epoch[0/2] Step[3545] Loss=0.7212\n",
            "Epoch[0/2] Step[3546] Loss=0.4428\n",
            "Epoch[0/2] Step[3547] Loss=0.5859\n",
            "Epoch[0/2] Step[3548] Loss=0.4392\n",
            "Epoch[0/2] Step[3549] Loss=0.5446\n",
            "Epoch[0/2] Step[3550] Loss=0.3047\n",
            "Epoch[0/2] Step[3551] Loss=0.2769\n",
            "Epoch[0/2] Step[3552] Loss=0.2281\n",
            "Epoch[0/2] Step[3553] Loss=0.1920\n",
            "Epoch[0/2] Step[3554] Loss=0.3583\n",
            "Epoch[0/2] Step[3555] Loss=0.5298\n",
            "Epoch[0/2] Step[3556] Loss=0.2319\n",
            "Epoch[0/2] Step[3557] Loss=0.2138\n",
            "Epoch[0/2] Step[3558] Loss=0.2406\n",
            "Epoch[0/2] Step[3559] Loss=0.6280\n",
            "Epoch[0/2] Step[3560] Loss=0.2069\n",
            "Epoch[0/2] Step[3561] Loss=0.1839\n",
            "Epoch[0/2] Step[3562] Loss=0.6407\n",
            "Epoch[0/2] Step[3563] Loss=0.5868\n",
            "Epoch[0/2] Step[3564] Loss=0.1663\n",
            "Epoch[0/2] Step[3565] Loss=0.1537\n",
            "Epoch[0/2] Step[3566] Loss=0.5489\n",
            "Epoch[0/2] Step[3567] Loss=0.1046\n",
            "Epoch[0/2] Step[3568] Loss=0.1890\n",
            "Epoch[0/2] Step[3569] Loss=0.0858\n",
            "Epoch[0/2] Step[3570] Loss=0.4010\n",
            "Epoch[0/2] Step[3571] Loss=0.3637\n",
            "Epoch[0/2] Step[3572] Loss=0.3554\n",
            "Epoch[0/2] Step[3573] Loss=0.2164\n",
            "Epoch[0/2] Step[3574] Loss=0.1871\n",
            "Epoch[0/2] Step[3575] Loss=0.9511\n",
            "Epoch[0/2] Step[3576] Loss=0.4179\n",
            "Epoch[0/2] Step[3577] Loss=0.4339\n",
            "Epoch[0/2] Step[3578] Loss=0.5150\n",
            "Epoch[0/2] Step[3579] Loss=0.6885\n",
            "Epoch[0/2] Step[3580] Loss=0.1383\n",
            "Epoch[0/2] Step[3581] Loss=0.3374\n",
            "Epoch[0/2] Step[3582] Loss=0.2853\n",
            "Epoch[0/2] Step[3583] Loss=0.3444\n",
            "Epoch[0/2] Step[3584] Loss=0.2079\n",
            "Epoch[0/2] Step[3585] Loss=1.3274\n",
            "Epoch[0/2] Step[3586] Loss=0.4069\n",
            "Epoch[0/2] Step[3587] Loss=0.1387\n",
            "Epoch[0/2] Step[3588] Loss=0.4493\n",
            "Epoch[0/2] Step[3589] Loss=0.7336\n",
            "Epoch[0/2] Step[3590] Loss=0.4938\n",
            "Epoch[0/2] Step[3591] Loss=0.5739\n",
            "Epoch[0/2] Step[3592] Loss=0.2643\n",
            "Epoch[0/2] Step[3593] Loss=0.3641\n",
            "Epoch[0/2] Step[3594] Loss=0.2661\n",
            "Epoch[0/2] Step[3595] Loss=0.5244\n",
            "Epoch[0/2] Step[3596] Loss=0.4703\n",
            "Epoch[0/2] Step[3597] Loss=0.0736\n",
            "Epoch[0/2] Step[3598] Loss=0.1073\n",
            "Epoch[0/2] Step[3599] Loss=0.1349\n",
            "Epoch[0/2] Step[3600] Loss=0.2438\n",
            "Epoch[0/2] Step[3601] Loss=0.4458\n",
            "Epoch[0/2] Step[3602] Loss=0.1176\n",
            "Epoch[0/2] Step[3603] Loss=0.5229\n",
            "Epoch[0/2] Step[3604] Loss=0.1317\n",
            "Epoch[0/2] Step[3605] Loss=0.2811\n",
            "Epoch[0/2] Step[3606] Loss=0.5091\n",
            "Epoch[0/2] Step[3607] Loss=0.1831\n",
            "Epoch[0/2] Step[3608] Loss=0.1985\n",
            "Epoch[0/2] Step[3609] Loss=0.2371\n",
            "Epoch[0/2] Step[3610] Loss=0.4972\n",
            "Epoch[0/2] Step[3611] Loss=0.2569\n",
            "Epoch[0/2] Step[3612] Loss=0.2038\n",
            "Epoch[0/2] Step[3613] Loss=0.4087\n",
            "Epoch[0/2] Step[3614] Loss=0.1769\n",
            "Epoch[0/2] Step[3615] Loss=0.1911\n",
            "Epoch[0/2] Step[3616] Loss=0.2921\n",
            "Epoch[0/2] Step[3617] Loss=0.2788\n",
            "Epoch[0/2] Step[3618] Loss=0.8911\n",
            "Epoch[0/2] Step[3619] Loss=0.3858\n",
            "Epoch[0/2] Step[3620] Loss=0.5319\n",
            "Epoch[0/2] Step[3621] Loss=0.5555\n",
            "Epoch[0/2] Step[3622] Loss=0.2030\n",
            "Epoch[0/2] Step[3623] Loss=0.3162\n",
            "Epoch[0/2] Step[3624] Loss=0.4087\n",
            "Epoch[0/2] Step[3625] Loss=0.2326\n",
            "Epoch[0/2] Step[3626] Loss=0.5556\n",
            "Epoch[0/2] Step[3627] Loss=0.1796\n",
            "Epoch[0/2] Step[3628] Loss=0.2114\n",
            "Epoch[0/2] Step[3629] Loss=0.2761\n",
            "Epoch[0/2] Step[3630] Loss=0.4681\n",
            "Epoch[0/2] Step[3631] Loss=0.4107\n",
            "Epoch[0/2] Step[3632] Loss=0.8645\n",
            "Epoch[0/2] Step[3633] Loss=0.3977\n",
            "Epoch[0/2] Step[3634] Loss=0.1393\n",
            "Epoch[0/2] Step[3635] Loss=0.4372\n",
            "Epoch[0/2] Step[3636] Loss=0.2320\n",
            "Epoch[0/2] Step[3637] Loss=0.6312\n",
            "Epoch[0/2] Step[3638] Loss=0.6420\n",
            "Epoch[0/2] Step[3639] Loss=0.6777\n",
            "Epoch[0/2] Step[3640] Loss=0.1200\n",
            "Epoch[0/2] Step[3641] Loss=0.3840\n",
            "Epoch[0/2] Step[3642] Loss=0.3987\n",
            "Epoch[0/2] Step[3643] Loss=0.2060\n",
            "Epoch[0/2] Step[3644] Loss=0.2762\n",
            "Epoch[0/2] Step[3645] Loss=0.3260\n",
            "Epoch[0/2] Step[3646] Loss=0.3088\n",
            "Epoch[0/2] Step[3647] Loss=0.1440\n",
            "Epoch[0/2] Step[3648] Loss=0.3723\n",
            "Epoch[0/2] Step[3649] Loss=0.3775\n",
            "Epoch[0/2] Step[3650] Loss=0.4652\n",
            "Epoch[0/2] Step[3651] Loss=0.5784\n",
            "Epoch[0/2] Step[3652] Loss=0.3284\n",
            "Epoch[0/2] Step[3653] Loss=0.1685\n",
            "Epoch[0/2] Step[3654] Loss=0.5755\n",
            "Epoch[0/2] Step[3655] Loss=0.1886\n",
            "Epoch[0/2] Step[3656] Loss=0.7418\n",
            "Epoch[0/2] Step[3657] Loss=0.6044\n",
            "Epoch[0/2] Step[3658] Loss=1.3668\n",
            "Epoch[0/2] Step[3659] Loss=0.3841\n",
            "Epoch[0/2] Step[3660] Loss=0.5547\n",
            "Epoch[0/2] Step[3661] Loss=0.9687\n",
            "Epoch[0/2] Step[3662] Loss=0.2532\n",
            "Epoch[0/2] Step[3663] Loss=0.4382\n",
            "Epoch[0/2] Step[3664] Loss=0.9415\n",
            "Epoch[0/2] Step[3665] Loss=0.7236\n",
            "Epoch[0/2] Step[3666] Loss=0.1767\n",
            "Epoch[0/2] Step[3667] Loss=0.1644\n",
            "Epoch[0/2] Step[3668] Loss=0.2506\n",
            "Epoch[0/2] Step[3669] Loss=0.1007\n",
            "Epoch[0/2] Step[3670] Loss=0.9145\n",
            "Epoch[0/2] Step[3671] Loss=0.5193\n",
            "Epoch[0/2] Step[3672] Loss=0.2278\n",
            "Epoch[0/2] Step[3673] Loss=0.3689\n",
            "Epoch[0/2] Step[3674] Loss=0.3128\n",
            "Epoch[0/2] Step[3675] Loss=0.3679\n",
            "Epoch[0/2] Step[3676] Loss=0.2716\n",
            "Epoch[0/2] Step[3677] Loss=0.0667\n",
            "Epoch[0/2] Step[3678] Loss=0.4083\n",
            "Epoch[0/2] Step[3679] Loss=0.0856\n",
            "Epoch[0/2] Step[3680] Loss=0.4304\n",
            "Epoch[0/2] Step[3681] Loss=0.3134\n",
            "Epoch[0/2] Step[3682] Loss=0.3617\n",
            "Epoch[0/2] Step[3683] Loss=0.2896\n",
            "Epoch[0/2] Step[3684] Loss=0.9300\n",
            "Epoch[0/2] Step[3685] Loss=0.3468\n",
            "Epoch[0/2] Step[3686] Loss=0.1125\n",
            "Epoch[0/2] Step[3687] Loss=0.1679\n",
            "Epoch[0/2] Step[3688] Loss=0.3098\n",
            "Epoch[0/2] Step[3689] Loss=0.5273\n",
            "Epoch[0/2] Step[3690] Loss=0.4489\n",
            "Epoch[0/2] Step[3691] Loss=0.3332\n",
            "Epoch[0/2] Step[3692] Loss=0.1438\n",
            "Epoch[0/2] Step[3693] Loss=0.4820\n",
            "Epoch[0/2] Step[3694] Loss=0.4019\n",
            "Epoch[0/2] Step[3695] Loss=0.3470\n",
            "Epoch[0/2] Step[3696] Loss=0.3496\n",
            "Epoch[0/2] Step[3697] Loss=0.1878\n",
            "Epoch[0/2] Step[3698] Loss=0.4596\n",
            "Epoch[0/2] Step[3699] Loss=0.3512\n",
            "Epoch[0/2] Step[3700] Loss=0.2416\n",
            "Epoch[0/2] Step[3701] Loss=0.9274\n",
            "Epoch[0/2] Step[3702] Loss=0.3042\n",
            "Epoch[0/2] Step[3703] Loss=0.0839\n",
            "Epoch[0/2] Step[3704] Loss=0.2296\n",
            "Epoch[0/2] Step[3705] Loss=0.3795\n",
            "Epoch[0/2] Step[3706] Loss=0.2600\n",
            "Epoch[0/2] Step[3707] Loss=0.1410\n",
            "Epoch[0/2] Step[3708] Loss=0.7377\n",
            "Epoch[0/2] Step[3709] Loss=0.2539\n",
            "Epoch[0/2] Step[3710] Loss=0.4215\n",
            "Epoch[0/2] Step[3711] Loss=1.1876\n",
            "Epoch[0/2] Step[3712] Loss=0.5542\n",
            "Epoch[0/2] Step[3713] Loss=0.3607\n",
            "Epoch[0/2] Step[3714] Loss=0.2784\n",
            "Epoch[0/2] Step[3715] Loss=0.6175\n",
            "Epoch[0/2] Step[3716] Loss=0.2220\n",
            "Epoch[0/2] Step[3717] Loss=0.4049\n",
            "Epoch[0/2] Step[3718] Loss=0.4007\n",
            "Epoch[0/2] Step[3719] Loss=0.5084\n",
            "Epoch[0/2] Step[3720] Loss=0.3807\n",
            "Epoch[0/2] Step[3721] Loss=0.6058\n",
            "Epoch[0/2] Step[3722] Loss=0.3018\n",
            "Epoch[0/2] Step[3723] Loss=0.4384\n",
            "Epoch[0/2] Step[3724] Loss=0.1205\n",
            "Epoch[0/2] Step[3725] Loss=0.1028\n",
            "Epoch[0/2] Step[3726] Loss=0.2969\n",
            "Epoch[0/2] Step[3727] Loss=0.4954\n",
            "Epoch[0/2] Step[3728] Loss=0.8532\n",
            "Epoch[0/2] Step[3729] Loss=0.1841\n",
            "Epoch[0/2] Step[3730] Loss=0.2364\n",
            "Epoch[0/2] Step[3731] Loss=0.2285\n",
            "Epoch[0/2] Step[3732] Loss=0.3069\n",
            "Epoch[0/2] Step[3733] Loss=0.6460\n",
            "Epoch[0/2] Step[3734] Loss=0.1339\n",
            "Epoch[0/2] Step[3735] Loss=0.5305\n",
            "Epoch[0/2] Step[3736] Loss=0.1283\n",
            "Epoch[0/2] Step[3737] Loss=1.0146\n",
            "Epoch[0/2] Step[3738] Loss=0.2909\n",
            "Epoch[0/2] Step[3739] Loss=0.1545\n",
            "Epoch[0/2] Step[3740] Loss=0.1108\n",
            "Epoch[0/2] Step[3741] Loss=0.2779\n",
            "Epoch[0/2] Step[3742] Loss=0.2302\n",
            "Epoch[0/2] Step[3743] Loss=0.2374\n",
            "Epoch[0/2] Step[3744] Loss=0.1204\n",
            "Epoch[0/2] Step[3745] Loss=0.6031\n",
            "Epoch[0/2] Step[3746] Loss=0.3191\n",
            "Epoch[0/2] Step[3747] Loss=0.4971\n",
            "Epoch[0/2] Step[3748] Loss=1.2805\n",
            "Epoch[0/2] Step[3749] Loss=0.2902\n",
            "Epoch[0/2] Step[3750] Loss=0.1601\n",
            "Epoch 1/2 => TrainLoss=0.7659 TestLoss=0.3500 Acc=89.50%\n",
            "Epoch[1/2] Step[3751] Loss=0.2865\n",
            "Epoch[1/2] Step[3752] Loss=0.2778\n",
            "Epoch[1/2] Step[3753] Loss=0.5669\n",
            "Epoch[1/2] Step[3754] Loss=0.1983\n",
            "Epoch[1/2] Step[3755] Loss=0.2682\n",
            "Epoch[1/2] Step[3756] Loss=0.6181\n",
            "Epoch[1/2] Step[3757] Loss=0.1075\n",
            "Epoch[1/2] Step[3758] Loss=0.2138\n",
            "Epoch[1/2] Step[3759] Loss=0.6528\n",
            "Epoch[1/2] Step[3760] Loss=0.4101\n",
            "Epoch[1/2] Step[3761] Loss=0.4674\n",
            "Epoch[1/2] Step[3762] Loss=0.2268\n",
            "Epoch[1/2] Step[3763] Loss=0.5867\n",
            "Epoch[1/2] Step[3764] Loss=0.5466\n",
            "Epoch[1/2] Step[3765] Loss=0.2439\n",
            "Epoch[1/2] Step[3766] Loss=0.8235\n",
            "Epoch[1/2] Step[3767] Loss=0.3518\n",
            "Epoch[1/2] Step[3768] Loss=0.4165\n",
            "Epoch[1/2] Step[3769] Loss=0.5838\n",
            "Epoch[1/2] Step[3770] Loss=0.3903\n",
            "Epoch[1/2] Step[3771] Loss=0.2581\n",
            "Epoch[1/2] Step[3772] Loss=0.3332\n",
            "Epoch[1/2] Step[3773] Loss=0.1070\n",
            "Epoch[1/2] Step[3774] Loss=0.1691\n",
            "Epoch[1/2] Step[3775] Loss=1.5859\n",
            "Epoch[1/2] Step[3776] Loss=0.3091\n",
            "Epoch[1/2] Step[3777] Loss=0.5485\n",
            "Epoch[1/2] Step[3778] Loss=0.3326\n",
            "Epoch[1/2] Step[3779] Loss=0.5227\n",
            "Epoch[1/2] Step[3780] Loss=0.3134\n",
            "Epoch[1/2] Step[3781] Loss=0.8203\n",
            "Epoch[1/2] Step[3782] Loss=0.3880\n",
            "Epoch[1/2] Step[3783] Loss=0.2285\n",
            "Epoch[1/2] Step[3784] Loss=0.6059\n",
            "Epoch[1/2] Step[3785] Loss=0.6018\n",
            "Epoch[1/2] Step[3786] Loss=0.4465\n",
            "Epoch[1/2] Step[3787] Loss=0.2592\n",
            "Epoch[1/2] Step[3788] Loss=0.3823\n",
            "Epoch[1/2] Step[3789] Loss=0.5080\n",
            "Epoch[1/2] Step[3790] Loss=0.6671\n",
            "Epoch[1/2] Step[3791] Loss=0.2032\n",
            "Epoch[1/2] Step[3792] Loss=0.3756\n",
            "Epoch[1/2] Step[3793] Loss=0.2145\n",
            "Epoch[1/2] Step[3794] Loss=0.3845\n",
            "Epoch[1/2] Step[3795] Loss=0.2326\n",
            "Epoch[1/2] Step[3796] Loss=0.3875\n",
            "Epoch[1/2] Step[3797] Loss=0.5159\n",
            "Epoch[1/2] Step[3798] Loss=0.5660\n",
            "Epoch[1/2] Step[3799] Loss=0.3305\n",
            "Epoch[1/2] Step[3800] Loss=0.2489\n",
            "Epoch[1/2] Step[3801] Loss=0.1470\n",
            "Epoch[1/2] Step[3802] Loss=0.3466\n",
            "Epoch[1/2] Step[3803] Loss=0.1729\n",
            "Epoch[1/2] Step[3804] Loss=0.2218\n",
            "Epoch[1/2] Step[3805] Loss=0.1911\n",
            "Epoch[1/2] Step[3806] Loss=0.2449\n",
            "Epoch[1/2] Step[3807] Loss=0.3391\n",
            "Epoch[1/2] Step[3808] Loss=1.2363\n",
            "Epoch[1/2] Step[3809] Loss=0.1573\n",
            "Epoch[1/2] Step[3810] Loss=0.0890\n",
            "Epoch[1/2] Step[3811] Loss=0.1974\n",
            "Epoch[1/2] Step[3812] Loss=0.6111\n",
            "Epoch[1/2] Step[3813] Loss=0.3274\n",
            "Epoch[1/2] Step[3814] Loss=0.5878\n",
            "Epoch[1/2] Step[3815] Loss=0.5232\n",
            "Epoch[1/2] Step[3816] Loss=0.4770\n",
            "Epoch[1/2] Step[3817] Loss=0.3850\n",
            "Epoch[1/2] Step[3818] Loss=0.3189\n",
            "Epoch[1/2] Step[3819] Loss=0.2164\n",
            "Epoch[1/2] Step[3820] Loss=0.6670\n",
            "Epoch[1/2] Step[3821] Loss=0.2300\n",
            "Epoch[1/2] Step[3822] Loss=0.2915\n",
            "Epoch[1/2] Step[3823] Loss=0.4225\n",
            "Epoch[1/2] Step[3824] Loss=0.6228\n",
            "Epoch[1/2] Step[3825] Loss=0.6769\n",
            "Epoch[1/2] Step[3826] Loss=0.1704\n",
            "Epoch[1/2] Step[3827] Loss=0.3599\n",
            "Epoch[1/2] Step[3828] Loss=0.4036\n",
            "Epoch[1/2] Step[3829] Loss=0.7047\n",
            "Epoch[1/2] Step[3830] Loss=0.0981\n",
            "Epoch[1/2] Step[3831] Loss=0.3740\n",
            "Epoch[1/2] Step[3832] Loss=0.3043\n",
            "Epoch[1/2] Step[3833] Loss=0.4039\n",
            "Epoch[1/2] Step[3834] Loss=0.7309\n",
            "Epoch[1/2] Step[3835] Loss=0.2769\n",
            "Epoch[1/2] Step[3836] Loss=0.1505\n",
            "Epoch[1/2] Step[3837] Loss=0.5278\n",
            "Epoch[1/2] Step[3838] Loss=0.5823\n",
            "Epoch[1/2] Step[3839] Loss=0.2665\n",
            "Epoch[1/2] Step[3840] Loss=0.4048\n",
            "Epoch[1/2] Step[3841] Loss=0.2543\n",
            "Epoch[1/2] Step[3842] Loss=0.6105\n",
            "Epoch[1/2] Step[3843] Loss=0.3126\n",
            "Epoch[1/2] Step[3844] Loss=0.0683\n",
            "Epoch[1/2] Step[3845] Loss=0.1763\n",
            "Epoch[1/2] Step[3846] Loss=0.3953\n",
            "Epoch[1/2] Step[3847] Loss=0.1897\n",
            "Epoch[1/2] Step[3848] Loss=0.3110\n",
            "Epoch[1/2] Step[3849] Loss=0.4217\n",
            "Epoch[1/2] Step[3850] Loss=0.1299\n",
            "Epoch[1/2] Step[3851] Loss=0.4378\n",
            "Epoch[1/2] Step[3852] Loss=0.6074\n",
            "Epoch[1/2] Step[3853] Loss=0.1936\n",
            "Epoch[1/2] Step[3854] Loss=0.2876\n",
            "Epoch[1/2] Step[3855] Loss=0.2173\n",
            "Epoch[1/2] Step[3856] Loss=0.3583\n",
            "Epoch[1/2] Step[3857] Loss=0.1567\n",
            "Epoch[1/2] Step[3858] Loss=0.2565\n",
            "Epoch[1/2] Step[3859] Loss=1.1462\n",
            "Epoch[1/2] Step[3860] Loss=0.3458\n",
            "Epoch[1/2] Step[3861] Loss=0.6710\n",
            "Epoch[1/2] Step[3862] Loss=0.4057\n",
            "Epoch[1/2] Step[3863] Loss=0.3829\n",
            "Epoch[1/2] Step[3864] Loss=0.4164\n",
            "Epoch[1/2] Step[3865] Loss=0.5798\n",
            "Epoch[1/2] Step[3866] Loss=0.2942\n",
            "Epoch[1/2] Step[3867] Loss=0.2039\n",
            "Epoch[1/2] Step[3868] Loss=0.6033\n",
            "Epoch[1/2] Step[3869] Loss=0.7235\n",
            "Epoch[1/2] Step[3870] Loss=0.6166\n",
            "Epoch[1/2] Step[3871] Loss=0.2454\n",
            "Epoch[1/2] Step[3872] Loss=0.7857\n",
            "Epoch[1/2] Step[3873] Loss=0.1073\n",
            "Epoch[1/2] Step[3874] Loss=0.2662\n",
            "Epoch[1/2] Step[3875] Loss=0.3995\n",
            "Epoch[1/2] Step[3876] Loss=0.1508\n",
            "Epoch[1/2] Step[3877] Loss=0.1364\n",
            "Epoch[1/2] Step[3878] Loss=0.2268\n",
            "Epoch[1/2] Step[3879] Loss=0.3240\n",
            "Epoch[1/2] Step[3880] Loss=0.1221\n",
            "Epoch[1/2] Step[3881] Loss=0.2239\n",
            "Epoch[1/2] Step[3882] Loss=0.4555\n",
            "Epoch[1/2] Step[3883] Loss=0.6239\n",
            "Epoch[1/2] Step[3884] Loss=0.2646\n",
            "Epoch[1/2] Step[3885] Loss=0.2668\n",
            "Epoch[1/2] Step[3886] Loss=0.4349\n",
            "Epoch[1/2] Step[3887] Loss=0.1001\n",
            "Epoch[1/2] Step[3888] Loss=0.3665\n",
            "Epoch[1/2] Step[3889] Loss=0.3603\n",
            "Epoch[1/2] Step[3890] Loss=0.2378\n",
            "Epoch[1/2] Step[3891] Loss=0.6191\n",
            "Epoch[1/2] Step[3892] Loss=0.4602\n",
            "Epoch[1/2] Step[3893] Loss=0.1379\n",
            "Epoch[1/2] Step[3894] Loss=0.2101\n",
            "Epoch[1/2] Step[3895] Loss=0.1717\n",
            "Epoch[1/2] Step[3896] Loss=0.4118\n",
            "Epoch[1/2] Step[3897] Loss=0.3690\n",
            "Epoch[1/2] Step[3898] Loss=0.1832\n",
            "Epoch[1/2] Step[3899] Loss=0.2180\n",
            "Epoch[1/2] Step[3900] Loss=0.2285\n",
            "Epoch[1/2] Step[3901] Loss=0.5400\n",
            "Epoch[1/2] Step[3902] Loss=0.3684\n",
            "Epoch[1/2] Step[3903] Loss=0.2799\n",
            "Epoch[1/2] Step[3904] Loss=0.2037\n",
            "Epoch[1/2] Step[3905] Loss=0.6268\n",
            "Epoch[1/2] Step[3906] Loss=0.1193\n",
            "Epoch[1/2] Step[3907] Loss=0.3045\n",
            "Epoch[1/2] Step[3908] Loss=0.1765\n",
            "Epoch[1/2] Step[3909] Loss=0.2039\n",
            "Epoch[1/2] Step[3910] Loss=0.2198\n",
            "Epoch[1/2] Step[3911] Loss=0.1318\n",
            "Epoch[1/2] Step[3912] Loss=0.2718\n",
            "Epoch[1/2] Step[3913] Loss=0.2887\n",
            "Epoch[1/2] Step[3914] Loss=0.2917\n",
            "Epoch[1/2] Step[3915] Loss=0.5363\n",
            "Epoch[1/2] Step[3916] Loss=0.4292\n",
            "Epoch[1/2] Step[3917] Loss=0.4412\n",
            "Epoch[1/2] Step[3918] Loss=0.1269\n",
            "Epoch[1/2] Step[3919] Loss=0.1671\n",
            "Epoch[1/2] Step[3920] Loss=0.1187\n",
            "Epoch[1/2] Step[3921] Loss=0.2139\n",
            "Epoch[1/2] Step[3922] Loss=0.2528\n",
            "Epoch[1/2] Step[3923] Loss=0.8091\n",
            "Epoch[1/2] Step[3924] Loss=0.4861\n",
            "Epoch[1/2] Step[3925] Loss=0.3144\n",
            "Epoch[1/2] Step[3926] Loss=0.7922\n",
            "Epoch[1/2] Step[3927] Loss=0.3917\n",
            "Epoch[1/2] Step[3928] Loss=0.2879\n",
            "Epoch[1/2] Step[3929] Loss=0.5165\n",
            "Epoch[1/2] Step[3930] Loss=0.1650\n",
            "Epoch[1/2] Step[3931] Loss=0.6032\n",
            "Epoch[1/2] Step[3932] Loss=0.3274\n",
            "Epoch[1/2] Step[3933] Loss=0.4670\n",
            "Epoch[1/2] Step[3934] Loss=0.3060\n",
            "Epoch[1/2] Step[3935] Loss=0.0788\n",
            "Epoch[1/2] Step[3936] Loss=0.5185\n",
            "Epoch[1/2] Step[3937] Loss=0.9735\n",
            "Epoch[1/2] Step[3938] Loss=0.3199\n",
            "Epoch[1/2] Step[3939] Loss=0.3388\n",
            "Epoch[1/2] Step[3940] Loss=0.2262\n",
            "Epoch[1/2] Step[3941] Loss=0.2087\n",
            "Epoch[1/2] Step[3942] Loss=0.3865\n",
            "Epoch[1/2] Step[3943] Loss=0.3137\n",
            "Epoch[1/2] Step[3944] Loss=0.2043\n",
            "Epoch[1/2] Step[3945] Loss=0.4813\n",
            "Epoch[1/2] Step[3946] Loss=0.2973\n",
            "Epoch[1/2] Step[3947] Loss=0.3154\n",
            "Epoch[1/2] Step[3948] Loss=0.2432\n",
            "Epoch[1/2] Step[3949] Loss=0.3140\n",
            "Epoch[1/2] Step[3950] Loss=0.3939\n",
            "Epoch[1/2] Step[3951] Loss=0.1094\n",
            "Epoch[1/2] Step[3952] Loss=0.8496\n",
            "Epoch[1/2] Step[3953] Loss=0.1391\n",
            "Epoch[1/2] Step[3954] Loss=0.6334\n",
            "Epoch[1/2] Step[3955] Loss=0.3461\n",
            "Epoch[1/2] Step[3956] Loss=0.4153\n",
            "Epoch[1/2] Step[3957] Loss=0.4073\n",
            "Epoch[1/2] Step[3958] Loss=0.2644\n",
            "Epoch[1/2] Step[3959] Loss=0.5264\n",
            "Epoch[1/2] Step[3960] Loss=0.2658\n",
            "Epoch[1/2] Step[3961] Loss=0.3220\n",
            "Epoch[1/2] Step[3962] Loss=0.3962\n",
            "Epoch[1/2] Step[3963] Loss=0.3582\n",
            "Epoch[1/2] Step[3964] Loss=0.3171\n",
            "Epoch[1/2] Step[3965] Loss=0.2223\n",
            "Epoch[1/2] Step[3966] Loss=0.4883\n",
            "Epoch[1/2] Step[3967] Loss=0.4641\n",
            "Epoch[1/2] Step[3968] Loss=0.2370\n",
            "Epoch[1/2] Step[3969] Loss=0.3484\n",
            "Epoch[1/2] Step[3970] Loss=0.6782\n",
            "Epoch[1/2] Step[3971] Loss=0.2704\n",
            "Epoch[1/2] Step[3972] Loss=0.1543\n",
            "Epoch[1/2] Step[3973] Loss=0.1522\n",
            "Epoch[1/2] Step[3974] Loss=0.4635\n",
            "Epoch[1/2] Step[3975] Loss=0.5005\n",
            "Epoch[1/2] Step[3976] Loss=0.6297\n",
            "Epoch[1/2] Step[3977] Loss=0.1300\n",
            "Epoch[1/2] Step[3978] Loss=0.3633\n",
            "Epoch[1/2] Step[3979] Loss=0.6329\n",
            "Epoch[1/2] Step[3980] Loss=0.8271\n",
            "Epoch[1/2] Step[3981] Loss=0.3762\n",
            "Epoch[1/2] Step[3982] Loss=0.2519\n",
            "Epoch[1/2] Step[3983] Loss=0.2637\n",
            "Epoch[1/2] Step[3984] Loss=0.0786\n",
            "Epoch[1/2] Step[3985] Loss=1.0302\n",
            "Epoch[1/2] Step[3986] Loss=0.3418\n",
            "Epoch[1/2] Step[3987] Loss=0.2329\n",
            "Epoch[1/2] Step[3988] Loss=0.1732\n",
            "Epoch[1/2] Step[3989] Loss=0.4587\n",
            "Epoch[1/2] Step[3990] Loss=0.4236\n",
            "Epoch[1/2] Step[3991] Loss=0.6057\n",
            "Epoch[1/2] Step[3992] Loss=0.4760\n",
            "Epoch[1/2] Step[3993] Loss=0.3538\n",
            "Epoch[1/2] Step[3994] Loss=0.3084\n",
            "Epoch[1/2] Step[3995] Loss=0.1399\n",
            "Epoch[1/2] Step[3996] Loss=0.9490\n",
            "Epoch[1/2] Step[3997] Loss=0.4429\n",
            "Epoch[1/2] Step[3998] Loss=0.0678\n",
            "Epoch[1/2] Step[3999] Loss=0.2541\n",
            "Epoch[1/2] Step[4000] Loss=0.1372\n",
            "Epoch[1/2] Step[4001] Loss=0.4362\n",
            "Epoch[1/2] Step[4002] Loss=0.2162\n",
            "Epoch[1/2] Step[4003] Loss=0.1379\n",
            "Epoch[1/2] Step[4004] Loss=0.1976\n",
            "Epoch[1/2] Step[4005] Loss=0.3299\n",
            "Epoch[1/2] Step[4006] Loss=0.2900\n",
            "Epoch[1/2] Step[4007] Loss=0.1931\n",
            "Epoch[1/2] Step[4008] Loss=0.2449\n",
            "Epoch[1/2] Step[4009] Loss=0.2376\n",
            "Epoch[1/2] Step[4010] Loss=0.1792\n",
            "Epoch[1/2] Step[4011] Loss=0.4064\n",
            "Epoch[1/2] Step[4012] Loss=0.2647\n",
            "Epoch[1/2] Step[4013] Loss=0.3716\n",
            "Epoch[1/2] Step[4014] Loss=0.5123\n",
            "Epoch[1/2] Step[4015] Loss=0.1764\n",
            "Epoch[1/2] Step[4016] Loss=0.4825\n",
            "Epoch[1/2] Step[4017] Loss=0.1168\n",
            "Epoch[1/2] Step[4018] Loss=0.0945\n",
            "Epoch[1/2] Step[4019] Loss=0.6821\n",
            "Epoch[1/2] Step[4020] Loss=0.9770\n",
            "Epoch[1/2] Step[4021] Loss=0.6142\n",
            "Epoch[1/2] Step[4022] Loss=0.5029\n",
            "Epoch[1/2] Step[4023] Loss=0.1561\n",
            "Epoch[1/2] Step[4024] Loss=0.2690\n",
            "Epoch[1/2] Step[4025] Loss=0.1898\n",
            "Epoch[1/2] Step[4026] Loss=0.1123\n",
            "Epoch[1/2] Step[4027] Loss=0.2564\n",
            "Epoch[1/2] Step[4028] Loss=0.8094\n",
            "Epoch[1/2] Step[4029] Loss=0.4693\n",
            "Epoch[1/2] Step[4030] Loss=0.6459\n",
            "Epoch[1/2] Step[4031] Loss=0.4572\n",
            "Epoch[1/2] Step[4032] Loss=0.1265\n",
            "Epoch[1/2] Step[4033] Loss=0.2164\n",
            "Epoch[1/2] Step[4034] Loss=0.1132\n",
            "Epoch[1/2] Step[4035] Loss=0.5395\n",
            "Epoch[1/2] Step[4036] Loss=0.5205\n",
            "Epoch[1/2] Step[4037] Loss=0.1921\n",
            "Epoch[1/2] Step[4038] Loss=0.4878\n",
            "Epoch[1/2] Step[4039] Loss=0.2929\n",
            "Epoch[1/2] Step[4040] Loss=0.7053\n",
            "Epoch[1/2] Step[4041] Loss=0.2593\n",
            "Epoch[1/2] Step[4042] Loss=0.4025\n",
            "Epoch[1/2] Step[4043] Loss=0.1151\n",
            "Epoch[1/2] Step[4044] Loss=0.6577\n",
            "Epoch[1/2] Step[4045] Loss=0.7369\n",
            "Epoch[1/2] Step[4046] Loss=0.4560\n",
            "Epoch[1/2] Step[4047] Loss=0.3062\n",
            "Epoch[1/2] Step[4048] Loss=0.1675\n",
            "Epoch[1/2] Step[4049] Loss=0.1291\n",
            "Epoch[1/2] Step[4050] Loss=0.3391\n",
            "Epoch[1/2] Step[4051] Loss=0.5212\n",
            "Epoch[1/2] Step[4052] Loss=0.1662\n",
            "Epoch[1/2] Step[4053] Loss=0.1974\n",
            "Epoch[1/2] Step[4054] Loss=0.1844\n",
            "Epoch[1/2] Step[4055] Loss=0.4360\n",
            "Epoch[1/2] Step[4056] Loss=0.1476\n",
            "Epoch[1/2] Step[4057] Loss=0.0338\n",
            "Epoch[1/2] Step[4058] Loss=0.4165\n",
            "Epoch[1/2] Step[4059] Loss=0.2887\n",
            "Epoch[1/2] Step[4060] Loss=0.3431\n",
            "Epoch[1/2] Step[4061] Loss=0.0999\n",
            "Epoch[1/2] Step[4062] Loss=0.7462\n",
            "Epoch[1/2] Step[4063] Loss=0.8121\n",
            "Epoch[1/2] Step[4064] Loss=0.2635\n",
            "Epoch[1/2] Step[4065] Loss=0.8025\n",
            "Epoch[1/2] Step[4066] Loss=0.4541\n",
            "Epoch[1/2] Step[4067] Loss=0.4908\n",
            "Epoch[1/2] Step[4068] Loss=0.1656\n",
            "Epoch[1/2] Step[4069] Loss=0.6451\n",
            "Epoch[1/2] Step[4070] Loss=0.4012\n",
            "Epoch[1/2] Step[4071] Loss=0.1737\n",
            "Epoch[1/2] Step[4072] Loss=0.2225\n",
            "Epoch[1/2] Step[4073] Loss=0.8777\n",
            "Epoch[1/2] Step[4074] Loss=0.3585\n",
            "Epoch[1/2] Step[4075] Loss=0.2903\n",
            "Epoch[1/2] Step[4076] Loss=0.1872\n",
            "Epoch[1/2] Step[4077] Loss=0.4951\n",
            "Epoch[1/2] Step[4078] Loss=0.1028\n",
            "Epoch[1/2] Step[4079] Loss=0.1111\n",
            "Epoch[1/2] Step[4080] Loss=0.8044\n",
            "Epoch[1/2] Step[4081] Loss=0.2006\n",
            "Epoch[1/2] Step[4082] Loss=0.1522\n",
            "Epoch[1/2] Step[4083] Loss=0.2077\n",
            "Epoch[1/2] Step[4084] Loss=0.2853\n",
            "Epoch[1/2] Step[4085] Loss=0.2540\n",
            "Epoch[1/2] Step[4086] Loss=0.3846\n",
            "Epoch[1/2] Step[4087] Loss=0.5902\n",
            "Epoch[1/2] Step[4088] Loss=0.0664\n",
            "Epoch[1/2] Step[4089] Loss=0.7940\n",
            "Epoch[1/2] Step[4090] Loss=0.7378\n",
            "Epoch[1/2] Step[4091] Loss=0.1586\n",
            "Epoch[1/2] Step[4092] Loss=0.2798\n",
            "Epoch[1/2] Step[4093] Loss=0.1950\n",
            "Epoch[1/2] Step[4094] Loss=0.1262\n",
            "Epoch[1/2] Step[4095] Loss=0.3147\n",
            "Epoch[1/2] Step[4096] Loss=0.2507\n",
            "Epoch[1/2] Step[4097] Loss=0.2596\n",
            "Epoch[1/2] Step[4098] Loss=0.1235\n",
            "Epoch[1/2] Step[4099] Loss=0.3482\n",
            "Epoch[1/2] Step[4100] Loss=0.5550\n",
            "Epoch[1/2] Step[4101] Loss=0.7063\n",
            "Epoch[1/2] Step[4102] Loss=0.6897\n",
            "Epoch[1/2] Step[4103] Loss=0.5347\n",
            "Epoch[1/2] Step[4104] Loss=0.6652\n",
            "Epoch[1/2] Step[4105] Loss=0.3108\n",
            "Epoch[1/2] Step[4106] Loss=0.0624\n",
            "Epoch[1/2] Step[4107] Loss=0.2731\n",
            "Epoch[1/2] Step[4108] Loss=0.1653\n",
            "Epoch[1/2] Step[4109] Loss=0.4630\n",
            "Epoch[1/2] Step[4110] Loss=0.4005\n",
            "Epoch[1/2] Step[4111] Loss=0.3617\n",
            "Epoch[1/2] Step[4112] Loss=0.1833\n",
            "Epoch[1/2] Step[4113] Loss=0.2362\n",
            "Epoch[1/2] Step[4114] Loss=0.3960\n",
            "Epoch[1/2] Step[4115] Loss=0.8909\n",
            "Epoch[1/2] Step[4116] Loss=0.2804\n",
            "Epoch[1/2] Step[4117] Loss=0.4565\n",
            "Epoch[1/2] Step[4118] Loss=0.7355\n",
            "Epoch[1/2] Step[4119] Loss=0.2532\n",
            "Epoch[1/2] Step[4120] Loss=0.0899\n",
            "Epoch[1/2] Step[4121] Loss=0.1472\n",
            "Epoch[1/2] Step[4122] Loss=0.8540\n",
            "Epoch[1/2] Step[4123] Loss=0.2702\n",
            "Epoch[1/2] Step[4124] Loss=0.9811\n",
            "Epoch[1/2] Step[4125] Loss=0.5684\n",
            "Epoch[1/2] Step[4126] Loss=0.5233\n",
            "Epoch[1/2] Step[4127] Loss=0.1268\n",
            "Epoch[1/2] Step[4128] Loss=0.5442\n",
            "Epoch[1/2] Step[4129] Loss=0.4278\n",
            "Epoch[1/2] Step[4130] Loss=0.0841\n",
            "Epoch[1/2] Step[4131] Loss=0.4374\n",
            "Epoch[1/2] Step[4132] Loss=0.4487\n",
            "Epoch[1/2] Step[4133] Loss=0.2352\n",
            "Epoch[1/2] Step[4134] Loss=0.1061\n",
            "Epoch[1/2] Step[4135] Loss=0.2347\n",
            "Epoch[1/2] Step[4136] Loss=0.2447\n",
            "Epoch[1/2] Step[4137] Loss=0.5377\n",
            "Epoch[1/2] Step[4138] Loss=0.5273\n",
            "Epoch[1/2] Step[4139] Loss=0.1912\n",
            "Epoch[1/2] Step[4140] Loss=0.2461\n",
            "Epoch[1/2] Step[4141] Loss=0.7651\n",
            "Epoch[1/2] Step[4142] Loss=0.5053\n",
            "Epoch[1/2] Step[4143] Loss=0.2980\n",
            "Epoch[1/2] Step[4144] Loss=0.5315\n",
            "Epoch[1/2] Step[4145] Loss=0.5861\n",
            "Epoch[1/2] Step[4146] Loss=0.3916\n",
            "Epoch[1/2] Step[4147] Loss=0.6780\n",
            "Epoch[1/2] Step[4148] Loss=0.3224\n",
            "Epoch[1/2] Step[4149] Loss=0.4283\n",
            "Epoch[1/2] Step[4150] Loss=0.1938\n",
            "Epoch[1/2] Step[4151] Loss=0.2853\n",
            "Epoch[1/2] Step[4152] Loss=0.2642\n",
            "Epoch[1/2] Step[4153] Loss=0.3821\n",
            "Epoch[1/2] Step[4154] Loss=0.1726\n",
            "Epoch[1/2] Step[4155] Loss=0.3766\n",
            "Epoch[1/2] Step[4156] Loss=0.1424\n",
            "Epoch[1/2] Step[4157] Loss=0.3082\n",
            "Epoch[1/2] Step[4158] Loss=0.6418\n",
            "Epoch[1/2] Step[4159] Loss=0.1659\n",
            "Epoch[1/2] Step[4160] Loss=0.4131\n",
            "Epoch[1/2] Step[4161] Loss=0.1376\n",
            "Epoch[1/2] Step[4162] Loss=0.4428\n",
            "Epoch[1/2] Step[4163] Loss=0.9221\n",
            "Epoch[1/2] Step[4164] Loss=0.0711\n",
            "Epoch[1/2] Step[4165] Loss=0.5462\n",
            "Epoch[1/2] Step[4166] Loss=0.3639\n",
            "Epoch[1/2] Step[4167] Loss=0.1688\n",
            "Epoch[1/2] Step[4168] Loss=0.1569\n",
            "Epoch[1/2] Step[4169] Loss=0.3647\n",
            "Epoch[1/2] Step[4170] Loss=0.2282\n",
            "Epoch[1/2] Step[4171] Loss=0.2864\n",
            "Epoch[1/2] Step[4172] Loss=0.3208\n",
            "Epoch[1/2] Step[4173] Loss=0.1707\n",
            "Epoch[1/2] Step[4174] Loss=0.3398\n",
            "Epoch[1/2] Step[4175] Loss=0.3144\n",
            "Epoch[1/2] Step[4176] Loss=0.2630\n",
            "Epoch[1/2] Step[4177] Loss=0.1349\n",
            "Epoch[1/2] Step[4178] Loss=0.6498\n",
            "Epoch[1/2] Step[4179] Loss=0.3537\n",
            "Epoch[1/2] Step[4180] Loss=0.2631\n",
            "Epoch[1/2] Step[4181] Loss=0.9091\n",
            "Epoch[1/2] Step[4182] Loss=0.5785\n",
            "Epoch[1/2] Step[4183] Loss=0.1108\n",
            "Epoch[1/2] Step[4184] Loss=0.6039\n",
            "Epoch[1/2] Step[4185] Loss=0.3039\n",
            "Epoch[1/2] Step[4186] Loss=0.3275\n",
            "Epoch[1/2] Step[4187] Loss=0.1983\n",
            "Epoch[1/2] Step[4188] Loss=0.1402\n",
            "Epoch[1/2] Step[4189] Loss=0.2478\n",
            "Epoch[1/2] Step[4190] Loss=0.2566\n",
            "Epoch[1/2] Step[4191] Loss=0.3245\n",
            "Epoch[1/2] Step[4192] Loss=0.1951\n",
            "Epoch[1/2] Step[4193] Loss=0.4777\n",
            "Epoch[1/2] Step[4194] Loss=0.6024\n",
            "Epoch[1/2] Step[4195] Loss=0.3820\n",
            "Epoch[1/2] Step[4196] Loss=0.4159\n",
            "Epoch[1/2] Step[4197] Loss=0.2235\n",
            "Epoch[1/2] Step[4198] Loss=0.2888\n",
            "Epoch[1/2] Step[4199] Loss=0.1940\n",
            "Epoch[1/2] Step[4200] Loss=0.0944\n",
            "Epoch[1/2] Step[4201] Loss=0.6348\n",
            "Epoch[1/2] Step[4202] Loss=0.1140\n",
            "Epoch[1/2] Step[4203] Loss=0.5878\n",
            "Epoch[1/2] Step[4204] Loss=0.3177\n",
            "Epoch[1/2] Step[4205] Loss=0.2437\n",
            "Epoch[1/2] Step[4206] Loss=0.2425\n",
            "Epoch[1/2] Step[4207] Loss=0.1732\n",
            "Epoch[1/2] Step[4208] Loss=0.7209\n",
            "Epoch[1/2] Step[4209] Loss=0.1343\n",
            "Epoch[1/2] Step[4210] Loss=0.5187\n",
            "Epoch[1/2] Step[4211] Loss=0.2369\n",
            "Epoch[1/2] Step[4212] Loss=0.1970\n",
            "Epoch[1/2] Step[4213] Loss=0.1854\n",
            "Epoch[1/2] Step[4214] Loss=0.3795\n",
            "Epoch[1/2] Step[4215] Loss=0.5417\n",
            "Epoch[1/2] Step[4216] Loss=0.2758\n",
            "Epoch[1/2] Step[4217] Loss=0.3546\n",
            "Epoch[1/2] Step[4218] Loss=0.1695\n",
            "Epoch[1/2] Step[4219] Loss=0.4906\n",
            "Epoch[1/2] Step[4220] Loss=0.3785\n",
            "Epoch[1/2] Step[4221] Loss=0.1506\n",
            "Epoch[1/2] Step[4222] Loss=0.3428\n",
            "Epoch[1/2] Step[4223] Loss=0.6603\n",
            "Epoch[1/2] Step[4224] Loss=0.2194\n",
            "Epoch[1/2] Step[4225] Loss=0.6469\n",
            "Epoch[1/2] Step[4226] Loss=0.3039\n",
            "Epoch[1/2] Step[4227] Loss=0.2727\n",
            "Epoch[1/2] Step[4228] Loss=0.6254\n",
            "Epoch[1/2] Step[4229] Loss=0.4614\n",
            "Epoch[1/2] Step[4230] Loss=0.2730\n",
            "Epoch[1/2] Step[4231] Loss=0.2947\n",
            "Epoch[1/2] Step[4232] Loss=0.4874\n",
            "Epoch[1/2] Step[4233] Loss=0.1618\n",
            "Epoch[1/2] Step[4234] Loss=0.7561\n",
            "Epoch[1/2] Step[4235] Loss=0.2467\n",
            "Epoch[1/2] Step[4236] Loss=0.4946\n",
            "Epoch[1/2] Step[4237] Loss=0.0993\n",
            "Epoch[1/2] Step[4238] Loss=0.4674\n",
            "Epoch[1/2] Step[4239] Loss=0.1717\n",
            "Epoch[1/2] Step[4240] Loss=0.3152\n",
            "Epoch[1/2] Step[4241] Loss=0.6087\n",
            "Epoch[1/2] Step[4242] Loss=0.4942\n",
            "Epoch[1/2] Step[4243] Loss=0.3290\n",
            "Epoch[1/2] Step[4244] Loss=0.1418\n",
            "Epoch[1/2] Step[4245] Loss=0.3695\n",
            "Epoch[1/2] Step[4246] Loss=0.1481\n",
            "Epoch[1/2] Step[4247] Loss=0.1384\n",
            "Epoch[1/2] Step[4248] Loss=0.1625\n",
            "Epoch[1/2] Step[4249] Loss=0.5004\n",
            "Epoch[1/2] Step[4250] Loss=0.3739\n",
            "Epoch[1/2] Step[4251] Loss=0.1179\n",
            "Epoch[1/2] Step[4252] Loss=0.3927\n",
            "Epoch[1/2] Step[4253] Loss=0.2102\n",
            "Epoch[1/2] Step[4254] Loss=0.4819\n",
            "Epoch[1/2] Step[4255] Loss=0.7407\n",
            "Epoch[1/2] Step[4256] Loss=0.4351\n",
            "Epoch[1/2] Step[4257] Loss=0.1865\n",
            "Epoch[1/2] Step[4258] Loss=0.8807\n",
            "Epoch[1/2] Step[4259] Loss=0.2309\n",
            "Epoch[1/2] Step[4260] Loss=0.2295\n",
            "Epoch[1/2] Step[4261] Loss=0.4174\n",
            "Epoch[1/2] Step[4262] Loss=0.2891\n",
            "Epoch[1/2] Step[4263] Loss=0.4649\n",
            "Epoch[1/2] Step[4264] Loss=0.3846\n",
            "Epoch[1/2] Step[4265] Loss=0.3579\n",
            "Epoch[1/2] Step[4266] Loss=0.8015\n",
            "Epoch[1/2] Step[4267] Loss=0.2387\n",
            "Epoch[1/2] Step[4268] Loss=0.3239\n",
            "Epoch[1/2] Step[4269] Loss=0.2326\n",
            "Epoch[1/2] Step[4270] Loss=0.2184\n",
            "Epoch[1/2] Step[4271] Loss=0.4661\n",
            "Epoch[1/2] Step[4272] Loss=0.1701\n",
            "Epoch[1/2] Step[4273] Loss=0.2682\n",
            "Epoch[1/2] Step[4274] Loss=0.6154\n",
            "Epoch[1/2] Step[4275] Loss=0.2972\n",
            "Epoch[1/2] Step[4276] Loss=0.4255\n",
            "Epoch[1/2] Step[4277] Loss=0.1541\n",
            "Epoch[1/2] Step[4278] Loss=0.6048\n",
            "Epoch[1/2] Step[4279] Loss=0.1529\n",
            "Epoch[1/2] Step[4280] Loss=0.3368\n",
            "Epoch[1/2] Step[4281] Loss=0.1114\n",
            "Epoch[1/2] Step[4282] Loss=0.3895\n",
            "Epoch[1/2] Step[4283] Loss=0.5641\n",
            "Epoch[1/2] Step[4284] Loss=0.4347\n",
            "Epoch[1/2] Step[4285] Loss=0.1976\n",
            "Epoch[1/2] Step[4286] Loss=0.0809\n",
            "Epoch[1/2] Step[4287] Loss=0.2068\n",
            "Epoch[1/2] Step[4288] Loss=0.4272\n",
            "Epoch[1/2] Step[4289] Loss=0.2271\n",
            "Epoch[1/2] Step[4290] Loss=0.1274\n",
            "Epoch[1/2] Step[4291] Loss=0.2634\n",
            "Epoch[1/2] Step[4292] Loss=0.1743\n",
            "Epoch[1/2] Step[4293] Loss=0.0947\n",
            "Epoch[1/2] Step[4294] Loss=0.1407\n",
            "Epoch[1/2] Step[4295] Loss=0.5114\n",
            "Epoch[1/2] Step[4296] Loss=0.4066\n",
            "Epoch[1/2] Step[4297] Loss=0.1279\n",
            "Epoch[1/2] Step[4298] Loss=0.4877\n",
            "Epoch[1/2] Step[4299] Loss=0.0974\n",
            "Epoch[1/2] Step[4300] Loss=0.6134\n",
            "Epoch[1/2] Step[4301] Loss=0.1502\n",
            "Epoch[1/2] Step[4302] Loss=0.1320\n",
            "Epoch[1/2] Step[4303] Loss=0.4392\n",
            "Epoch[1/2] Step[4304] Loss=0.9825\n",
            "Epoch[1/2] Step[4305] Loss=0.3855\n",
            "Epoch[1/2] Step[4306] Loss=0.2354\n",
            "Epoch[1/2] Step[4307] Loss=0.2600\n",
            "Epoch[1/2] Step[4308] Loss=0.6821\n",
            "Epoch[1/2] Step[4309] Loss=0.3802\n",
            "Epoch[1/2] Step[4310] Loss=0.7325\n",
            "Epoch[1/2] Step[4311] Loss=0.3088\n",
            "Epoch[1/2] Step[4312] Loss=0.3250\n",
            "Epoch[1/2] Step[4313] Loss=0.0777\n",
            "Epoch[1/2] Step[4314] Loss=0.2787\n",
            "Epoch[1/2] Step[4315] Loss=0.3322\n",
            "Epoch[1/2] Step[4316] Loss=0.2218\n",
            "Epoch[1/2] Step[4317] Loss=0.1334\n",
            "Epoch[1/2] Step[4318] Loss=0.1202\n",
            "Epoch[1/2] Step[4319] Loss=0.2764\n",
            "Epoch[1/2] Step[4320] Loss=0.2732\n",
            "Epoch[1/2] Step[4321] Loss=0.1311\n",
            "Epoch[1/2] Step[4322] Loss=0.2759\n",
            "Epoch[1/2] Step[4323] Loss=0.1419\n",
            "Epoch[1/2] Step[4324] Loss=0.2616\n",
            "Epoch[1/2] Step[4325] Loss=0.8730\n",
            "Epoch[1/2] Step[4326] Loss=1.1474\n",
            "Epoch[1/2] Step[4327] Loss=0.9962\n",
            "Epoch[1/2] Step[4328] Loss=0.9204\n",
            "Epoch[1/2] Step[4329] Loss=0.3636\n",
            "Epoch[1/2] Step[4330] Loss=0.1547\n",
            "Epoch[1/2] Step[4331] Loss=0.4965\n",
            "Epoch[1/2] Step[4332] Loss=0.2927\n",
            "Epoch[1/2] Step[4333] Loss=0.4927\n",
            "Epoch[1/2] Step[4334] Loss=0.2601\n",
            "Epoch[1/2] Step[4335] Loss=0.3859\n",
            "Epoch[1/2] Step[4336] Loss=0.9027\n",
            "Epoch[1/2] Step[4337] Loss=0.0967\n",
            "Epoch[1/2] Step[4338] Loss=0.4410\n",
            "Epoch[1/2] Step[4339] Loss=0.2222\n",
            "Epoch[1/2] Step[4340] Loss=0.2312\n",
            "Epoch[1/2] Step[4341] Loss=0.7010\n",
            "Epoch[1/2] Step[4342] Loss=0.4044\n",
            "Epoch[1/2] Step[4343] Loss=0.1381\n",
            "Epoch[1/2] Step[4344] Loss=0.0744\n",
            "Epoch[1/2] Step[4345] Loss=0.5936\n",
            "Epoch[1/2] Step[4346] Loss=0.3306\n",
            "Epoch[1/2] Step[4347] Loss=0.1791\n",
            "Epoch[1/2] Step[4348] Loss=0.2155\n",
            "Epoch[1/2] Step[4349] Loss=0.4450\n",
            "Epoch[1/2] Step[4350] Loss=0.4258\n",
            "Epoch[1/2] Step[4351] Loss=0.5970\n",
            "Epoch[1/2] Step[4352] Loss=0.1388\n",
            "Epoch[1/2] Step[4353] Loss=0.3845\n",
            "Epoch[1/2] Step[4354] Loss=0.2850\n",
            "Epoch[1/2] Step[4355] Loss=0.3248\n",
            "Epoch[1/2] Step[4356] Loss=0.5129\n",
            "Epoch[1/2] Step[4357] Loss=0.4003\n",
            "Epoch[1/2] Step[4358] Loss=0.1737\n",
            "Epoch[1/2] Step[4359] Loss=0.6323\n",
            "Epoch[1/2] Step[4360] Loss=0.1205\n",
            "Epoch[1/2] Step[4361] Loss=0.5613\n",
            "Epoch[1/2] Step[4362] Loss=0.4991\n",
            "Epoch[1/2] Step[4363] Loss=0.2203\n",
            "Epoch[1/2] Step[4364] Loss=0.6461\n",
            "Epoch[1/2] Step[4365] Loss=0.1754\n",
            "Epoch[1/2] Step[4366] Loss=0.7520\n",
            "Epoch[1/2] Step[4367] Loss=0.1754\n",
            "Epoch[1/2] Step[4368] Loss=0.3577\n",
            "Epoch[1/2] Step[4369] Loss=0.2589\n",
            "Epoch[1/2] Step[4370] Loss=0.3074\n",
            "Epoch[1/2] Step[4371] Loss=0.2438\n",
            "Epoch[1/2] Step[4372] Loss=0.2352\n",
            "Epoch[1/2] Step[4373] Loss=0.3427\n",
            "Epoch[1/2] Step[4374] Loss=0.1973\n",
            "Epoch[1/2] Step[4375] Loss=0.3054\n",
            "Epoch[1/2] Step[4376] Loss=0.3765\n",
            "Epoch[1/2] Step[4377] Loss=0.7854\n",
            "Epoch[1/2] Step[4378] Loss=0.3985\n",
            "Epoch[1/2] Step[4379] Loss=0.2755\n",
            "Epoch[1/2] Step[4380] Loss=0.3736\n",
            "Epoch[1/2] Step[4381] Loss=0.0874\n",
            "Epoch[1/2] Step[4382] Loss=0.1959\n",
            "Epoch[1/2] Step[4383] Loss=0.5709\n",
            "Epoch[1/2] Step[4384] Loss=0.2164\n",
            "Epoch[1/2] Step[4385] Loss=0.4870\n",
            "Epoch[1/2] Step[4386] Loss=0.4064\n",
            "Epoch[1/2] Step[4387] Loss=0.3431\n",
            "Epoch[1/2] Step[4388] Loss=0.1328\n",
            "Epoch[1/2] Step[4389] Loss=0.1629\n",
            "Epoch[1/2] Step[4390] Loss=0.2153\n",
            "Epoch[1/2] Step[4391] Loss=0.4230\n",
            "Epoch[1/2] Step[4392] Loss=0.2412\n",
            "Epoch[1/2] Step[4393] Loss=0.1219\n",
            "Epoch[1/2] Step[4394] Loss=0.1621\n",
            "Epoch[1/2] Step[4395] Loss=0.1686\n",
            "Epoch[1/2] Step[4396] Loss=0.3332\n",
            "Epoch[1/2] Step[4397] Loss=0.2705\n",
            "Epoch[1/2] Step[4398] Loss=0.3890\n",
            "Epoch[1/2] Step[4399] Loss=0.1820\n",
            "Epoch[1/2] Step[4400] Loss=0.3564\n",
            "Epoch[1/2] Step[4401] Loss=0.1813\n",
            "Epoch[1/2] Step[4402] Loss=0.8353\n",
            "Epoch[1/2] Step[4403] Loss=0.1546\n",
            "Epoch[1/2] Step[4404] Loss=0.8863\n",
            "Epoch[1/2] Step[4405] Loss=0.4491\n",
            "Epoch[1/2] Step[4406] Loss=0.2493\n",
            "Epoch[1/2] Step[4407] Loss=0.3728\n",
            "Epoch[1/2] Step[4408] Loss=0.1894\n",
            "Epoch[1/2] Step[4409] Loss=0.3071\n",
            "Epoch[1/2] Step[4410] Loss=0.6021\n",
            "Epoch[1/2] Step[4411] Loss=0.3568\n",
            "Epoch[1/2] Step[4412] Loss=1.0488\n",
            "Epoch[1/2] Step[4413] Loss=0.2611\n",
            "Epoch[1/2] Step[4414] Loss=0.2394\n",
            "Epoch[1/2] Step[4415] Loss=0.4166\n",
            "Epoch[1/2] Step[4416] Loss=0.4377\n",
            "Epoch[1/2] Step[4417] Loss=0.3322\n",
            "Epoch[1/2] Step[4418] Loss=0.5926\n",
            "Epoch[1/2] Step[4419] Loss=0.2643\n",
            "Epoch[1/2] Step[4420] Loss=0.3214\n",
            "Epoch[1/2] Step[4421] Loss=0.0613\n",
            "Epoch[1/2] Step[4422] Loss=0.2359\n",
            "Epoch[1/2] Step[4423] Loss=0.4934\n",
            "Epoch[1/2] Step[4424] Loss=0.1982\n",
            "Epoch[1/2] Step[4425] Loss=0.4463\n",
            "Epoch[1/2] Step[4426] Loss=0.7101\n",
            "Epoch[1/2] Step[4427] Loss=0.5465\n",
            "Epoch[1/2] Step[4428] Loss=0.5816\n",
            "Epoch[1/2] Step[4429] Loss=0.4235\n",
            "Epoch[1/2] Step[4430] Loss=0.3447\n",
            "Epoch[1/2] Step[4431] Loss=0.2058\n",
            "Epoch[1/2] Step[4432] Loss=0.3177\n",
            "Epoch[1/2] Step[4433] Loss=0.3185\n",
            "Epoch[1/2] Step[4434] Loss=0.1626\n",
            "Epoch[1/2] Step[4435] Loss=0.2026\n",
            "Epoch[1/2] Step[4436] Loss=0.3864\n",
            "Epoch[1/2] Step[4437] Loss=0.3031\n",
            "Epoch[1/2] Step[4438] Loss=0.5619\n",
            "Epoch[1/2] Step[4439] Loss=0.5062\n",
            "Epoch[1/2] Step[4440] Loss=0.3952\n",
            "Epoch[1/2] Step[4441] Loss=0.2297\n",
            "Epoch[1/2] Step[4442] Loss=0.3815\n",
            "Epoch[1/2] Step[4443] Loss=0.2123\n",
            "Epoch[1/2] Step[4444] Loss=0.3732\n",
            "Epoch[1/2] Step[4445] Loss=0.5147\n",
            "Epoch[1/2] Step[4446] Loss=0.2170\n",
            "Epoch[1/2] Step[4447] Loss=0.7092\n",
            "Epoch[1/2] Step[4448] Loss=0.4227\n",
            "Epoch[1/2] Step[4449] Loss=0.3266\n",
            "Epoch[1/2] Step[4450] Loss=0.4525\n",
            "Epoch[1/2] Step[4451] Loss=0.2075\n",
            "Epoch[1/2] Step[4452] Loss=0.2505\n",
            "Epoch[1/2] Step[4453] Loss=0.3879\n",
            "Epoch[1/2] Step[4454] Loss=0.1398\n",
            "Epoch[1/2] Step[4455] Loss=0.7609\n",
            "Epoch[1/2] Step[4456] Loss=0.6629\n",
            "Epoch[1/2] Step[4457] Loss=0.3864\n",
            "Epoch[1/2] Step[4458] Loss=0.3921\n",
            "Epoch[1/2] Step[4459] Loss=0.2141\n",
            "Epoch[1/2] Step[4460] Loss=0.7961\n",
            "Epoch[1/2] Step[4461] Loss=0.2046\n",
            "Epoch[1/2] Step[4462] Loss=0.3884\n",
            "Epoch[1/2] Step[4463] Loss=0.1269\n",
            "Epoch[1/2] Step[4464] Loss=0.7822\n",
            "Epoch[1/2] Step[4465] Loss=0.3708\n",
            "Epoch[1/2] Step[4466] Loss=0.2853\n",
            "Epoch[1/2] Step[4467] Loss=0.3035\n",
            "Epoch[1/2] Step[4468] Loss=0.3527\n",
            "Epoch[1/2] Step[4469] Loss=0.1904\n",
            "Epoch[1/2] Step[4470] Loss=0.3843\n",
            "Epoch[1/2] Step[4471] Loss=0.1026\n",
            "Epoch[1/2] Step[4472] Loss=0.3836\n",
            "Epoch[1/2] Step[4473] Loss=0.3851\n",
            "Epoch[1/2] Step[4474] Loss=0.1547\n",
            "Epoch[1/2] Step[4475] Loss=0.3898\n",
            "Epoch[1/2] Step[4476] Loss=0.4576\n",
            "Epoch[1/2] Step[4477] Loss=0.4497\n",
            "Epoch[1/2] Step[4478] Loss=0.1203\n",
            "Epoch[1/2] Step[4479] Loss=0.2509\n",
            "Epoch[1/2] Step[4480] Loss=0.3642\n",
            "Epoch[1/2] Step[4481] Loss=0.0696\n",
            "Epoch[1/2] Step[4482] Loss=0.6031\n",
            "Epoch[1/2] Step[4483] Loss=0.5909\n",
            "Epoch[1/2] Step[4484] Loss=0.6425\n",
            "Epoch[1/2] Step[4485] Loss=0.6204\n",
            "Epoch[1/2] Step[4486] Loss=0.3183\n",
            "Epoch[1/2] Step[4487] Loss=0.3713\n",
            "Epoch[1/2] Step[4488] Loss=0.1395\n",
            "Epoch[1/2] Step[4489] Loss=0.1223\n",
            "Epoch[1/2] Step[4490] Loss=0.5175\n",
            "Epoch[1/2] Step[4491] Loss=0.0842\n",
            "Epoch[1/2] Step[4492] Loss=0.2680\n",
            "Epoch[1/2] Step[4493] Loss=0.1437\n",
            "Epoch[1/2] Step[4494] Loss=0.1944\n",
            "Epoch[1/2] Step[4495] Loss=0.4717\n",
            "Epoch[1/2] Step[4496] Loss=0.4398\n",
            "Epoch[1/2] Step[4497] Loss=0.2253\n",
            "Epoch[1/2] Step[4498] Loss=0.5707\n",
            "Epoch[1/2] Step[4499] Loss=0.3434\n",
            "Epoch[1/2] Step[4500] Loss=0.3954\n",
            "Epoch[1/2] Step[4501] Loss=0.3371\n",
            "Epoch[1/2] Step[4502] Loss=0.5640\n",
            "Epoch[1/2] Step[4503] Loss=0.1654\n",
            "Epoch[1/2] Step[4504] Loss=0.1669\n",
            "Epoch[1/2] Step[4505] Loss=0.0798\n",
            "Epoch[1/2] Step[4506] Loss=0.5062\n",
            "Epoch[1/2] Step[4507] Loss=0.5612\n",
            "Epoch[1/2] Step[4508] Loss=0.5322\n",
            "Epoch[1/2] Step[4509] Loss=0.6205\n",
            "Epoch[1/2] Step[4510] Loss=0.5120\n",
            "Epoch[1/2] Step[4511] Loss=0.4012\n",
            "Epoch[1/2] Step[4512] Loss=0.7448\n",
            "Epoch[1/2] Step[4513] Loss=0.2870\n",
            "Epoch[1/2] Step[4514] Loss=0.2229\n",
            "Epoch[1/2] Step[4515] Loss=0.2224\n",
            "Epoch[1/2] Step[4516] Loss=0.6921\n",
            "Epoch[1/2] Step[4517] Loss=0.1274\n",
            "Epoch[1/2] Step[4518] Loss=0.2815\n",
            "Epoch[1/2] Step[4519] Loss=0.5602\n",
            "Epoch[1/2] Step[4520] Loss=0.5348\n",
            "Epoch[1/2] Step[4521] Loss=0.0570\n",
            "Epoch[1/2] Step[4522] Loss=0.5989\n",
            "Epoch[1/2] Step[4523] Loss=0.1116\n",
            "Epoch[1/2] Step[4524] Loss=0.2918\n",
            "Epoch[1/2] Step[4525] Loss=0.5551\n",
            "Epoch[1/2] Step[4526] Loss=0.5971\n",
            "Epoch[1/2] Step[4527] Loss=0.3648\n",
            "Epoch[1/2] Step[4528] Loss=0.4375\n",
            "Epoch[1/2] Step[4529] Loss=0.1038\n",
            "Epoch[1/2] Step[4530] Loss=0.3235\n",
            "Epoch[1/2] Step[4531] Loss=0.2024\n",
            "Epoch[1/2] Step[4532] Loss=0.3177\n",
            "Epoch[1/2] Step[4533] Loss=0.2862\n",
            "Epoch[1/2] Step[4534] Loss=0.1543\n",
            "Epoch[1/2] Step[4535] Loss=0.1157\n",
            "Epoch[1/2] Step[4536] Loss=0.3930\n",
            "Epoch[1/2] Step[4537] Loss=0.1033\n",
            "Epoch[1/2] Step[4538] Loss=0.5411\n",
            "Epoch[1/2] Step[4539] Loss=0.1807\n",
            "Epoch[1/2] Step[4540] Loss=0.2406\n",
            "Epoch[1/2] Step[4541] Loss=0.1141\n",
            "Epoch[1/2] Step[4542] Loss=0.2025\n",
            "Epoch[1/2] Step[4543] Loss=0.2525\n",
            "Epoch[1/2] Step[4544] Loss=0.7290\n",
            "Epoch[1/2] Step[4545] Loss=0.1049\n",
            "Epoch[1/2] Step[4546] Loss=0.6331\n",
            "Epoch[1/2] Step[4547] Loss=0.1103\n",
            "Epoch[1/2] Step[4548] Loss=0.2106\n",
            "Epoch[1/2] Step[4549] Loss=0.3190\n",
            "Epoch[1/2] Step[4550] Loss=0.1294\n",
            "Epoch[1/2] Step[4551] Loss=0.3552\n",
            "Epoch[1/2] Step[4552] Loss=0.2332\n",
            "Epoch[1/2] Step[4553] Loss=0.2233\n",
            "Epoch[1/2] Step[4554] Loss=0.2993\n",
            "Epoch[1/2] Step[4555] Loss=0.2127\n",
            "Epoch[1/2] Step[4556] Loss=0.9568\n",
            "Epoch[1/2] Step[4557] Loss=0.7230\n",
            "Epoch[1/2] Step[4558] Loss=0.1051\n",
            "Epoch[1/2] Step[4559] Loss=0.2689\n",
            "Epoch[1/2] Step[4560] Loss=0.3245\n",
            "Epoch[1/2] Step[4561] Loss=0.5895\n",
            "Epoch[1/2] Step[4562] Loss=0.3301\n",
            "Epoch[1/2] Step[4563] Loss=0.1269\n",
            "Epoch[1/2] Step[4564] Loss=0.2876\n",
            "Epoch[1/2] Step[4565] Loss=0.3898\n",
            "Epoch[1/2] Step[4566] Loss=0.1879\n",
            "Epoch[1/2] Step[4567] Loss=0.7739\n",
            "Epoch[1/2] Step[4568] Loss=0.4151\n",
            "Epoch[1/2] Step[4569] Loss=0.3406\n",
            "Epoch[1/2] Step[4570] Loss=0.1771\n",
            "Epoch[1/2] Step[4571] Loss=0.4832\n",
            "Epoch[1/2] Step[4572] Loss=0.1437\n",
            "Epoch[1/2] Step[4573] Loss=0.2161\n",
            "Epoch[1/2] Step[4574] Loss=0.1275\n",
            "Epoch[1/2] Step[4575] Loss=0.1980\n",
            "Epoch[1/2] Step[4576] Loss=0.2277\n",
            "Epoch[1/2] Step[4577] Loss=0.6094\n",
            "Epoch[1/2] Step[4578] Loss=0.2334\n",
            "Epoch[1/2] Step[4579] Loss=0.2578\n",
            "Epoch[1/2] Step[4580] Loss=0.2093\n",
            "Epoch[1/2] Step[4581] Loss=0.3070\n",
            "Epoch[1/2] Step[4582] Loss=0.3916\n",
            "Epoch[1/2] Step[4583] Loss=0.0728\n",
            "Epoch[1/2] Step[4584] Loss=0.3743\n",
            "Epoch[1/2] Step[4585] Loss=0.2545\n",
            "Epoch[1/2] Step[4586] Loss=0.1360\n",
            "Epoch[1/2] Step[4587] Loss=0.8334\n",
            "Epoch[1/2] Step[4588] Loss=0.6620\n",
            "Epoch[1/2] Step[4589] Loss=0.1784\n",
            "Epoch[1/2] Step[4590] Loss=0.0930\n",
            "Epoch[1/2] Step[4591] Loss=0.3574\n",
            "Epoch[1/2] Step[4592] Loss=0.2154\n",
            "Epoch[1/2] Step[4593] Loss=0.2211\n",
            "Epoch[1/2] Step[4594] Loss=0.2023\n",
            "Epoch[1/2] Step[4595] Loss=0.1691\n",
            "Epoch[1/2] Step[4596] Loss=0.8493\n",
            "Epoch[1/2] Step[4597] Loss=0.2803\n",
            "Epoch[1/2] Step[4598] Loss=0.5354\n",
            "Epoch[1/2] Step[4599] Loss=0.2995\n",
            "Epoch[1/2] Step[4600] Loss=0.1487\n",
            "Epoch[1/2] Step[4601] Loss=0.2235\n",
            "Epoch[1/2] Step[4602] Loss=0.3354\n",
            "Epoch[1/2] Step[4603] Loss=0.0975\n",
            "Epoch[1/2] Step[4604] Loss=0.1651\n",
            "Epoch[1/2] Step[4605] Loss=0.3486\n",
            "Epoch[1/2] Step[4606] Loss=0.2248\n",
            "Epoch[1/2] Step[4607] Loss=0.7604\n",
            "Epoch[1/2] Step[4608] Loss=0.1504\n",
            "Epoch[1/2] Step[4609] Loss=0.1979\n",
            "Epoch[1/2] Step[4610] Loss=0.1332\n",
            "Epoch[1/2] Step[4611] Loss=0.0523\n",
            "Epoch[1/2] Step[4612] Loss=0.3361\n",
            "Epoch[1/2] Step[4613] Loss=0.3389\n",
            "Epoch[1/2] Step[4614] Loss=0.3594\n",
            "Epoch[1/2] Step[4615] Loss=0.1806\n",
            "Epoch[1/2] Step[4616] Loss=0.2265\n",
            "Epoch[1/2] Step[4617] Loss=0.4028\n",
            "Epoch[1/2] Step[4618] Loss=0.0872\n",
            "Epoch[1/2] Step[4619] Loss=0.5314\n",
            "Epoch[1/2] Step[4620] Loss=0.5045\n",
            "Epoch[1/2] Step[4621] Loss=0.3799\n",
            "Epoch[1/2] Step[4622] Loss=0.7516\n",
            "Epoch[1/2] Step[4623] Loss=0.1053\n",
            "Epoch[1/2] Step[4624] Loss=0.3613\n",
            "Epoch[1/2] Step[4625] Loss=0.3860\n",
            "Epoch[1/2] Step[4626] Loss=0.3859\n",
            "Epoch[1/2] Step[4627] Loss=0.3205\n",
            "Epoch[1/2] Step[4628] Loss=0.2150\n",
            "Epoch[1/2] Step[4629] Loss=0.0923\n",
            "Epoch[1/2] Step[4630] Loss=0.1299\n",
            "Epoch[1/2] Step[4631] Loss=0.2053\n",
            "Epoch[1/2] Step[4632] Loss=0.6783\n",
            "Epoch[1/2] Step[4633] Loss=0.1708\n",
            "Epoch[1/2] Step[4634] Loss=0.4159\n",
            "Epoch[1/2] Step[4635] Loss=0.4585\n",
            "Epoch[1/2] Step[4636] Loss=0.1432\n",
            "Epoch[1/2] Step[4637] Loss=0.1156\n",
            "Epoch[1/2] Step[4638] Loss=0.2069\n",
            "Epoch[1/2] Step[4639] Loss=0.3275\n",
            "Epoch[1/2] Step[4640] Loss=0.1745\n",
            "Epoch[1/2] Step[4641] Loss=0.2767\n",
            "Epoch[1/2] Step[4642] Loss=0.2092\n",
            "Epoch[1/2] Step[4643] Loss=0.4034\n",
            "Epoch[1/2] Step[4644] Loss=0.5463\n",
            "Epoch[1/2] Step[4645] Loss=0.0872\n",
            "Epoch[1/2] Step[4646] Loss=0.7588\n",
            "Epoch[1/2] Step[4647] Loss=0.6690\n",
            "Epoch[1/2] Step[4648] Loss=0.7560\n",
            "Epoch[1/2] Step[4649] Loss=0.4571\n",
            "Epoch[1/2] Step[4650] Loss=0.4476\n",
            "Epoch[1/2] Step[4651] Loss=0.1249\n",
            "Epoch[1/2] Step[4652] Loss=0.0431\n",
            "Epoch[1/2] Step[4653] Loss=0.4085\n",
            "Epoch[1/2] Step[4654] Loss=0.1136\n",
            "Epoch[1/2] Step[4655] Loss=0.4810\n",
            "Epoch[1/2] Step[4656] Loss=0.2301\n",
            "Epoch[1/2] Step[4657] Loss=0.4969\n",
            "Epoch[1/2] Step[4658] Loss=0.2803\n",
            "Epoch[1/2] Step[4659] Loss=0.5646\n",
            "Epoch[1/2] Step[4660] Loss=0.3866\n",
            "Epoch[1/2] Step[4661] Loss=0.3506\n",
            "Epoch[1/2] Step[4662] Loss=0.1524\n",
            "Epoch[1/2] Step[4663] Loss=0.4711\n",
            "Epoch[1/2] Step[4664] Loss=0.4529\n",
            "Epoch[1/2] Step[4665] Loss=0.6189\n",
            "Epoch[1/2] Step[4666] Loss=0.1562\n",
            "Epoch[1/2] Step[4667] Loss=0.2359\n",
            "Epoch[1/2] Step[4668] Loss=0.4161\n",
            "Epoch[1/2] Step[4669] Loss=0.2412\n",
            "Epoch[1/2] Step[4670] Loss=0.2300\n",
            "Epoch[1/2] Step[4671] Loss=0.0833\n",
            "Epoch[1/2] Step[4672] Loss=0.2095\n",
            "Epoch[1/2] Step[4673] Loss=0.5859\n",
            "Epoch[1/2] Step[4674] Loss=0.1869\n",
            "Epoch[1/2] Step[4675] Loss=0.7426\n",
            "Epoch[1/2] Step[4676] Loss=0.6220\n",
            "Epoch[1/2] Step[4677] Loss=0.4291\n",
            "Epoch[1/2] Step[4678] Loss=0.3549\n",
            "Epoch[1/2] Step[4679] Loss=0.4894\n",
            "Epoch[1/2] Step[4680] Loss=0.2165\n",
            "Epoch[1/2] Step[4681] Loss=0.1129\n",
            "Epoch[1/2] Step[4682] Loss=0.2815\n",
            "Epoch[1/2] Step[4683] Loss=0.4480\n",
            "Epoch[1/2] Step[4684] Loss=0.1482\n",
            "Epoch[1/2] Step[4685] Loss=0.1956\n",
            "Epoch[1/2] Step[4686] Loss=0.6718\n",
            "Epoch[1/2] Step[4687] Loss=0.7090\n",
            "Epoch[1/2] Step[4688] Loss=0.3427\n",
            "Epoch[1/2] Step[4689] Loss=0.1075\n",
            "Epoch[1/2] Step[4690] Loss=0.4488\n",
            "Epoch[1/2] Step[4691] Loss=0.3805\n",
            "Epoch[1/2] Step[4692] Loss=0.5627\n",
            "Epoch[1/2] Step[4693] Loss=0.2380\n",
            "Epoch[1/2] Step[4694] Loss=0.5239\n",
            "Epoch[1/2] Step[4695] Loss=0.2392\n",
            "Epoch[1/2] Step[4696] Loss=0.1548\n",
            "Epoch[1/2] Step[4697] Loss=0.9348\n",
            "Epoch[1/2] Step[4698] Loss=0.7347\n",
            "Epoch[1/2] Step[4699] Loss=0.1084\n",
            "Epoch[1/2] Step[4700] Loss=0.4092\n",
            "Epoch[1/2] Step[4701] Loss=0.2680\n",
            "Epoch[1/2] Step[4702] Loss=0.4101\n",
            "Epoch[1/2] Step[4703] Loss=0.3303\n",
            "Epoch[1/2] Step[4704] Loss=0.3798\n",
            "Epoch[1/2] Step[4705] Loss=0.1216\n",
            "Epoch[1/2] Step[4706] Loss=0.1862\n",
            "Epoch[1/2] Step[4707] Loss=0.5139\n",
            "Epoch[1/2] Step[4708] Loss=0.1840\n",
            "Epoch[1/2] Step[4709] Loss=0.4800\n",
            "Epoch[1/2] Step[4710] Loss=0.0955\n",
            "Epoch[1/2] Step[4711] Loss=0.1389\n",
            "Epoch[1/2] Step[4712] Loss=0.1717\n",
            "Epoch[1/2] Step[4713] Loss=0.7341\n",
            "Epoch[1/2] Step[4714] Loss=0.5629\n",
            "Epoch[1/2] Step[4715] Loss=0.1665\n",
            "Epoch[1/2] Step[4716] Loss=0.2377\n",
            "Epoch[1/2] Step[4717] Loss=0.4038\n",
            "Epoch[1/2] Step[4718] Loss=0.2855\n",
            "Epoch[1/2] Step[4719] Loss=0.7021\n",
            "Epoch[1/2] Step[4720] Loss=0.4322\n",
            "Epoch[1/2] Step[4721] Loss=0.2497\n",
            "Epoch[1/2] Step[4722] Loss=0.2002\n",
            "Epoch[1/2] Step[4723] Loss=0.1788\n",
            "Epoch[1/2] Step[4724] Loss=0.2441\n",
            "Epoch[1/2] Step[4725] Loss=0.3613\n",
            "Epoch[1/2] Step[4726] Loss=0.1471\n",
            "Epoch[1/2] Step[4727] Loss=0.5593\n",
            "Epoch[1/2] Step[4728] Loss=0.7247\n",
            "Epoch[1/2] Step[4729] Loss=0.2231\n",
            "Epoch[1/2] Step[4730] Loss=0.1307\n",
            "Epoch[1/2] Step[4731] Loss=0.3636\n",
            "Epoch[1/2] Step[4732] Loss=0.1254\n",
            "Epoch[1/2] Step[4733] Loss=0.7192\n",
            "Epoch[1/2] Step[4734] Loss=0.4380\n",
            "Epoch[1/2] Step[4735] Loss=0.6093\n",
            "Epoch[1/2] Step[4736] Loss=0.1235\n",
            "Epoch[1/2] Step[4737] Loss=0.4561\n",
            "Epoch[1/2] Step[4738] Loss=0.1990\n",
            "Epoch[1/2] Step[4739] Loss=0.5518\n",
            "Epoch[1/2] Step[4740] Loss=0.2247\n",
            "Epoch[1/2] Step[4741] Loss=0.4037\n",
            "Epoch[1/2] Step[4742] Loss=0.4369\n",
            "Epoch[1/2] Step[4743] Loss=0.3245\n",
            "Epoch[1/2] Step[4744] Loss=0.3718\n",
            "Epoch[1/2] Step[4745] Loss=0.0758\n",
            "Epoch[1/2] Step[4746] Loss=0.3330\n",
            "Epoch[1/2] Step[4747] Loss=0.1738\n",
            "Epoch[1/2] Step[4748] Loss=0.1735\n",
            "Epoch[1/2] Step[4749] Loss=1.0531\n",
            "Epoch[1/2] Step[4750] Loss=0.1049\n",
            "Epoch[1/2] Step[4751] Loss=0.2532\n",
            "Epoch[1/2] Step[4752] Loss=0.0590\n",
            "Epoch[1/2] Step[4753] Loss=0.0888\n",
            "Epoch[1/2] Step[4754] Loss=0.2799\n",
            "Epoch[1/2] Step[4755] Loss=0.2988\n",
            "Epoch[1/2] Step[4756] Loss=0.0616\n",
            "Epoch[1/2] Step[4757] Loss=0.0628\n",
            "Epoch[1/2] Step[4758] Loss=0.4329\n",
            "Epoch[1/2] Step[4759] Loss=0.1750\n",
            "Epoch[1/2] Step[4760] Loss=0.4438\n",
            "Epoch[1/2] Step[4761] Loss=0.4247\n",
            "Epoch[1/2] Step[4762] Loss=0.4323\n",
            "Epoch[1/2] Step[4763] Loss=0.3751\n",
            "Epoch[1/2] Step[4764] Loss=0.2429\n",
            "Epoch[1/2] Step[4765] Loss=0.2211\n",
            "Epoch[1/2] Step[4766] Loss=0.1876\n",
            "Epoch[1/2] Step[4767] Loss=0.4013\n",
            "Epoch[1/2] Step[4768] Loss=0.3247\n",
            "Epoch[1/2] Step[4769] Loss=0.1777\n",
            "Epoch[1/2] Step[4770] Loss=0.9720\n",
            "Epoch[1/2] Step[4771] Loss=0.2306\n",
            "Epoch[1/2] Step[4772] Loss=0.3118\n",
            "Epoch[1/2] Step[4773] Loss=0.0632\n",
            "Epoch[1/2] Step[4774] Loss=0.2796\n",
            "Epoch[1/2] Step[4775] Loss=0.3318\n",
            "Epoch[1/2] Step[4776] Loss=0.1872\n",
            "Epoch[1/2] Step[4777] Loss=0.1615\n",
            "Epoch[1/2] Step[4778] Loss=0.2574\n",
            "Epoch[1/2] Step[4779] Loss=0.8785\n",
            "Epoch[1/2] Step[4780] Loss=0.2792\n",
            "Epoch[1/2] Step[4781] Loss=0.0801\n",
            "Epoch[1/2] Step[4782] Loss=0.1376\n",
            "Epoch[1/2] Step[4783] Loss=0.2042\n",
            "Epoch[1/2] Step[4784] Loss=0.4478\n",
            "Epoch[1/2] Step[4785] Loss=0.1475\n",
            "Epoch[1/2] Step[4786] Loss=0.4166\n",
            "Epoch[1/2] Step[4787] Loss=0.1221\n",
            "Epoch[1/2] Step[4788] Loss=0.1938\n",
            "Epoch[1/2] Step[4789] Loss=0.5378\n",
            "Epoch[1/2] Step[4790] Loss=0.3306\n",
            "Epoch[1/2] Step[4791] Loss=1.1584\n",
            "Epoch[1/2] Step[4792] Loss=0.0801\n",
            "Epoch[1/2] Step[4793] Loss=0.4303\n",
            "Epoch[1/2] Step[4794] Loss=0.1430\n",
            "Epoch[1/2] Step[4795] Loss=0.5381\n",
            "Epoch[1/2] Step[4796] Loss=0.8369\n",
            "Epoch[1/2] Step[4797] Loss=0.1477\n",
            "Epoch[1/2] Step[4798] Loss=0.2348\n",
            "Epoch[1/2] Step[4799] Loss=0.1549\n",
            "Epoch[1/2] Step[4800] Loss=0.1202\n",
            "Epoch[1/2] Step[4801] Loss=0.1763\n",
            "Epoch[1/2] Step[4802] Loss=0.4239\n",
            "Epoch[1/2] Step[4803] Loss=0.4035\n",
            "Epoch[1/2] Step[4804] Loss=0.2183\n",
            "Epoch[1/2] Step[4805] Loss=0.7974\n",
            "Epoch[1/2] Step[4806] Loss=0.9136\n",
            "Epoch[1/2] Step[4807] Loss=0.2223\n",
            "Epoch[1/2] Step[4808] Loss=0.0846\n",
            "Epoch[1/2] Step[4809] Loss=0.3723\n",
            "Epoch[1/2] Step[4810] Loss=0.7544\n",
            "Epoch[1/2] Step[4811] Loss=0.3058\n",
            "Epoch[1/2] Step[4812] Loss=1.1458\n",
            "Epoch[1/2] Step[4813] Loss=0.0861\n",
            "Epoch[1/2] Step[4814] Loss=0.2102\n",
            "Epoch[1/2] Step[4815] Loss=0.1954\n",
            "Epoch[1/2] Step[4816] Loss=0.6982\n",
            "Epoch[1/2] Step[4817] Loss=0.0955\n",
            "Epoch[1/2] Step[4818] Loss=0.0685\n",
            "Epoch[1/2] Step[4819] Loss=0.3146\n",
            "Epoch[1/2] Step[4820] Loss=0.1773\n",
            "Epoch[1/2] Step[4821] Loss=0.4338\n",
            "Epoch[1/2] Step[4822] Loss=0.2397\n",
            "Epoch[1/2] Step[4823] Loss=0.4875\n",
            "Epoch[1/2] Step[4824] Loss=0.3672\n",
            "Epoch[1/2] Step[4825] Loss=0.1925\n",
            "Epoch[1/2] Step[4826] Loss=0.2129\n",
            "Epoch[1/2] Step[4827] Loss=0.3077\n",
            "Epoch[1/2] Step[4828] Loss=0.2410\n",
            "Epoch[1/2] Step[4829] Loss=0.4789\n",
            "Epoch[1/2] Step[4830] Loss=0.3087\n",
            "Epoch[1/2] Step[4831] Loss=0.1447\n",
            "Epoch[1/2] Step[4832] Loss=0.1621\n",
            "Epoch[1/2] Step[4833] Loss=0.1861\n",
            "Epoch[1/2] Step[4834] Loss=0.1914\n",
            "Epoch[1/2] Step[4835] Loss=0.2609\n",
            "Epoch[1/2] Step[4836] Loss=0.0833\n",
            "Epoch[1/2] Step[4837] Loss=0.3441\n",
            "Epoch[1/2] Step[4838] Loss=0.0954\n",
            "Epoch[1/2] Step[4839] Loss=0.2080\n",
            "Epoch[1/2] Step[4840] Loss=0.1306\n",
            "Epoch[1/2] Step[4841] Loss=0.1796\n",
            "Epoch[1/2] Step[4842] Loss=0.9191\n",
            "Epoch[1/2] Step[4843] Loss=0.2389\n",
            "Epoch[1/2] Step[4844] Loss=0.2595\n",
            "Epoch[1/2] Step[4845] Loss=0.1100\n",
            "Epoch[1/2] Step[4846] Loss=0.1624\n",
            "Epoch[1/2] Step[4847] Loss=0.1530\n",
            "Epoch[1/2] Step[4848] Loss=0.6455\n",
            "Epoch[1/2] Step[4849] Loss=0.2103\n",
            "Epoch[1/2] Step[4850] Loss=0.4609\n",
            "Epoch[1/2] Step[4851] Loss=0.3087\n",
            "Epoch[1/2] Step[4852] Loss=0.2234\n",
            "Epoch[1/2] Step[4853] Loss=0.3938\n",
            "Epoch[1/2] Step[4854] Loss=0.4077\n",
            "Epoch[1/2] Step[4855] Loss=0.6044\n",
            "Epoch[1/2] Step[4856] Loss=0.4149\n",
            "Epoch[1/2] Step[4857] Loss=0.3586\n",
            "Epoch[1/2] Step[4858] Loss=0.1373\n",
            "Epoch[1/2] Step[4859] Loss=0.2020\n",
            "Epoch[1/2] Step[4860] Loss=0.4250\n",
            "Epoch[1/2] Step[4861] Loss=0.1843\n",
            "Epoch[1/2] Step[4862] Loss=0.4652\n",
            "Epoch[1/2] Step[4863] Loss=0.7199\n",
            "Epoch[1/2] Step[4864] Loss=0.1889\n",
            "Epoch[1/2] Step[4865] Loss=0.2034\n",
            "Epoch[1/2] Step[4866] Loss=0.5555\n",
            "Epoch[1/2] Step[4867] Loss=0.5068\n",
            "Epoch[1/2] Step[4868] Loss=0.1419\n",
            "Epoch[1/2] Step[4869] Loss=0.4822\n",
            "Epoch[1/2] Step[4870] Loss=0.6294\n",
            "Epoch[1/2] Step[4871] Loss=0.0965\n",
            "Epoch[1/2] Step[4872] Loss=0.2574\n",
            "Epoch[1/2] Step[4873] Loss=0.2345\n",
            "Epoch[1/2] Step[4874] Loss=0.3158\n",
            "Epoch[1/2] Step[4875] Loss=0.2058\n",
            "Epoch[1/2] Step[4876] Loss=0.3883\n",
            "Epoch[1/2] Step[4877] Loss=0.1017\n",
            "Epoch[1/2] Step[4878] Loss=0.2350\n",
            "Epoch[1/2] Step[4879] Loss=0.1274\n",
            "Epoch[1/2] Step[4880] Loss=0.3670\n",
            "Epoch[1/2] Step[4881] Loss=0.2426\n",
            "Epoch[1/2] Step[4882] Loss=0.1884\n",
            "Epoch[1/2] Step[4883] Loss=0.3979\n",
            "Epoch[1/2] Step[4884] Loss=0.0904\n",
            "Epoch[1/2] Step[4885] Loss=0.1038\n",
            "Epoch[1/2] Step[4886] Loss=0.3332\n",
            "Epoch[1/2] Step[4887] Loss=0.4321\n",
            "Epoch[1/2] Step[4888] Loss=0.4328\n",
            "Epoch[1/2] Step[4889] Loss=0.1350\n",
            "Epoch[1/2] Step[4890] Loss=0.2942\n",
            "Epoch[1/2] Step[4891] Loss=0.0807\n",
            "Epoch[1/2] Step[4892] Loss=0.2950\n",
            "Epoch[1/2] Step[4893] Loss=0.4599\n",
            "Epoch[1/2] Step[4894] Loss=0.2253\n",
            "Epoch[1/2] Step[4895] Loss=0.2894\n",
            "Epoch[1/2] Step[4896] Loss=0.7030\n",
            "Epoch[1/2] Step[4897] Loss=0.1888\n",
            "Epoch[1/2] Step[4898] Loss=0.5468\n",
            "Epoch[1/2] Step[4899] Loss=0.1877\n",
            "Epoch[1/2] Step[4900] Loss=0.2141\n",
            "Epoch[1/2] Step[4901] Loss=0.2882\n",
            "Epoch[1/2] Step[4902] Loss=0.1602\n",
            "Epoch[1/2] Step[4903] Loss=0.2958\n",
            "Epoch[1/2] Step[4904] Loss=0.3555\n",
            "Epoch[1/2] Step[4905] Loss=0.1246\n",
            "Epoch[1/2] Step[4906] Loss=0.3225\n",
            "Epoch[1/2] Step[4907] Loss=0.1956\n",
            "Epoch[1/2] Step[4908] Loss=0.2644\n",
            "Epoch[1/2] Step[4909] Loss=0.3377\n",
            "Epoch[1/2] Step[4910] Loss=0.3185\n",
            "Epoch[1/2] Step[4911] Loss=0.2776\n",
            "Epoch[1/2] Step[4912] Loss=0.3966\n",
            "Epoch[1/2] Step[4913] Loss=0.4546\n",
            "Epoch[1/2] Step[4914] Loss=0.7059\n",
            "Epoch[1/2] Step[4915] Loss=0.3924\n",
            "Epoch[1/2] Step[4916] Loss=0.5917\n",
            "Epoch[1/2] Step[4917] Loss=0.0792\n",
            "Epoch[1/2] Step[4918] Loss=0.5867\n",
            "Epoch[1/2] Step[4919] Loss=0.4418\n",
            "Epoch[1/2] Step[4920] Loss=0.4603\n",
            "Epoch[1/2] Step[4921] Loss=0.3039\n",
            "Epoch[1/2] Step[4922] Loss=0.2631\n",
            "Epoch[1/2] Step[4923] Loss=0.0888\n",
            "Epoch[1/2] Step[4924] Loss=0.2856\n",
            "Epoch[1/2] Step[4925] Loss=0.2455\n",
            "Epoch[1/2] Step[4926] Loss=0.7153\n",
            "Epoch[1/2] Step[4927] Loss=0.3310\n",
            "Epoch[1/2] Step[4928] Loss=0.8884\n",
            "Epoch[1/2] Step[4929] Loss=0.2223\n",
            "Epoch[1/2] Step[4930] Loss=0.0688\n",
            "Epoch[1/2] Step[4931] Loss=0.4887\n",
            "Epoch[1/2] Step[4932] Loss=0.3221\n",
            "Epoch[1/2] Step[4933] Loss=0.0869\n",
            "Epoch[1/2] Step[4934] Loss=0.2077\n",
            "Epoch[1/2] Step[4935] Loss=0.2363\n",
            "Epoch[1/2] Step[4936] Loss=0.0682\n",
            "Epoch[1/2] Step[4937] Loss=0.1711\n",
            "Epoch[1/2] Step[4938] Loss=0.2378\n",
            "Epoch[1/2] Step[4939] Loss=0.1062\n",
            "Epoch[1/2] Step[4940] Loss=0.3462\n",
            "Epoch[1/2] Step[4941] Loss=0.3789\n",
            "Epoch[1/2] Step[4942] Loss=0.2687\n",
            "Epoch[1/2] Step[4943] Loss=0.1550\n",
            "Epoch[1/2] Step[4944] Loss=0.1578\n",
            "Epoch[1/2] Step[4945] Loss=0.0829\n",
            "Epoch[1/2] Step[4946] Loss=0.2409\n",
            "Epoch[1/2] Step[4947] Loss=0.2180\n",
            "Epoch[1/2] Step[4948] Loss=0.2185\n",
            "Epoch[1/2] Step[4949] Loss=0.1186\n",
            "Epoch[1/2] Step[4950] Loss=0.8587\n",
            "Epoch[1/2] Step[4951] Loss=0.4706\n",
            "Epoch[1/2] Step[4952] Loss=0.4114\n",
            "Epoch[1/2] Step[4953] Loss=0.5825\n",
            "Epoch[1/2] Step[4954] Loss=0.0899\n",
            "Epoch[1/2] Step[4955] Loss=0.3236\n",
            "Epoch[1/2] Step[4956] Loss=0.9518\n",
            "Epoch[1/2] Step[4957] Loss=0.4484\n",
            "Epoch[1/2] Step[4958] Loss=0.1338\n",
            "Epoch[1/2] Step[4959] Loss=0.3150\n",
            "Epoch[1/2] Step[4960] Loss=0.3676\n",
            "Epoch[1/2] Step[4961] Loss=0.4427\n",
            "Epoch[1/2] Step[4962] Loss=0.5545\n",
            "Epoch[1/2] Step[4963] Loss=0.2432\n",
            "Epoch[1/2] Step[4964] Loss=0.1090\n",
            "Epoch[1/2] Step[4965] Loss=0.2910\n",
            "Epoch[1/2] Step[4966] Loss=0.1875\n",
            "Epoch[1/2] Step[4967] Loss=0.6802\n",
            "Epoch[1/2] Step[4968] Loss=0.1806\n",
            "Epoch[1/2] Step[4969] Loss=0.1062\n",
            "Epoch[1/2] Step[4970] Loss=0.1771\n",
            "Epoch[1/2] Step[4971] Loss=0.6172\n",
            "Epoch[1/2] Step[4972] Loss=0.1850\n",
            "Epoch[1/2] Step[4973] Loss=0.1543\n",
            "Epoch[1/2] Step[4974] Loss=0.1107\n",
            "Epoch[1/2] Step[4975] Loss=0.0927\n",
            "Epoch[1/2] Step[4976] Loss=0.1693\n",
            "Epoch[1/2] Step[4977] Loss=0.0472\n",
            "Epoch[1/2] Step[4978] Loss=0.1179\n",
            "Epoch[1/2] Step[4979] Loss=0.1678\n",
            "Epoch[1/2] Step[4980] Loss=0.1249\n",
            "Epoch[1/2] Step[4981] Loss=0.0895\n",
            "Epoch[1/2] Step[4982] Loss=0.1224\n",
            "Epoch[1/2] Step[4983] Loss=0.3173\n",
            "Epoch[1/2] Step[4984] Loss=0.7865\n",
            "Epoch[1/2] Step[4985] Loss=0.0840\n",
            "Epoch[1/2] Step[4986] Loss=0.3946\n",
            "Epoch[1/2] Step[4987] Loss=0.4206\n",
            "Epoch[1/2] Step[4988] Loss=0.1952\n",
            "Epoch[1/2] Step[4989] Loss=0.2152\n",
            "Epoch[1/2] Step[4990] Loss=0.5142\n",
            "Epoch[1/2] Step[4991] Loss=0.5385\n",
            "Epoch[1/2] Step[4992] Loss=0.1313\n",
            "Epoch[1/2] Step[4993] Loss=0.2717\n",
            "Epoch[1/2] Step[4994] Loss=0.2204\n",
            "Epoch[1/2] Step[4995] Loss=0.1391\n",
            "Epoch[1/2] Step[4996] Loss=0.1476\n",
            "Epoch[1/2] Step[4997] Loss=0.2117\n",
            "Epoch[1/2] Step[4998] Loss=0.6569\n",
            "Epoch[1/2] Step[4999] Loss=0.3000\n",
            "Epoch[1/2] Step[5000] Loss=0.6737\n",
            "Epoch[1/2] Step[5001] Loss=0.1710\n",
            "Epoch[1/2] Step[5002] Loss=0.4049\n",
            "Epoch[1/2] Step[5003] Loss=0.4605\n",
            "Epoch[1/2] Step[5004] Loss=0.2096\n",
            "Epoch[1/2] Step[5005] Loss=0.5467\n",
            "Epoch[1/2] Step[5006] Loss=0.1310\n",
            "Epoch[1/2] Step[5007] Loss=0.1030\n",
            "Epoch[1/2] Step[5008] Loss=0.1330\n",
            "Epoch[1/2] Step[5009] Loss=0.3372\n",
            "Epoch[1/2] Step[5010] Loss=0.6243\n",
            "Epoch[1/2] Step[5011] Loss=0.4743\n",
            "Epoch[1/2] Step[5012] Loss=0.4515\n",
            "Epoch[1/2] Step[5013] Loss=0.5737\n",
            "Epoch[1/2] Step[5014] Loss=0.3476\n",
            "Epoch[1/2] Step[5015] Loss=0.5067\n",
            "Epoch[1/2] Step[5016] Loss=0.2414\n",
            "Epoch[1/2] Step[5017] Loss=0.2002\n",
            "Epoch[1/2] Step[5018] Loss=0.5538\n",
            "Epoch[1/2] Step[5019] Loss=0.0727\n",
            "Epoch[1/2] Step[5020] Loss=0.3843\n",
            "Epoch[1/2] Step[5021] Loss=0.2338\n",
            "Epoch[1/2] Step[5022] Loss=0.1169\n",
            "Epoch[1/2] Step[5023] Loss=0.2740\n",
            "Epoch[1/2] Step[5024] Loss=0.2616\n",
            "Epoch[1/2] Step[5025] Loss=0.3765\n",
            "Epoch[1/2] Step[5026] Loss=0.2248\n",
            "Epoch[1/2] Step[5027] Loss=0.1269\n",
            "Epoch[1/2] Step[5028] Loss=0.2798\n",
            "Epoch[1/2] Step[5029] Loss=0.7901\n",
            "Epoch[1/2] Step[5030] Loss=0.2841\n",
            "Epoch[1/2] Step[5031] Loss=0.1173\n",
            "Epoch[1/2] Step[5032] Loss=0.4937\n",
            "Epoch[1/2] Step[5033] Loss=0.6026\n",
            "Epoch[1/2] Step[5034] Loss=0.2342\n",
            "Epoch[1/2] Step[5035] Loss=0.0916\n",
            "Epoch[1/2] Step[5036] Loss=0.1887\n",
            "Epoch[1/2] Step[5037] Loss=0.1027\n",
            "Epoch[1/2] Step[5038] Loss=0.1818\n",
            "Epoch[1/2] Step[5039] Loss=0.3998\n",
            "Epoch[1/2] Step[5040] Loss=0.2127\n",
            "Epoch[1/2] Step[5041] Loss=0.6227\n",
            "Epoch[1/2] Step[5042] Loss=1.2178\n",
            "Epoch[1/2] Step[5043] Loss=0.2239\n",
            "Epoch[1/2] Step[5044] Loss=0.2233\n",
            "Epoch[1/2] Step[5045] Loss=0.1395\n",
            "Epoch[1/2] Step[5046] Loss=0.9876\n",
            "Epoch[1/2] Step[5047] Loss=0.1639\n",
            "Epoch[1/2] Step[5048] Loss=0.1988\n",
            "Epoch[1/2] Step[5049] Loss=0.3164\n",
            "Epoch[1/2] Step[5050] Loss=0.0826\n",
            "Epoch[1/2] Step[5051] Loss=0.6098\n",
            "Epoch[1/2] Step[5052] Loss=0.4712\n",
            "Epoch[1/2] Step[5053] Loss=0.3305\n",
            "Epoch[1/2] Step[5054] Loss=0.4374\n",
            "Epoch[1/2] Step[5055] Loss=0.3243\n",
            "Epoch[1/2] Step[5056] Loss=0.1670\n",
            "Epoch[1/2] Step[5057] Loss=0.1700\n",
            "Epoch[1/2] Step[5058] Loss=0.3343\n",
            "Epoch[1/2] Step[5059] Loss=0.4037\n",
            "Epoch[1/2] Step[5060] Loss=0.1530\n",
            "Epoch[1/2] Step[5061] Loss=0.0762\n",
            "Epoch[1/2] Step[5062] Loss=0.1253\n",
            "Epoch[1/2] Step[5063] Loss=0.1582\n",
            "Epoch[1/2] Step[5064] Loss=0.9356\n",
            "Epoch[1/2] Step[5065] Loss=0.2684\n",
            "Epoch[1/2] Step[5066] Loss=0.3628\n",
            "Epoch[1/2] Step[5067] Loss=0.5047\n",
            "Epoch[1/2] Step[5068] Loss=0.3384\n",
            "Epoch[1/2] Step[5069] Loss=0.7387\n",
            "Epoch[1/2] Step[5070] Loss=0.1362\n",
            "Epoch[1/2] Step[5071] Loss=0.3713\n",
            "Epoch[1/2] Step[5072] Loss=0.5169\n",
            "Epoch[1/2] Step[5073] Loss=0.4018\n",
            "Epoch[1/2] Step[5074] Loss=0.0843\n",
            "Epoch[1/2] Step[5075] Loss=0.4724\n",
            "Epoch[1/2] Step[5076] Loss=0.4638\n",
            "Epoch[1/2] Step[5077] Loss=0.8044\n",
            "Epoch[1/2] Step[5078] Loss=0.3515\n",
            "Epoch[1/2] Step[5079] Loss=0.9884\n",
            "Epoch[1/2] Step[5080] Loss=0.4330\n",
            "Epoch[1/2] Step[5081] Loss=0.4219\n",
            "Epoch[1/2] Step[5082] Loss=0.5765\n",
            "Epoch[1/2] Step[5083] Loss=0.2224\n",
            "Epoch[1/2] Step[5084] Loss=0.1254\n",
            "Epoch[1/2] Step[5085] Loss=0.2950\n",
            "Epoch[1/2] Step[5086] Loss=0.6496\n",
            "Epoch[1/2] Step[5087] Loss=0.4744\n",
            "Epoch[1/2] Step[5088] Loss=0.4144\n",
            "Epoch[1/2] Step[5089] Loss=0.5714\n",
            "Epoch[1/2] Step[5090] Loss=0.8890\n",
            "Epoch[1/2] Step[5091] Loss=0.5889\n",
            "Epoch[1/2] Step[5092] Loss=0.3455\n",
            "Epoch[1/2] Step[5093] Loss=0.4034\n",
            "Epoch[1/2] Step[5094] Loss=0.1959\n",
            "Epoch[1/2] Step[5095] Loss=0.3706\n",
            "Epoch[1/2] Step[5096] Loss=0.4204\n",
            "Epoch[1/2] Step[5097] Loss=0.1330\n",
            "Epoch[1/2] Step[5098] Loss=0.8347\n",
            "Epoch[1/2] Step[5099] Loss=0.1516\n",
            "Epoch[1/2] Step[5100] Loss=0.5146\n",
            "Epoch[1/2] Step[5101] Loss=0.2340\n",
            "Epoch[1/2] Step[5102] Loss=0.1737\n",
            "Epoch[1/2] Step[5103] Loss=0.6129\n",
            "Epoch[1/2] Step[5104] Loss=0.3868\n",
            "Epoch[1/2] Step[5105] Loss=0.4370\n",
            "Epoch[1/2] Step[5106] Loss=0.1573\n",
            "Epoch[1/2] Step[5107] Loss=0.3598\n",
            "Epoch[1/2] Step[5108] Loss=0.3218\n",
            "Epoch[1/2] Step[5109] Loss=0.1799\n",
            "Epoch[1/2] Step[5110] Loss=0.3201\n",
            "Epoch[1/2] Step[5111] Loss=0.4900\n",
            "Epoch[1/2] Step[5112] Loss=0.4256\n",
            "Epoch[1/2] Step[5113] Loss=0.4379\n",
            "Epoch[1/2] Step[5114] Loss=0.5616\n",
            "Epoch[1/2] Step[5115] Loss=0.3893\n",
            "Epoch[1/2] Step[5116] Loss=0.1506\n",
            "Epoch[1/2] Step[5117] Loss=0.2050\n",
            "Epoch[1/2] Step[5118] Loss=0.1812\n",
            "Epoch[1/2] Step[5119] Loss=0.3416\n",
            "Epoch[1/2] Step[5120] Loss=0.1956\n",
            "Epoch[1/2] Step[5121] Loss=0.1299\n",
            "Epoch[1/2] Step[5122] Loss=0.1031\n",
            "Epoch[1/2] Step[5123] Loss=0.1199\n",
            "Epoch[1/2] Step[5124] Loss=0.3018\n",
            "Epoch[1/2] Step[5125] Loss=0.6392\n",
            "Epoch[1/2] Step[5126] Loss=0.4122\n",
            "Epoch[1/2] Step[5127] Loss=0.2111\n",
            "Epoch[1/2] Step[5128] Loss=0.0868\n",
            "Epoch[1/2] Step[5129] Loss=0.1235\n",
            "Epoch[1/2] Step[5130] Loss=0.0268\n",
            "Epoch[1/2] Step[5131] Loss=0.1720\n",
            "Epoch[1/2] Step[5132] Loss=0.0672\n",
            "Epoch[1/2] Step[5133] Loss=0.2260\n",
            "Epoch[1/2] Step[5134] Loss=0.2603\n",
            "Epoch[1/2] Step[5135] Loss=0.4764\n",
            "Epoch[1/2] Step[5136] Loss=0.1785\n",
            "Epoch[1/2] Step[5137] Loss=0.2099\n",
            "Epoch[1/2] Step[5138] Loss=0.1497\n",
            "Epoch[1/2] Step[5139] Loss=0.5790\n",
            "Epoch[1/2] Step[5140] Loss=0.1051\n",
            "Epoch[1/2] Step[5141] Loss=0.1583\n",
            "Epoch[1/2] Step[5142] Loss=0.4079\n",
            "Epoch[1/2] Step[5143] Loss=0.4003\n",
            "Epoch[1/2] Step[5144] Loss=0.3452\n",
            "Epoch[1/2] Step[5145] Loss=0.4715\n",
            "Epoch[1/2] Step[5146] Loss=0.2281\n",
            "Epoch[1/2] Step[5147] Loss=0.4502\n",
            "Epoch[1/2] Step[5148] Loss=0.5166\n",
            "Epoch[1/2] Step[5149] Loss=0.3387\n",
            "Epoch[1/2] Step[5150] Loss=0.4135\n",
            "Epoch[1/2] Step[5151] Loss=0.0920\n",
            "Epoch[1/2] Step[5152] Loss=0.6980\n",
            "Epoch[1/2] Step[5153] Loss=0.2699\n",
            "Epoch[1/2] Step[5154] Loss=1.4348\n",
            "Epoch[1/2] Step[5155] Loss=0.2040\n",
            "Epoch[1/2] Step[5156] Loss=0.0826\n",
            "Epoch[1/2] Step[5157] Loss=0.6001\n",
            "Epoch[1/2] Step[5158] Loss=0.4676\n",
            "Epoch[1/2] Step[5159] Loss=0.2097\n",
            "Epoch[1/2] Step[5160] Loss=0.1192\n",
            "Epoch[1/2] Step[5161] Loss=0.5890\n",
            "Epoch[1/2] Step[5162] Loss=0.1100\n",
            "Epoch[1/2] Step[5163] Loss=0.1445\n",
            "Epoch[1/2] Step[5164] Loss=0.2453\n",
            "Epoch[1/2] Step[5165] Loss=0.2127\n",
            "Epoch[1/2] Step[5166] Loss=0.1903\n",
            "Epoch[1/2] Step[5167] Loss=0.2226\n",
            "Epoch[1/2] Step[5168] Loss=0.0966\n",
            "Epoch[1/2] Step[5169] Loss=0.3303\n",
            "Epoch[1/2] Step[5170] Loss=0.5947\n",
            "Epoch[1/2] Step[5171] Loss=0.2237\n",
            "Epoch[1/2] Step[5172] Loss=0.1922\n",
            "Epoch[1/2] Step[5173] Loss=0.6073\n",
            "Epoch[1/2] Step[5174] Loss=0.2368\n",
            "Epoch[1/2] Step[5175] Loss=0.2835\n",
            "Epoch[1/2] Step[5176] Loss=0.2888\n",
            "Epoch[1/2] Step[5177] Loss=0.4458\n",
            "Epoch[1/2] Step[5178] Loss=0.1949\n",
            "Epoch[1/2] Step[5179] Loss=0.4096\n",
            "Epoch[1/2] Step[5180] Loss=0.4405\n",
            "Epoch[1/2] Step[5181] Loss=0.1065\n",
            "Epoch[1/2] Step[5182] Loss=0.1498\n",
            "Epoch[1/2] Step[5183] Loss=0.4075\n",
            "Epoch[1/2] Step[5184] Loss=0.4713\n",
            "Epoch[1/2] Step[5185] Loss=0.4682\n",
            "Epoch[1/2] Step[5186] Loss=0.6760\n",
            "Epoch[1/2] Step[5187] Loss=0.2997\n",
            "Epoch[1/2] Step[5188] Loss=0.3598\n",
            "Epoch[1/2] Step[5189] Loss=0.1168\n",
            "Epoch[1/2] Step[5190] Loss=0.1794\n",
            "Epoch[1/2] Step[5191] Loss=0.2168\n",
            "Epoch[1/2] Step[5192] Loss=0.6914\n",
            "Epoch[1/2] Step[5193] Loss=0.1706\n",
            "Epoch[1/2] Step[5194] Loss=0.3549\n",
            "Epoch[1/2] Step[5195] Loss=0.2299\n",
            "Epoch[1/2] Step[5196] Loss=0.3691\n",
            "Epoch[1/2] Step[5197] Loss=0.4547\n",
            "Epoch[1/2] Step[5198] Loss=0.2294\n",
            "Epoch[1/2] Step[5199] Loss=0.1566\n",
            "Epoch[1/2] Step[5200] Loss=0.5339\n",
            "Epoch[1/2] Step[5201] Loss=0.2832\n",
            "Epoch[1/2] Step[5202] Loss=0.5623\n",
            "Epoch[1/2] Step[5203] Loss=0.6594\n",
            "Epoch[1/2] Step[5204] Loss=0.2202\n",
            "Epoch[1/2] Step[5205] Loss=0.8957\n",
            "Epoch[1/2] Step[5206] Loss=0.4713\n",
            "Epoch[1/2] Step[5207] Loss=0.4636\n",
            "Epoch[1/2] Step[5208] Loss=0.5915\n",
            "Epoch[1/2] Step[5209] Loss=0.2267\n",
            "Epoch[1/2] Step[5210] Loss=0.3639\n",
            "Epoch[1/2] Step[5211] Loss=0.2988\n",
            "Epoch[1/2] Step[5212] Loss=0.1238\n",
            "Epoch[1/2] Step[5213] Loss=0.1298\n",
            "Epoch[1/2] Step[5214] Loss=1.0132\n",
            "Epoch[1/2] Step[5215] Loss=0.2863\n",
            "Epoch[1/2] Step[5216] Loss=0.4681\n",
            "Epoch[1/2] Step[5217] Loss=0.3849\n",
            "Epoch[1/2] Step[5218] Loss=0.2007\n",
            "Epoch[1/2] Step[5219] Loss=0.4673\n",
            "Epoch[1/2] Step[5220] Loss=0.4387\n",
            "Epoch[1/2] Step[5221] Loss=0.3274\n",
            "Epoch[1/2] Step[5222] Loss=0.4115\n",
            "Epoch[1/2] Step[5223] Loss=0.1720\n",
            "Epoch[1/2] Step[5224] Loss=0.0736\n",
            "Epoch[1/2] Step[5225] Loss=0.2653\n",
            "Epoch[1/2] Step[5226] Loss=0.3575\n",
            "Epoch[1/2] Step[5227] Loss=0.0493\n",
            "Epoch[1/2] Step[5228] Loss=0.4060\n",
            "Epoch[1/2] Step[5229] Loss=0.3254\n",
            "Epoch[1/2] Step[5230] Loss=0.4154\n",
            "Epoch[1/2] Step[5231] Loss=0.5423\n",
            "Epoch[1/2] Step[5232] Loss=0.1281\n",
            "Epoch[1/2] Step[5233] Loss=0.3356\n",
            "Epoch[1/2] Step[5234] Loss=0.4635\n",
            "Epoch[1/2] Step[5235] Loss=0.5043\n",
            "Epoch[1/2] Step[5236] Loss=0.5582\n",
            "Epoch[1/2] Step[5237] Loss=0.3614\n",
            "Epoch[1/2] Step[5238] Loss=0.2107\n",
            "Epoch[1/2] Step[5239] Loss=0.0563\n",
            "Epoch[1/2] Step[5240] Loss=0.2095\n",
            "Epoch[1/2] Step[5241] Loss=0.3401\n",
            "Epoch[1/2] Step[5242] Loss=0.3703\n",
            "Epoch[1/2] Step[5243] Loss=0.5536\n",
            "Epoch[1/2] Step[5244] Loss=0.1384\n",
            "Epoch[1/2] Step[5245] Loss=0.2358\n",
            "Epoch[1/2] Step[5246] Loss=0.4372\n",
            "Epoch[1/2] Step[5247] Loss=0.1016\n",
            "Epoch[1/2] Step[5248] Loss=0.1624\n",
            "Epoch[1/2] Step[5249] Loss=0.1860\n",
            "Epoch[1/2] Step[5250] Loss=0.2846\n",
            "Epoch[1/2] Step[5251] Loss=0.2463\n",
            "Epoch[1/2] Step[5252] Loss=0.2081\n",
            "Epoch[1/2] Step[5253] Loss=1.1318\n",
            "Epoch[1/2] Step[5254] Loss=0.6386\n",
            "Epoch[1/2] Step[5255] Loss=0.7376\n",
            "Epoch[1/2] Step[5256] Loss=0.5605\n",
            "Epoch[1/2] Step[5257] Loss=0.2055\n",
            "Epoch[1/2] Step[5258] Loss=0.2654\n",
            "Epoch[1/2] Step[5259] Loss=0.3340\n",
            "Epoch[1/2] Step[5260] Loss=0.3748\n",
            "Epoch[1/2] Step[5261] Loss=0.4301\n",
            "Epoch[1/2] Step[5262] Loss=0.0803\n",
            "Epoch[1/2] Step[5263] Loss=0.1426\n",
            "Epoch[1/2] Step[5264] Loss=0.2870\n",
            "Epoch[1/2] Step[5265] Loss=0.5172\n",
            "Epoch[1/2] Step[5266] Loss=0.1173\n",
            "Epoch[1/2] Step[5267] Loss=0.8974\n",
            "Epoch[1/2] Step[5268] Loss=0.3637\n",
            "Epoch[1/2] Step[5269] Loss=0.2700\n",
            "Epoch[1/2] Step[5270] Loss=0.1558\n",
            "Epoch[1/2] Step[5271] Loss=0.5492\n",
            "Epoch[1/2] Step[5272] Loss=0.0889\n",
            "Epoch[1/2] Step[5273] Loss=0.7437\n",
            "Epoch[1/2] Step[5274] Loss=0.8335\n",
            "Epoch[1/2] Step[5275] Loss=0.3170\n",
            "Epoch[1/2] Step[5276] Loss=0.4199\n",
            "Epoch[1/2] Step[5277] Loss=0.2875\n",
            "Epoch[1/2] Step[5278] Loss=0.2911\n",
            "Epoch[1/2] Step[5279] Loss=0.4928\n",
            "Epoch[1/2] Step[5280] Loss=0.4980\n",
            "Epoch[1/2] Step[5281] Loss=0.2876\n",
            "Epoch[1/2] Step[5282] Loss=0.2794\n",
            "Epoch[1/2] Step[5283] Loss=0.1507\n",
            "Epoch[1/2] Step[5284] Loss=0.1028\n",
            "Epoch[1/2] Step[5285] Loss=0.4192\n",
            "Epoch[1/2] Step[5286] Loss=0.3244\n",
            "Epoch[1/2] Step[5287] Loss=0.1793\n",
            "Epoch[1/2] Step[5288] Loss=0.0560\n",
            "Epoch[1/2] Step[5289] Loss=0.5932\n",
            "Epoch[1/2] Step[5290] Loss=0.5434\n",
            "Epoch[1/2] Step[5291] Loss=0.1672\n",
            "Epoch[1/2] Step[5292] Loss=0.2559\n",
            "Epoch[1/2] Step[5293] Loss=0.8347\n",
            "Epoch[1/2] Step[5294] Loss=0.5721\n",
            "Epoch[1/2] Step[5295] Loss=0.1266\n",
            "Epoch[1/2] Step[5296] Loss=0.7727\n",
            "Epoch[1/2] Step[5297] Loss=0.2675\n",
            "Epoch[1/2] Step[5298] Loss=0.1115\n",
            "Epoch[1/2] Step[5299] Loss=0.1301\n",
            "Epoch[1/2] Step[5300] Loss=0.4034\n",
            "Epoch[1/2] Step[5301] Loss=0.2746\n",
            "Epoch[1/2] Step[5302] Loss=0.1440\n",
            "Epoch[1/2] Step[5303] Loss=0.2567\n",
            "Epoch[1/2] Step[5304] Loss=0.1126\n",
            "Epoch[1/2] Step[5305] Loss=0.1041\n",
            "Epoch[1/2] Step[5306] Loss=0.1876\n",
            "Epoch[1/2] Step[5307] Loss=0.4085\n",
            "Epoch[1/2] Step[5308] Loss=0.2138\n",
            "Epoch[1/2] Step[5309] Loss=0.1622\n",
            "Epoch[1/2] Step[5310] Loss=0.1559\n",
            "Epoch[1/2] Step[5311] Loss=0.0870\n",
            "Epoch[1/2] Step[5312] Loss=0.1304\n",
            "Epoch[1/2] Step[5313] Loss=0.3250\n",
            "Epoch[1/2] Step[5314] Loss=0.4181\n",
            "Epoch[1/2] Step[5315] Loss=0.3739\n",
            "Epoch[1/2] Step[5316] Loss=0.8360\n",
            "Epoch[1/2] Step[5317] Loss=0.3972\n",
            "Epoch[1/2] Step[5318] Loss=0.2537\n",
            "Epoch[1/2] Step[5319] Loss=0.5689\n",
            "Epoch[1/2] Step[5320] Loss=0.3925\n",
            "Epoch[1/2] Step[5321] Loss=0.5515\n",
            "Epoch[1/2] Step[5322] Loss=0.3312\n",
            "Epoch[1/2] Step[5323] Loss=0.3727\n",
            "Epoch[1/2] Step[5324] Loss=0.3377\n",
            "Epoch[1/2] Step[5325] Loss=0.2402\n",
            "Epoch[1/2] Step[5326] Loss=0.1317\n",
            "Epoch[1/2] Step[5327] Loss=0.4387\n",
            "Epoch[1/2] Step[5328] Loss=0.0646\n",
            "Epoch[1/2] Step[5329] Loss=0.0967\n",
            "Epoch[1/2] Step[5330] Loss=0.2618\n",
            "Epoch[1/2] Step[5331] Loss=0.0562\n",
            "Epoch[1/2] Step[5332] Loss=0.2234\n",
            "Epoch[1/2] Step[5333] Loss=0.3117\n",
            "Epoch[1/2] Step[5334] Loss=0.2193\n",
            "Epoch[1/2] Step[5335] Loss=0.1204\n",
            "Epoch[1/2] Step[5336] Loss=0.3521\n",
            "Epoch[1/2] Step[5337] Loss=0.2416\n",
            "Epoch[1/2] Step[5338] Loss=0.1118\n",
            "Epoch[1/2] Step[5339] Loss=0.2861\n",
            "Epoch[1/2] Step[5340] Loss=0.0897\n",
            "Epoch[1/2] Step[5341] Loss=0.4613\n",
            "Epoch[1/2] Step[5342] Loss=0.1760\n",
            "Epoch[1/2] Step[5343] Loss=0.5383\n",
            "Epoch[1/2] Step[5344] Loss=0.0741\n",
            "Epoch[1/2] Step[5345] Loss=0.3562\n",
            "Epoch[1/2] Step[5346] Loss=0.4597\n",
            "Epoch[1/2] Step[5347] Loss=0.5460\n",
            "Epoch[1/2] Step[5348] Loss=0.8784\n",
            "Epoch[1/2] Step[5349] Loss=0.2439\n",
            "Epoch[1/2] Step[5350] Loss=0.1818\n",
            "Epoch[1/2] Step[5351] Loss=0.8168\n",
            "Epoch[1/2] Step[5352] Loss=0.3954\n",
            "Epoch[1/2] Step[5353] Loss=0.2622\n",
            "Epoch[1/2] Step[5354] Loss=0.3596\n",
            "Epoch[1/2] Step[5355] Loss=0.0751\n",
            "Epoch[1/2] Step[5356] Loss=0.1181\n",
            "Epoch[1/2] Step[5357] Loss=0.0747\n",
            "Epoch[1/2] Step[5358] Loss=0.1421\n",
            "Epoch[1/2] Step[5359] Loss=0.6254\n",
            "Epoch[1/2] Step[5360] Loss=0.2618\n",
            "Epoch[1/2] Step[5361] Loss=0.1828\n",
            "Epoch[1/2] Step[5362] Loss=0.2464\n",
            "Epoch[1/2] Step[5363] Loss=0.6719\n",
            "Epoch[1/2] Step[5364] Loss=0.0792\n",
            "Epoch[1/2] Step[5365] Loss=0.2756\n",
            "Epoch[1/2] Step[5366] Loss=0.0909\n",
            "Epoch[1/2] Step[5367] Loss=0.5464\n",
            "Epoch[1/2] Step[5368] Loss=0.1350\n",
            "Epoch[1/2] Step[5369] Loss=0.5125\n",
            "Epoch[1/2] Step[5370] Loss=0.4531\n",
            "Epoch[1/2] Step[5371] Loss=0.0792\n",
            "Epoch[1/2] Step[5372] Loss=0.3569\n",
            "Epoch[1/2] Step[5373] Loss=0.4752\n",
            "Epoch[1/2] Step[5374] Loss=0.3257\n",
            "Epoch[1/2] Step[5375] Loss=0.2043\n",
            "Epoch[1/2] Step[5376] Loss=0.2266\n",
            "Epoch[1/2] Step[5377] Loss=0.1306\n",
            "Epoch[1/2] Step[5378] Loss=0.7483\n",
            "Epoch[1/2] Step[5379] Loss=0.3101\n",
            "Epoch[1/2] Step[5380] Loss=0.5565\n",
            "Epoch[1/2] Step[5381] Loss=1.5115\n",
            "Epoch[1/2] Step[5382] Loss=0.3639\n",
            "Epoch[1/2] Step[5383] Loss=0.7596\n",
            "Epoch[1/2] Step[5384] Loss=0.1212\n",
            "Epoch[1/2] Step[5385] Loss=0.2734\n",
            "Epoch[1/2] Step[5386] Loss=0.3530\n",
            "Epoch[1/2] Step[5387] Loss=0.3083\n",
            "Epoch[1/2] Step[5388] Loss=0.3474\n",
            "Epoch[1/2] Step[5389] Loss=0.2525\n",
            "Epoch[1/2] Step[5390] Loss=0.3484\n",
            "Epoch[1/2] Step[5391] Loss=0.2298\n",
            "Epoch[1/2] Step[5392] Loss=0.9421\n",
            "Epoch[1/2] Step[5393] Loss=0.3354\n",
            "Epoch[1/2] Step[5394] Loss=0.7716\n",
            "Epoch[1/2] Step[5395] Loss=0.6933\n",
            "Epoch[1/2] Step[5396] Loss=0.4903\n",
            "Epoch[1/2] Step[5397] Loss=0.2274\n",
            "Epoch[1/2] Step[5398] Loss=0.6113\n",
            "Epoch[1/2] Step[5399] Loss=0.0864\n",
            "Epoch[1/2] Step[5400] Loss=0.0966\n",
            "Epoch[1/2] Step[5401] Loss=0.4057\n",
            "Epoch[1/2] Step[5402] Loss=0.8427\n",
            "Epoch[1/2] Step[5403] Loss=0.1712\n",
            "Epoch[1/2] Step[5404] Loss=0.1559\n",
            "Epoch[1/2] Step[5405] Loss=0.2347\n",
            "Epoch[1/2] Step[5406] Loss=0.2601\n",
            "Epoch[1/2] Step[5407] Loss=0.0681\n",
            "Epoch[1/2] Step[5408] Loss=0.6025\n",
            "Epoch[1/2] Step[5409] Loss=0.3119\n",
            "Epoch[1/2] Step[5410] Loss=0.3701\n",
            "Epoch[1/2] Step[5411] Loss=0.1104\n",
            "Epoch[1/2] Step[5412] Loss=0.7386\n",
            "Epoch[1/2] Step[5413] Loss=0.1271\n",
            "Epoch[1/2] Step[5414] Loss=0.2260\n",
            "Epoch[1/2] Step[5415] Loss=0.0944\n",
            "Epoch[1/2] Step[5416] Loss=0.2274\n",
            "Epoch[1/2] Step[5417] Loss=0.2073\n",
            "Epoch[1/2] Step[5418] Loss=0.3450\n",
            "Epoch[1/2] Step[5419] Loss=0.0734\n",
            "Epoch[1/2] Step[5420] Loss=0.4066\n",
            "Epoch[1/2] Step[5421] Loss=0.2588\n",
            "Epoch[1/2] Step[5422] Loss=0.3198\n",
            "Epoch[1/2] Step[5423] Loss=0.4081\n",
            "Epoch[1/2] Step[5424] Loss=0.4419\n",
            "Epoch[1/2] Step[5425] Loss=0.0978\n",
            "Epoch[1/2] Step[5426] Loss=0.3792\n",
            "Epoch[1/2] Step[5427] Loss=0.5511\n",
            "Epoch[1/2] Step[5428] Loss=0.2539\n",
            "Epoch[1/2] Step[5429] Loss=0.5811\n",
            "Epoch[1/2] Step[5430] Loss=0.3517\n",
            "Epoch[1/2] Step[5431] Loss=0.2314\n",
            "Epoch[1/2] Step[5432] Loss=0.3087\n",
            "Epoch[1/2] Step[5433] Loss=0.1516\n",
            "Epoch[1/2] Step[5434] Loss=0.1374\n",
            "Epoch[1/2] Step[5435] Loss=0.3393\n",
            "Epoch[1/2] Step[5436] Loss=0.2166\n",
            "Epoch[1/2] Step[5437] Loss=0.4320\n",
            "Epoch[1/2] Step[5438] Loss=0.3256\n",
            "Epoch[1/2] Step[5439] Loss=0.5096\n",
            "Epoch[1/2] Step[5440] Loss=0.4665\n",
            "Epoch[1/2] Step[5441] Loss=0.2546\n",
            "Epoch[1/2] Step[5442] Loss=0.1781\n",
            "Epoch[1/2] Step[5443] Loss=0.6407\n",
            "Epoch[1/2] Step[5444] Loss=0.1388\n",
            "Epoch[1/2] Step[5445] Loss=0.0922\n",
            "Epoch[1/2] Step[5446] Loss=1.2262\n",
            "Epoch[1/2] Step[5447] Loss=0.1832\n",
            "Epoch[1/2] Step[5448] Loss=0.1145\n",
            "Epoch[1/2] Step[5449] Loss=0.5978\n",
            "Epoch[1/2] Step[5450] Loss=0.3428\n",
            "Epoch[1/2] Step[5451] Loss=0.2282\n",
            "Epoch[1/2] Step[5452] Loss=0.0736\n",
            "Epoch[1/2] Step[5453] Loss=0.3477\n",
            "Epoch[1/2] Step[5454] Loss=0.2551\n",
            "Epoch[1/2] Step[5455] Loss=0.0603\n",
            "Epoch[1/2] Step[5456] Loss=0.7908\n",
            "Epoch[1/2] Step[5457] Loss=0.0885\n",
            "Epoch[1/2] Step[5458] Loss=0.0437\n",
            "Epoch[1/2] Step[5459] Loss=0.0621\n",
            "Epoch[1/2] Step[5460] Loss=0.1392\n",
            "Epoch[1/2] Step[5461] Loss=0.3316\n",
            "Epoch[1/2] Step[5462] Loss=0.3949\n",
            "Epoch[1/2] Step[5463] Loss=0.4988\n",
            "Epoch[1/2] Step[5464] Loss=0.3307\n",
            "Epoch[1/2] Step[5465] Loss=0.5605\n",
            "Epoch[1/2] Step[5466] Loss=0.2317\n",
            "Epoch[1/2] Step[5467] Loss=1.0339\n",
            "Epoch[1/2] Step[5468] Loss=0.5117\n",
            "Epoch[1/2] Step[5469] Loss=0.4384\n",
            "Epoch[1/2] Step[5470] Loss=0.2530\n",
            "Epoch[1/2] Step[5471] Loss=0.3546\n",
            "Epoch[1/2] Step[5472] Loss=0.2656\n",
            "Epoch[1/2] Step[5473] Loss=0.2987\n",
            "Epoch[1/2] Step[5474] Loss=0.0715\n",
            "Epoch[1/2] Step[5475] Loss=0.5454\n",
            "Epoch[1/2] Step[5476] Loss=0.0532\n",
            "Epoch[1/2] Step[5477] Loss=0.1151\n",
            "Epoch[1/2] Step[5478] Loss=0.4734\n",
            "Epoch[1/2] Step[5479] Loss=0.1252\n",
            "Epoch[1/2] Step[5480] Loss=0.4364\n",
            "Epoch[1/2] Step[5481] Loss=0.1532\n",
            "Epoch[1/2] Step[5482] Loss=0.6752\n",
            "Epoch[1/2] Step[5483] Loss=0.2263\n",
            "Epoch[1/2] Step[5484] Loss=0.3337\n",
            "Epoch[1/2] Step[5485] Loss=0.5562\n",
            "Epoch[1/2] Step[5486] Loss=0.8053\n",
            "Epoch[1/2] Step[5487] Loss=0.3832\n",
            "Epoch[1/2] Step[5488] Loss=0.2266\n",
            "Epoch[1/2] Step[5489] Loss=0.9960\n",
            "Epoch[1/2] Step[5490] Loss=0.0905\n",
            "Epoch[1/2] Step[5491] Loss=0.1775\n",
            "Epoch[1/2] Step[5492] Loss=0.1205\n",
            "Epoch[1/2] Step[5493] Loss=0.2585\n",
            "Epoch[1/2] Step[5494] Loss=0.1663\n",
            "Epoch[1/2] Step[5495] Loss=0.2955\n",
            "Epoch[1/2] Step[5496] Loss=0.7155\n",
            "Epoch[1/2] Step[5497] Loss=0.1201\n",
            "Epoch[1/2] Step[5498] Loss=0.2417\n",
            "Epoch[1/2] Step[5499] Loss=0.3153\n",
            "Epoch[1/2] Step[5500] Loss=0.1882\n",
            "Epoch[1/2] Step[5501] Loss=0.1718\n",
            "Epoch[1/2] Step[5502] Loss=0.0944\n",
            "Epoch[1/2] Step[5503] Loss=0.2181\n",
            "Epoch[1/2] Step[5504] Loss=0.2372\n",
            "Epoch[1/2] Step[5505] Loss=0.6004\n",
            "Epoch[1/2] Step[5506] Loss=1.1954\n",
            "Epoch[1/2] Step[5507] Loss=0.0722\n",
            "Epoch[1/2] Step[5508] Loss=0.4362\n",
            "Epoch[1/2] Step[5509] Loss=0.5540\n",
            "Epoch[1/2] Step[5510] Loss=0.3359\n",
            "Epoch[1/2] Step[5511] Loss=0.4427\n",
            "Epoch[1/2] Step[5512] Loss=0.4731\n",
            "Epoch[1/2] Step[5513] Loss=0.6830\n",
            "Epoch[1/2] Step[5514] Loss=0.2374\n",
            "Epoch[1/2] Step[5515] Loss=0.7957\n",
            "Epoch[1/2] Step[5516] Loss=0.3288\n",
            "Epoch[1/2] Step[5517] Loss=0.1494\n",
            "Epoch[1/2] Step[5518] Loss=0.1514\n",
            "Epoch[1/2] Step[5519] Loss=0.0651\n",
            "Epoch[1/2] Step[5520] Loss=0.1499\n",
            "Epoch[1/2] Step[5521] Loss=0.1254\n",
            "Epoch[1/2] Step[5522] Loss=0.1434\n",
            "Epoch[1/2] Step[5523] Loss=0.1970\n",
            "Epoch[1/2] Step[5524] Loss=0.2159\n",
            "Epoch[1/2] Step[5525] Loss=0.6986\n",
            "Epoch[1/2] Step[5526] Loss=0.1281\n",
            "Epoch[1/2] Step[5527] Loss=0.2968\n",
            "Epoch[1/2] Step[5528] Loss=0.4012\n",
            "Epoch[1/2] Step[5529] Loss=0.2265\n",
            "Epoch[1/2] Step[5530] Loss=0.3945\n",
            "Epoch[1/2] Step[5531] Loss=0.1688\n",
            "Epoch[1/2] Step[5532] Loss=0.0562\n",
            "Epoch[1/2] Step[5533] Loss=0.2210\n",
            "Epoch[1/2] Step[5534] Loss=0.2156\n",
            "Epoch[1/2] Step[5535] Loss=0.2694\n",
            "Epoch[1/2] Step[5536] Loss=0.3035\n",
            "Epoch[1/2] Step[5537] Loss=0.2685\n",
            "Epoch[1/2] Step[5538] Loss=0.2313\n",
            "Epoch[1/2] Step[5539] Loss=0.2507\n",
            "Epoch[1/2] Step[5540] Loss=0.1458\n",
            "Epoch[1/2] Step[5541] Loss=0.2595\n",
            "Epoch[1/2] Step[5542] Loss=0.1335\n",
            "Epoch[1/2] Step[5543] Loss=0.5139\n",
            "Epoch[1/2] Step[5544] Loss=0.3539\n",
            "Epoch[1/2] Step[5545] Loss=0.2025\n",
            "Epoch[1/2] Step[5546] Loss=0.5467\n",
            "Epoch[1/2] Step[5547] Loss=0.4212\n",
            "Epoch[1/2] Step[5548] Loss=0.3152\n",
            "Epoch[1/2] Step[5549] Loss=0.3275\n",
            "Epoch[1/2] Step[5550] Loss=0.1610\n",
            "Epoch[1/2] Step[5551] Loss=0.3226\n",
            "Epoch[1/2] Step[5552] Loss=0.1946\n",
            "Epoch[1/2] Step[5553] Loss=0.4332\n",
            "Epoch[1/2] Step[5554] Loss=0.4399\n",
            "Epoch[1/2] Step[5555] Loss=0.2313\n",
            "Epoch[1/2] Step[5556] Loss=0.3264\n",
            "Epoch[1/2] Step[5557] Loss=0.1732\n",
            "Epoch[1/2] Step[5558] Loss=0.1167\n",
            "Epoch[1/2] Step[5559] Loss=0.2294\n",
            "Epoch[1/2] Step[5560] Loss=0.1290\n",
            "Epoch[1/2] Step[5561] Loss=0.3214\n",
            "Epoch[1/2] Step[5562] Loss=0.1590\n",
            "Epoch[1/2] Step[5563] Loss=0.3156\n",
            "Epoch[1/2] Step[5564] Loss=0.0452\n",
            "Epoch[1/2] Step[5565] Loss=0.0982\n",
            "Epoch[1/2] Step[5566] Loss=0.5612\n",
            "Epoch[1/2] Step[5567] Loss=1.0193\n",
            "Epoch[1/2] Step[5568] Loss=0.3671\n",
            "Epoch[1/2] Step[5569] Loss=0.1465\n",
            "Epoch[1/2] Step[5570] Loss=0.3605\n",
            "Epoch[1/2] Step[5571] Loss=0.1109\n",
            "Epoch[1/2] Step[5572] Loss=0.3032\n",
            "Epoch[1/2] Step[5573] Loss=0.4314\n",
            "Epoch[1/2] Step[5574] Loss=0.1941\n",
            "Epoch[1/2] Step[5575] Loss=0.3246\n",
            "Epoch[1/2] Step[5576] Loss=0.4597\n",
            "Epoch[1/2] Step[5577] Loss=0.2224\n",
            "Epoch[1/2] Step[5578] Loss=0.1406\n",
            "Epoch[1/2] Step[5579] Loss=0.6466\n",
            "Epoch[1/2] Step[5580] Loss=0.1154\n",
            "Epoch[1/2] Step[5581] Loss=0.3086\n",
            "Epoch[1/2] Step[5582] Loss=0.5910\n",
            "Epoch[1/2] Step[5583] Loss=0.6391\n",
            "Epoch[1/2] Step[5584] Loss=0.1742\n",
            "Epoch[1/2] Step[5585] Loss=0.4533\n",
            "Epoch[1/2] Step[5586] Loss=0.1501\n",
            "Epoch[1/2] Step[5587] Loss=0.4990\n",
            "Epoch[1/2] Step[5588] Loss=0.1357\n",
            "Epoch[1/2] Step[5589] Loss=0.2515\n",
            "Epoch[1/2] Step[5590] Loss=0.5759\n",
            "Epoch[1/2] Step[5591] Loss=0.2413\n",
            "Epoch[1/2] Step[5592] Loss=0.3796\n",
            "Epoch[1/2] Step[5593] Loss=0.5199\n",
            "Epoch[1/2] Step[5594] Loss=0.4290\n",
            "Epoch[1/2] Step[5595] Loss=0.3358\n",
            "Epoch[1/2] Step[5596] Loss=0.6181\n",
            "Epoch[1/2] Step[5597] Loss=0.4872\n",
            "Epoch[1/2] Step[5598] Loss=0.7922\n",
            "Epoch[1/2] Step[5599] Loss=0.0701\n",
            "Epoch[1/2] Step[5600] Loss=0.2024\n",
            "Epoch[1/2] Step[5601] Loss=0.0671\n",
            "Epoch[1/2] Step[5602] Loss=0.5304\n",
            "Epoch[1/2] Step[5603] Loss=0.0797\n",
            "Epoch[1/2] Step[5604] Loss=0.1572\n",
            "Epoch[1/2] Step[5605] Loss=0.1351\n",
            "Epoch[1/2] Step[5606] Loss=0.1130\n",
            "Epoch[1/2] Step[5607] Loss=0.3072\n",
            "Epoch[1/2] Step[5608] Loss=0.5182\n",
            "Epoch[1/2] Step[5609] Loss=0.1204\n",
            "Epoch[1/2] Step[5610] Loss=0.3918\n",
            "Epoch[1/2] Step[5611] Loss=0.2727\n",
            "Epoch[1/2] Step[5612] Loss=0.1220\n",
            "Epoch[1/2] Step[5613] Loss=0.4581\n",
            "Epoch[1/2] Step[5614] Loss=0.8606\n",
            "Epoch[1/2] Step[5615] Loss=0.7699\n",
            "Epoch[1/2] Step[5616] Loss=0.1253\n",
            "Epoch[1/2] Step[5617] Loss=0.3894\n",
            "Epoch[1/2] Step[5618] Loss=0.2947\n",
            "Epoch[1/2] Step[5619] Loss=0.7217\n",
            "Epoch[1/2] Step[5620] Loss=0.8373\n",
            "Epoch[1/2] Step[5621] Loss=0.4552\n",
            "Epoch[1/2] Step[5622] Loss=0.4841\n",
            "Epoch[1/2] Step[5623] Loss=0.5614\n",
            "Epoch[1/2] Step[5624] Loss=0.3724\n",
            "Epoch[1/2] Step[5625] Loss=0.0340\n",
            "Epoch[1/2] Step[5626] Loss=0.1393\n",
            "Epoch[1/2] Step[5627] Loss=0.4420\n",
            "Epoch[1/2] Step[5628] Loss=0.1264\n",
            "Epoch[1/2] Step[5629] Loss=0.1929\n",
            "Epoch[1/2] Step[5630] Loss=0.3275\n",
            "Epoch[1/2] Step[5631] Loss=0.1193\n",
            "Epoch[1/2] Step[5632] Loss=0.3218\n",
            "Epoch[1/2] Step[5633] Loss=0.1914\n",
            "Epoch[1/2] Step[5634] Loss=0.2714\n",
            "Epoch[1/2] Step[5635] Loss=1.0478\n",
            "Epoch[1/2] Step[5636] Loss=0.2589\n",
            "Epoch[1/2] Step[5637] Loss=0.3792\n",
            "Epoch[1/2] Step[5638] Loss=0.5414\n",
            "Epoch[1/2] Step[5639] Loss=0.3443\n",
            "Epoch[1/2] Step[5640] Loss=0.1537\n",
            "Epoch[1/2] Step[5641] Loss=0.1244\n",
            "Epoch[1/2] Step[5642] Loss=0.6343\n",
            "Epoch[1/2] Step[5643] Loss=0.2714\n",
            "Epoch[1/2] Step[5644] Loss=0.0752\n",
            "Epoch[1/2] Step[5645] Loss=0.0972\n",
            "Epoch[1/2] Step[5646] Loss=0.1121\n",
            "Epoch[1/2] Step[5647] Loss=0.5375\n",
            "Epoch[1/2] Step[5648] Loss=0.5349\n",
            "Epoch[1/2] Step[5649] Loss=0.1682\n",
            "Epoch[1/2] Step[5650] Loss=0.3941\n",
            "Epoch[1/2] Step[5651] Loss=0.5370\n",
            "Epoch[1/2] Step[5652] Loss=0.8326\n",
            "Epoch[1/2] Step[5653] Loss=0.3228\n",
            "Epoch[1/2] Step[5654] Loss=0.2370\n",
            "Epoch[1/2] Step[5655] Loss=0.2870\n",
            "Epoch[1/2] Step[5656] Loss=0.1568\n",
            "Epoch[1/2] Step[5657] Loss=0.3503\n",
            "Epoch[1/2] Step[5658] Loss=0.2549\n",
            "Epoch[1/2] Step[5659] Loss=0.5092\n",
            "Epoch[1/2] Step[5660] Loss=0.2155\n",
            "Epoch[1/2] Step[5661] Loss=0.2251\n",
            "Epoch[1/2] Step[5662] Loss=0.1138\n",
            "Epoch[1/2] Step[5663] Loss=0.7739\n",
            "Epoch[1/2] Step[5664] Loss=0.1148\n",
            "Epoch[1/2] Step[5665] Loss=0.1947\n",
            "Epoch[1/2] Step[5666] Loss=0.2930\n",
            "Epoch[1/2] Step[5667] Loss=0.0680\n",
            "Epoch[1/2] Step[5668] Loss=0.3054\n",
            "Epoch[1/2] Step[5669] Loss=0.1404\n",
            "Epoch[1/2] Step[5670] Loss=0.5154\n",
            "Epoch[1/2] Step[5671] Loss=0.3443\n",
            "Epoch[1/2] Step[5672] Loss=0.0757\n",
            "Epoch[1/2] Step[5673] Loss=0.1229\n",
            "Epoch[1/2] Step[5674] Loss=0.0755\n",
            "Epoch[1/2] Step[5675] Loss=0.2257\n",
            "Epoch[1/2] Step[5676] Loss=0.4076\n",
            "Epoch[1/2] Step[5677] Loss=0.0638\n",
            "Epoch[1/2] Step[5678] Loss=0.0815\n",
            "Epoch[1/2] Step[5679] Loss=0.1734\n",
            "Epoch[1/2] Step[5680] Loss=0.6325\n",
            "Epoch[1/2] Step[5681] Loss=0.6129\n",
            "Epoch[1/2] Step[5682] Loss=0.1842\n",
            "Epoch[1/2] Step[5683] Loss=0.5019\n",
            "Epoch[1/2] Step[5684] Loss=0.2781\n",
            "Epoch[1/2] Step[5685] Loss=0.8691\n",
            "Epoch[1/2] Step[5686] Loss=0.1620\n",
            "Epoch[1/2] Step[5687] Loss=0.0975\n",
            "Epoch[1/2] Step[5688] Loss=0.2519\n",
            "Epoch[1/2] Step[5689] Loss=0.0901\n",
            "Epoch[1/2] Step[5690] Loss=1.2153\n",
            "Epoch[1/2] Step[5691] Loss=0.2547\n",
            "Epoch[1/2] Step[5692] Loss=0.3412\n",
            "Epoch[1/2] Step[5693] Loss=0.4470\n",
            "Epoch[1/2] Step[5694] Loss=0.1325\n",
            "Epoch[1/2] Step[5695] Loss=0.2628\n",
            "Epoch[1/2] Step[5696] Loss=0.5707\n",
            "Epoch[1/2] Step[5697] Loss=0.2919\n",
            "Epoch[1/2] Step[5698] Loss=0.5259\n",
            "Epoch[1/2] Step[5699] Loss=0.1793\n",
            "Epoch[1/2] Step[5700] Loss=0.1979\n",
            "Epoch[1/2] Step[5701] Loss=0.1826\n",
            "Epoch[1/2] Step[5702] Loss=0.2379\n",
            "Epoch[1/2] Step[5703] Loss=0.9995\n",
            "Epoch[1/2] Step[5704] Loss=0.1951\n",
            "Epoch[1/2] Step[5705] Loss=0.4043\n",
            "Epoch[1/2] Step[5706] Loss=0.0817\n",
            "Epoch[1/2] Step[5707] Loss=0.0877\n",
            "Epoch[1/2] Step[5708] Loss=0.3997\n",
            "Epoch[1/2] Step[5709] Loss=0.1366\n",
            "Epoch[1/2] Step[5710] Loss=0.1039\n",
            "Epoch[1/2] Step[5711] Loss=0.1041\n",
            "Epoch[1/2] Step[5712] Loss=0.2918\n",
            "Epoch[1/2] Step[5713] Loss=0.2033\n",
            "Epoch[1/2] Step[5714] Loss=0.1485\n",
            "Epoch[1/2] Step[5715] Loss=0.3866\n",
            "Epoch[1/2] Step[5716] Loss=0.6265\n",
            "Epoch[1/2] Step[5717] Loss=0.2671\n",
            "Epoch[1/2] Step[5718] Loss=1.4442\n",
            "Epoch[1/2] Step[5719] Loss=0.1461\n",
            "Epoch[1/2] Step[5720] Loss=0.6829\n",
            "Epoch[1/2] Step[5721] Loss=0.3592\n",
            "Epoch[1/2] Step[5722] Loss=0.3226\n",
            "Epoch[1/2] Step[5723] Loss=0.6724\n",
            "Epoch[1/2] Step[5724] Loss=0.1092\n",
            "Epoch[1/2] Step[5725] Loss=0.4463\n",
            "Epoch[1/2] Step[5726] Loss=0.5692\n",
            "Epoch[1/2] Step[5727] Loss=0.4295\n",
            "Epoch[1/2] Step[5728] Loss=0.1902\n",
            "Epoch[1/2] Step[5729] Loss=0.4495\n",
            "Epoch[1/2] Step[5730] Loss=0.0563\n",
            "Epoch[1/2] Step[5731] Loss=0.2295\n",
            "Epoch[1/2] Step[5732] Loss=0.5599\n",
            "Epoch[1/2] Step[5733] Loss=0.3793\n",
            "Epoch[1/2] Step[5734] Loss=0.3019\n",
            "Epoch[1/2] Step[5735] Loss=0.1815\n",
            "Epoch[1/2] Step[5736] Loss=0.2040\n",
            "Epoch[1/2] Step[5737] Loss=0.2859\n",
            "Epoch[1/2] Step[5738] Loss=1.0041\n",
            "Epoch[1/2] Step[5739] Loss=0.2104\n",
            "Epoch[1/2] Step[5740] Loss=0.7697\n",
            "Epoch[1/2] Step[5741] Loss=0.3222\n",
            "Epoch[1/2] Step[5742] Loss=0.2365\n",
            "Epoch[1/2] Step[5743] Loss=0.3629\n",
            "Epoch[1/2] Step[5744] Loss=0.5257\n",
            "Epoch[1/2] Step[5745] Loss=0.0630\n",
            "Epoch[1/2] Step[5746] Loss=0.1634\n",
            "Epoch[1/2] Step[5747] Loss=1.3498\n",
            "Epoch[1/2] Step[5748] Loss=0.3262\n",
            "Epoch[1/2] Step[5749] Loss=0.7720\n",
            "Epoch[1/2] Step[5750] Loss=0.1821\n",
            "Epoch[1/2] Step[5751] Loss=0.5429\n",
            "Epoch[1/2] Step[5752] Loss=0.3395\n",
            "Epoch[1/2] Step[5753] Loss=0.3025\n",
            "Epoch[1/2] Step[5754] Loss=0.3030\n",
            "Epoch[1/2] Step[5755] Loss=0.0706\n",
            "Epoch[1/2] Step[5756] Loss=0.5396\n",
            "Epoch[1/2] Step[5757] Loss=0.4381\n",
            "Epoch[1/2] Step[5758] Loss=0.1145\n",
            "Epoch[1/2] Step[5759] Loss=0.4495\n",
            "Epoch[1/2] Step[5760] Loss=0.2064\n",
            "Epoch[1/2] Step[5761] Loss=0.0677\n",
            "Epoch[1/2] Step[5762] Loss=0.4881\n",
            "Epoch[1/2] Step[5763] Loss=0.4594\n",
            "Epoch[1/2] Step[5764] Loss=0.1960\n",
            "Epoch[1/2] Step[5765] Loss=0.7371\n",
            "Epoch[1/2] Step[5766] Loss=0.0897\n",
            "Epoch[1/2] Step[5767] Loss=0.1922\n",
            "Epoch[1/2] Step[5768] Loss=0.2966\n",
            "Epoch[1/2] Step[5769] Loss=0.0936\n",
            "Epoch[1/2] Step[5770] Loss=0.1749\n",
            "Epoch[1/2] Step[5771] Loss=0.2309\n",
            "Epoch[1/2] Step[5772] Loss=0.9815\n",
            "Epoch[1/2] Step[5773] Loss=0.4960\n",
            "Epoch[1/2] Step[5774] Loss=0.1705\n",
            "Epoch[1/2] Step[5775] Loss=0.4306\n",
            "Epoch[1/2] Step[5776] Loss=0.3389\n",
            "Epoch[1/2] Step[5777] Loss=0.4700\n",
            "Epoch[1/2] Step[5778] Loss=0.0819\n",
            "Epoch[1/2] Step[5779] Loss=0.2501\n",
            "Epoch[1/2] Step[5780] Loss=0.7737\n",
            "Epoch[1/2] Step[5781] Loss=0.4186\n",
            "Epoch[1/2] Step[5782] Loss=0.3980\n",
            "Epoch[1/2] Step[5783] Loss=0.3264\n",
            "Epoch[1/2] Step[5784] Loss=0.2150\n",
            "Epoch[1/2] Step[5785] Loss=0.5224\n",
            "Epoch[1/2] Step[5786] Loss=0.2308\n",
            "Epoch[1/2] Step[5787] Loss=0.8293\n",
            "Epoch[1/2] Step[5788] Loss=0.8630\n",
            "Epoch[1/2] Step[5789] Loss=0.5405\n",
            "Epoch[1/2] Step[5790] Loss=0.8400\n",
            "Epoch[1/2] Step[5791] Loss=0.0943\n",
            "Epoch[1/2] Step[5792] Loss=0.2649\n",
            "Epoch[1/2] Step[5793] Loss=0.1051\n",
            "Epoch[1/2] Step[5794] Loss=0.2088\n",
            "Epoch[1/2] Step[5795] Loss=0.0801\n",
            "Epoch[1/2] Step[5796] Loss=0.3990\n",
            "Epoch[1/2] Step[5797] Loss=0.1567\n",
            "Epoch[1/2] Step[5798] Loss=0.6856\n",
            "Epoch[1/2] Step[5799] Loss=0.3842\n",
            "Epoch[1/2] Step[5800] Loss=0.1887\n",
            "Epoch[1/2] Step[5801] Loss=0.6845\n",
            "Epoch[1/2] Step[5802] Loss=0.1539\n",
            "Epoch[1/2] Step[5803] Loss=0.2607\n",
            "Epoch[1/2] Step[5804] Loss=0.4410\n",
            "Epoch[1/2] Step[5805] Loss=0.4104\n",
            "Epoch[1/2] Step[5806] Loss=0.5180\n",
            "Epoch[1/2] Step[5807] Loss=0.2120\n",
            "Epoch[1/2] Step[5808] Loss=0.2130\n",
            "Epoch[1/2] Step[5809] Loss=0.5544\n",
            "Epoch[1/2] Step[5810] Loss=0.7824\n",
            "Epoch[1/2] Step[5811] Loss=0.1839\n",
            "Epoch[1/2] Step[5812] Loss=0.1842\n",
            "Epoch[1/2] Step[5813] Loss=0.1839\n",
            "Epoch[1/2] Step[5814] Loss=0.4733\n",
            "Epoch[1/2] Step[5815] Loss=0.2560\n",
            "Epoch[1/2] Step[5816] Loss=0.3883\n",
            "Epoch[1/2] Step[5817] Loss=0.3619\n",
            "Epoch[1/2] Step[5818] Loss=0.3517\n",
            "Epoch[1/2] Step[5819] Loss=0.5538\n",
            "Epoch[1/2] Step[5820] Loss=0.0780\n",
            "Epoch[1/2] Step[5821] Loss=0.4083\n",
            "Epoch[1/2] Step[5822] Loss=0.1588\n",
            "Epoch[1/2] Step[5823] Loss=0.3040\n",
            "Epoch[1/2] Step[5824] Loss=0.2291\n",
            "Epoch[1/2] Step[5825] Loss=0.2474\n",
            "Epoch[1/2] Step[5826] Loss=0.2589\n",
            "Epoch[1/2] Step[5827] Loss=0.5394\n",
            "Epoch[1/2] Step[5828] Loss=0.6097\n",
            "Epoch[1/2] Step[5829] Loss=0.0975\n",
            "Epoch[1/2] Step[5830] Loss=0.3245\n",
            "Epoch[1/2] Step[5831] Loss=0.3420\n",
            "Epoch[1/2] Step[5832] Loss=0.0982\n",
            "Epoch[1/2] Step[5833] Loss=0.2848\n",
            "Epoch[1/2] Step[5834] Loss=0.1064\n",
            "Epoch[1/2] Step[5835] Loss=0.2381\n",
            "Epoch[1/2] Step[5836] Loss=0.7128\n",
            "Epoch[1/2] Step[5837] Loss=0.2297\n",
            "Epoch[1/2] Step[5838] Loss=0.2770\n",
            "Epoch[1/2] Step[5839] Loss=0.6663\n",
            "Epoch[1/2] Step[5840] Loss=0.2198\n",
            "Epoch[1/2] Step[5841] Loss=0.3594\n",
            "Epoch[1/2] Step[5842] Loss=0.3371\n",
            "Epoch[1/2] Step[5843] Loss=0.4779\n",
            "Epoch[1/2] Step[5844] Loss=0.0893\n",
            "Epoch[1/2] Step[5845] Loss=0.2396\n",
            "Epoch[1/2] Step[5846] Loss=0.4704\n",
            "Epoch[1/2] Step[5847] Loss=0.4358\n",
            "Epoch[1/2] Step[5848] Loss=0.5256\n",
            "Epoch[1/2] Step[5849] Loss=0.1643\n",
            "Epoch[1/2] Step[5850] Loss=0.1266\n",
            "Epoch[1/2] Step[5851] Loss=0.2528\n",
            "Epoch[1/2] Step[5852] Loss=0.2058\n",
            "Epoch[1/2] Step[5853] Loss=0.1687\n",
            "Epoch[1/2] Step[5854] Loss=0.3356\n",
            "Epoch[1/2] Step[5855] Loss=0.0815\n",
            "Epoch[1/2] Step[5856] Loss=0.1115\n",
            "Epoch[1/2] Step[5857] Loss=0.2423\n",
            "Epoch[1/2] Step[5858] Loss=0.4313\n",
            "Epoch[1/2] Step[5859] Loss=0.1552\n",
            "Epoch[1/2] Step[5860] Loss=0.0748\n",
            "Epoch[1/2] Step[5861] Loss=0.1644\n",
            "Epoch[1/2] Step[5862] Loss=0.6613\n",
            "Epoch[1/2] Step[5863] Loss=0.2252\n",
            "Epoch[1/2] Step[5864] Loss=0.1510\n",
            "Epoch[1/2] Step[5865] Loss=0.4963\n",
            "Epoch[1/2] Step[5866] Loss=0.2439\n",
            "Epoch[1/2] Step[5867] Loss=0.4865\n",
            "Epoch[1/2] Step[5868] Loss=0.4035\n",
            "Epoch[1/2] Step[5869] Loss=0.4258\n",
            "Epoch[1/2] Step[5870] Loss=0.3792\n",
            "Epoch[1/2] Step[5871] Loss=0.0758\n",
            "Epoch[1/2] Step[5872] Loss=0.1437\n",
            "Epoch[1/2] Step[5873] Loss=0.0543\n",
            "Epoch[1/2] Step[5874] Loss=0.3511\n",
            "Epoch[1/2] Step[5875] Loss=0.2622\n",
            "Epoch[1/2] Step[5876] Loss=0.0967\n",
            "Epoch[1/2] Step[5877] Loss=0.3499\n",
            "Epoch[1/2] Step[5878] Loss=0.0528\n",
            "Epoch[1/2] Step[5879] Loss=0.3848\n",
            "Epoch[1/2] Step[5880] Loss=0.1825\n",
            "Epoch[1/2] Step[5881] Loss=0.2501\n",
            "Epoch[1/2] Step[5882] Loss=0.3972\n",
            "Epoch[1/2] Step[5883] Loss=0.4310\n",
            "Epoch[1/2] Step[5884] Loss=0.2482\n",
            "Epoch[1/2] Step[5885] Loss=0.2928\n",
            "Epoch[1/2] Step[5886] Loss=0.7499\n",
            "Epoch[1/2] Step[5887] Loss=0.1345\n",
            "Epoch[1/2] Step[5888] Loss=0.3745\n",
            "Epoch[1/2] Step[5889] Loss=0.1069\n",
            "Epoch[1/2] Step[5890] Loss=0.1218\n",
            "Epoch[1/2] Step[5891] Loss=0.3441\n",
            "Epoch[1/2] Step[5892] Loss=0.3147\n",
            "Epoch[1/2] Step[5893] Loss=0.0470\n",
            "Epoch[1/2] Step[5894] Loss=0.1573\n",
            "Epoch[1/2] Step[5895] Loss=0.6122\n",
            "Epoch[1/2] Step[5896] Loss=0.4813\n",
            "Epoch[1/2] Step[5897] Loss=0.2558\n",
            "Epoch[1/2] Step[5898] Loss=0.0457\n",
            "Epoch[1/2] Step[5899] Loss=0.3507\n",
            "Epoch[1/2] Step[5900] Loss=0.2163\n",
            "Epoch[1/2] Step[5901] Loss=0.1608\n",
            "Epoch[1/2] Step[5902] Loss=0.5937\n",
            "Epoch[1/2] Step[5903] Loss=0.2099\n",
            "Epoch[1/2] Step[5904] Loss=0.3036\n",
            "Epoch[1/2] Step[5905] Loss=0.7623\n",
            "Epoch[1/2] Step[5906] Loss=0.4344\n",
            "Epoch[1/2] Step[5907] Loss=0.1878\n",
            "Epoch[1/2] Step[5908] Loss=0.1675\n",
            "Epoch[1/2] Step[5909] Loss=0.2450\n",
            "Epoch[1/2] Step[5910] Loss=0.2534\n",
            "Epoch[1/2] Step[5911] Loss=0.1518\n",
            "Epoch[1/2] Step[5912] Loss=0.8345\n",
            "Epoch[1/2] Step[5913] Loss=0.2420\n",
            "Epoch[1/2] Step[5914] Loss=0.3362\n",
            "Epoch[1/2] Step[5915] Loss=0.1862\n",
            "Epoch[1/2] Step[5916] Loss=0.3177\n",
            "Epoch[1/2] Step[5917] Loss=0.2613\n",
            "Epoch[1/2] Step[5918] Loss=0.5451\n",
            "Epoch[1/2] Step[5919] Loss=0.0409\n",
            "Epoch[1/2] Step[5920] Loss=0.2043\n",
            "Epoch[1/2] Step[5921] Loss=0.6679\n",
            "Epoch[1/2] Step[5922] Loss=0.2870\n",
            "Epoch[1/2] Step[5923] Loss=0.0542\n",
            "Epoch[1/2] Step[5924] Loss=0.2621\n",
            "Epoch[1/2] Step[5925] Loss=0.5300\n",
            "Epoch[1/2] Step[5926] Loss=0.3386\n",
            "Epoch[1/2] Step[5927] Loss=0.2713\n",
            "Epoch[1/2] Step[5928] Loss=0.1662\n",
            "Epoch[1/2] Step[5929] Loss=0.5740\n",
            "Epoch[1/2] Step[5930] Loss=0.2333\n",
            "Epoch[1/2] Step[5931] Loss=0.2337\n",
            "Epoch[1/2] Step[5932] Loss=0.1992\n",
            "Epoch[1/2] Step[5933] Loss=0.0546\n",
            "Epoch[1/2] Step[5934] Loss=0.3936\n",
            "Epoch[1/2] Step[5935] Loss=0.3486\n",
            "Epoch[1/2] Step[5936] Loss=0.4179\n",
            "Epoch[1/2] Step[5937] Loss=0.1228\n",
            "Epoch[1/2] Step[5938] Loss=0.8408\n",
            "Epoch[1/2] Step[5939] Loss=0.7432\n",
            "Epoch[1/2] Step[5940] Loss=0.1646\n",
            "Epoch[1/2] Step[5941] Loss=0.3723\n",
            "Epoch[1/2] Step[5942] Loss=0.1610\n",
            "Epoch[1/2] Step[5943] Loss=0.1258\n",
            "Epoch[1/2] Step[5944] Loss=0.5210\n",
            "Epoch[1/2] Step[5945] Loss=0.0858\n",
            "Epoch[1/2] Step[5946] Loss=0.1389\n",
            "Epoch[1/2] Step[5947] Loss=0.1449\n",
            "Epoch[1/2] Step[5948] Loss=0.1077\n",
            "Epoch[1/2] Step[5949] Loss=0.1245\n",
            "Epoch[1/2] Step[5950] Loss=0.0820\n",
            "Epoch[1/2] Step[5951] Loss=0.0840\n",
            "Epoch[1/2] Step[5952] Loss=0.0552\n",
            "Epoch[1/2] Step[5953] Loss=0.6683\n",
            "Epoch[1/2] Step[5954] Loss=0.2181\n",
            "Epoch[1/2] Step[5955] Loss=0.2503\n",
            "Epoch[1/2] Step[5956] Loss=0.0730\n",
            "Epoch[1/2] Step[5957] Loss=0.7437\n",
            "Epoch[1/2] Step[5958] Loss=0.3610\n",
            "Epoch[1/2] Step[5959] Loss=0.4415\n",
            "Epoch[1/2] Step[5960] Loss=0.1203\n",
            "Epoch[1/2] Step[5961] Loss=0.3701\n",
            "Epoch[1/2] Step[5962] Loss=0.5235\n",
            "Epoch[1/2] Step[5963] Loss=0.2467\n",
            "Epoch[1/2] Step[5964] Loss=0.2739\n",
            "Epoch[1/2] Step[5965] Loss=0.2988\n",
            "Epoch[1/2] Step[5966] Loss=0.4861\n",
            "Epoch[1/2] Step[5967] Loss=0.1058\n",
            "Epoch[1/2] Step[5968] Loss=0.2411\n",
            "Epoch[1/2] Step[5969] Loss=0.2021\n",
            "Epoch[1/2] Step[5970] Loss=0.2720\n",
            "Epoch[1/2] Step[5971] Loss=0.3003\n",
            "Epoch[1/2] Step[5972] Loss=0.2440\n",
            "Epoch[1/2] Step[5973] Loss=0.2561\n",
            "Epoch[1/2] Step[5974] Loss=0.2800\n",
            "Epoch[1/2] Step[5975] Loss=0.2839\n",
            "Epoch[1/2] Step[5976] Loss=0.1200\n",
            "Epoch[1/2] Step[5977] Loss=0.0558\n",
            "Epoch[1/2] Step[5978] Loss=0.7190\n",
            "Epoch[1/2] Step[5979] Loss=0.3805\n",
            "Epoch[1/2] Step[5980] Loss=0.6711\n",
            "Epoch[1/2] Step[5981] Loss=0.5947\n",
            "Epoch[1/2] Step[5982] Loss=0.5040\n",
            "Epoch[1/2] Step[5983] Loss=0.2803\n",
            "Epoch[1/2] Step[5984] Loss=0.2456\n",
            "Epoch[1/2] Step[5985] Loss=0.4910\n",
            "Epoch[1/2] Step[5986] Loss=0.0829\n",
            "Epoch[1/2] Step[5987] Loss=0.1613\n",
            "Epoch[1/2] Step[5988] Loss=0.1060\n",
            "Epoch[1/2] Step[5989] Loss=0.5296\n",
            "Epoch[1/2] Step[5990] Loss=0.4131\n",
            "Epoch[1/2] Step[5991] Loss=0.3413\n",
            "Epoch[1/2] Step[5992] Loss=0.4404\n",
            "Epoch[1/2] Step[5993] Loss=0.1241\n",
            "Epoch[1/2] Step[5994] Loss=0.1604\n",
            "Epoch[1/2] Step[5995] Loss=0.3968\n",
            "Epoch[1/2] Step[5996] Loss=0.2268\n",
            "Epoch[1/2] Step[5997] Loss=0.2599\n",
            "Epoch[1/2] Step[5998] Loss=0.2610\n",
            "Epoch[1/2] Step[5999] Loss=0.3360\n",
            "Epoch[1/2] Step[6000] Loss=0.1701\n",
            "Epoch[1/2] Step[6001] Loss=0.7653\n",
            "Epoch[1/2] Step[6002] Loss=0.2311\n",
            "Epoch[1/2] Step[6003] Loss=0.3862\n",
            "Epoch[1/2] Step[6004] Loss=0.3109\n",
            "Epoch[1/2] Step[6005] Loss=0.2463\n",
            "Epoch[1/2] Step[6006] Loss=0.2307\n",
            "Epoch[1/2] Step[6007] Loss=0.1380\n",
            "Epoch[1/2] Step[6008] Loss=0.3058\n",
            "Epoch[1/2] Step[6009] Loss=0.5384\n",
            "Epoch[1/2] Step[6010] Loss=0.6563\n",
            "Epoch[1/2] Step[6011] Loss=0.5718\n",
            "Epoch[1/2] Step[6012] Loss=0.0824\n",
            "Epoch[1/2] Step[6013] Loss=0.1932\n",
            "Epoch[1/2] Step[6014] Loss=1.1990\n",
            "Epoch[1/2] Step[6015] Loss=0.4435\n",
            "Epoch[1/2] Step[6016] Loss=0.7128\n",
            "Epoch[1/2] Step[6017] Loss=0.0652\n",
            "Epoch[1/2] Step[6018] Loss=0.3911\n",
            "Epoch[1/2] Step[6019] Loss=0.5148\n",
            "Epoch[1/2] Step[6020] Loss=0.3794\n",
            "Epoch[1/2] Step[6021] Loss=0.1332\n",
            "Epoch[1/2] Step[6022] Loss=0.1999\n",
            "Epoch[1/2] Step[6023] Loss=0.0954\n",
            "Epoch[1/2] Step[6024] Loss=0.4094\n",
            "Epoch[1/2] Step[6025] Loss=0.3095\n",
            "Epoch[1/2] Step[6026] Loss=0.4027\n",
            "Epoch[1/2] Step[6027] Loss=0.3158\n",
            "Epoch[1/2] Step[6028] Loss=0.0941\n",
            "Epoch[1/2] Step[6029] Loss=0.0225\n",
            "Epoch[1/2] Step[6030] Loss=0.1120\n",
            "Epoch[1/2] Step[6031] Loss=0.4195\n",
            "Epoch[1/2] Step[6032] Loss=0.5156\n",
            "Epoch[1/2] Step[6033] Loss=0.2312\n",
            "Epoch[1/2] Step[6034] Loss=0.7329\n",
            "Epoch[1/2] Step[6035] Loss=0.5114\n",
            "Epoch[1/2] Step[6036] Loss=0.3969\n",
            "Epoch[1/2] Step[6037] Loss=0.3845\n",
            "Epoch[1/2] Step[6038] Loss=0.1266\n",
            "Epoch[1/2] Step[6039] Loss=0.1446\n",
            "Epoch[1/2] Step[6040] Loss=0.5499\n",
            "Epoch[1/2] Step[6041] Loss=0.1541\n",
            "Epoch[1/2] Step[6042] Loss=0.1227\n",
            "Epoch[1/2] Step[6043] Loss=0.3874\n",
            "Epoch[1/2] Step[6044] Loss=0.2013\n",
            "Epoch[1/2] Step[6045] Loss=0.1766\n",
            "Epoch[1/2] Step[6046] Loss=0.2388\n",
            "Epoch[1/2] Step[6047] Loss=0.4969\n",
            "Epoch[1/2] Step[6048] Loss=0.0814\n",
            "Epoch[1/2] Step[6049] Loss=0.5717\n",
            "Epoch[1/2] Step[6050] Loss=0.3034\n",
            "Epoch[1/2] Step[6051] Loss=0.2876\n",
            "Epoch[1/2] Step[6052] Loss=0.9180\n",
            "Epoch[1/2] Step[6053] Loss=0.2824\n",
            "Epoch[1/2] Step[6054] Loss=1.1788\n",
            "Epoch[1/2] Step[6055] Loss=0.1722\n",
            "Epoch[1/2] Step[6056] Loss=0.2137\n",
            "Epoch[1/2] Step[6057] Loss=0.2922\n",
            "Epoch[1/2] Step[6058] Loss=0.4068\n",
            "Epoch[1/2] Step[6059] Loss=0.3237\n",
            "Epoch[1/2] Step[6060] Loss=0.1657\n",
            "Epoch[1/2] Step[6061] Loss=0.0955\n",
            "Epoch[1/2] Step[6062] Loss=0.0620\n",
            "Epoch[1/2] Step[6063] Loss=0.2435\n",
            "Epoch[1/2] Step[6064] Loss=0.3263\n",
            "Epoch[1/2] Step[6065] Loss=0.2062\n",
            "Epoch[1/2] Step[6066] Loss=0.1811\n",
            "Epoch[1/2] Step[6067] Loss=0.3562\n",
            "Epoch[1/2] Step[6068] Loss=0.0495\n",
            "Epoch[1/2] Step[6069] Loss=0.4701\n",
            "Epoch[1/2] Step[6070] Loss=0.4309\n",
            "Epoch[1/2] Step[6071] Loss=0.3474\n",
            "Epoch[1/2] Step[6072] Loss=0.4003\n",
            "Epoch[1/2] Step[6073] Loss=0.2746\n",
            "Epoch[1/2] Step[6074] Loss=0.4970\n",
            "Epoch[1/2] Step[6075] Loss=0.2794\n",
            "Epoch[1/2] Step[6076] Loss=0.0620\n",
            "Epoch[1/2] Step[6077] Loss=0.1532\n",
            "Epoch[1/2] Step[6078] Loss=0.7812\n",
            "Epoch[1/2] Step[6079] Loss=0.4226\n",
            "Epoch[1/2] Step[6080] Loss=0.6397\n",
            "Epoch[1/2] Step[6081] Loss=0.0867\n",
            "Epoch[1/2] Step[6082] Loss=0.2708\n",
            "Epoch[1/2] Step[6083] Loss=0.4383\n",
            "Epoch[1/2] Step[6084] Loss=0.5815\n",
            "Epoch[1/2] Step[6085] Loss=0.0940\n",
            "Epoch[1/2] Step[6086] Loss=0.4617\n",
            "Epoch[1/2] Step[6087] Loss=0.1234\n",
            "Epoch[1/2] Step[6088] Loss=0.4617\n",
            "Epoch[1/2] Step[6089] Loss=0.1724\n",
            "Epoch[1/2] Step[6090] Loss=0.4784\n",
            "Epoch[1/2] Step[6091] Loss=0.1807\n",
            "Epoch[1/2] Step[6092] Loss=0.1287\n",
            "Epoch[1/2] Step[6093] Loss=0.2683\n",
            "Epoch[1/2] Step[6094] Loss=0.3459\n",
            "Epoch[1/2] Step[6095] Loss=0.5122\n",
            "Epoch[1/2] Step[6096] Loss=0.2861\n",
            "Epoch[1/2] Step[6097] Loss=0.1663\n",
            "Epoch[1/2] Step[6098] Loss=0.2598\n",
            "Epoch[1/2] Step[6099] Loss=0.2725\n",
            "Epoch[1/2] Step[6100] Loss=0.7649\n",
            "Epoch[1/2] Step[6101] Loss=0.0833\n",
            "Epoch[1/2] Step[6102] Loss=0.1573\n",
            "Epoch[1/2] Step[6103] Loss=0.1434\n",
            "Epoch[1/2] Step[6104] Loss=0.5095\n",
            "Epoch[1/2] Step[6105] Loss=0.7318\n",
            "Epoch[1/2] Step[6106] Loss=0.2082\n",
            "Epoch[1/2] Step[6107] Loss=0.5608\n",
            "Epoch[1/2] Step[6108] Loss=0.1294\n",
            "Epoch[1/2] Step[6109] Loss=0.1137\n",
            "Epoch[1/2] Step[6110] Loss=0.7141\n",
            "Epoch[1/2] Step[6111] Loss=0.1984\n",
            "Epoch[1/2] Step[6112] Loss=0.0444\n",
            "Epoch[1/2] Step[6113] Loss=0.0955\n",
            "Epoch[1/2] Step[6114] Loss=0.0727\n",
            "Epoch[1/2] Step[6115] Loss=0.2579\n",
            "Epoch[1/2] Step[6116] Loss=0.4588\n",
            "Epoch[1/2] Step[6117] Loss=0.3047\n",
            "Epoch[1/2] Step[6118] Loss=0.0595\n",
            "Epoch[1/2] Step[6119] Loss=0.3635\n",
            "Epoch[1/2] Step[6120] Loss=0.4451\n",
            "Epoch[1/2] Step[6121] Loss=0.0774\n",
            "Epoch[1/2] Step[6122] Loss=0.1652\n",
            "Epoch[1/2] Step[6123] Loss=0.5669\n",
            "Epoch[1/2] Step[6124] Loss=0.1348\n",
            "Epoch[1/2] Step[6125] Loss=0.1085\n",
            "Epoch[1/2] Step[6126] Loss=0.0351\n",
            "Epoch[1/2] Step[6127] Loss=0.3029\n",
            "Epoch[1/2] Step[6128] Loss=0.1192\n",
            "Epoch[1/2] Step[6129] Loss=0.1965\n",
            "Epoch[1/2] Step[6130] Loss=0.2449\n",
            "Epoch[1/2] Step[6131] Loss=0.0395\n",
            "Epoch[1/2] Step[6132] Loss=0.1225\n",
            "Epoch[1/2] Step[6133] Loss=0.4412\n",
            "Epoch[1/2] Step[6134] Loss=0.0407\n",
            "Epoch[1/2] Step[6135] Loss=0.3333\n",
            "Epoch[1/2] Step[6136] Loss=0.4473\n",
            "Epoch[1/2] Step[6137] Loss=0.1035\n",
            "Epoch[1/2] Step[6138] Loss=0.5068\n",
            "Epoch[1/2] Step[6139] Loss=0.3107\n",
            "Epoch[1/2] Step[6140] Loss=0.1680\n",
            "Epoch[1/2] Step[6141] Loss=0.1544\n",
            "Epoch[1/2] Step[6142] Loss=0.4194\n",
            "Epoch[1/2] Step[6143] Loss=0.1933\n",
            "Epoch[1/2] Step[6144] Loss=0.5102\n",
            "Epoch[1/2] Step[6145] Loss=0.6357\n",
            "Epoch[1/2] Step[6146] Loss=0.6441\n",
            "Epoch[1/2] Step[6147] Loss=0.0880\n",
            "Epoch[1/2] Step[6148] Loss=0.2547\n",
            "Epoch[1/2] Step[6149] Loss=0.2878\n",
            "Epoch[1/2] Step[6150] Loss=0.3280\n",
            "Epoch[1/2] Step[6151] Loss=0.3125\n",
            "Epoch[1/2] Step[6152] Loss=0.3503\n",
            "Epoch[1/2] Step[6153] Loss=0.3854\n",
            "Epoch[1/2] Step[6154] Loss=0.2109\n",
            "Epoch[1/2] Step[6155] Loss=0.4884\n",
            "Epoch[1/2] Step[6156] Loss=0.1895\n",
            "Epoch[1/2] Step[6157] Loss=0.4247\n",
            "Epoch[1/2] Step[6158] Loss=0.2908\n",
            "Epoch[1/2] Step[6159] Loss=0.2611\n",
            "Epoch[1/2] Step[6160] Loss=0.2548\n",
            "Epoch[1/2] Step[6161] Loss=0.0354\n",
            "Epoch[1/2] Step[6162] Loss=0.0783\n",
            "Epoch[1/2] Step[6163] Loss=1.1024\n",
            "Epoch[1/2] Step[6164] Loss=0.0841\n",
            "Epoch[1/2] Step[6165] Loss=0.2519\n",
            "Epoch[1/2] Step[6166] Loss=0.4859\n",
            "Epoch[1/2] Step[6167] Loss=0.0611\n",
            "Epoch[1/2] Step[6168] Loss=0.2171\n",
            "Epoch[1/2] Step[6169] Loss=0.3825\n",
            "Epoch[1/2] Step[6170] Loss=0.2110\n",
            "Epoch[1/2] Step[6171] Loss=0.1955\n",
            "Epoch[1/2] Step[6172] Loss=0.1941\n",
            "Epoch[1/2] Step[6173] Loss=0.3555\n",
            "Epoch[1/2] Step[6174] Loss=0.3325\n",
            "Epoch[1/2] Step[6175] Loss=0.3593\n",
            "Epoch[1/2] Step[6176] Loss=0.2453\n",
            "Epoch[1/2] Step[6177] Loss=0.3144\n",
            "Epoch[1/2] Step[6178] Loss=0.1937\n",
            "Epoch[1/2] Step[6179] Loss=0.5195\n",
            "Epoch[1/2] Step[6180] Loss=0.4090\n",
            "Epoch[1/2] Step[6181] Loss=0.3640\n",
            "Epoch[1/2] Step[6182] Loss=0.3004\n",
            "Epoch[1/2] Step[6183] Loss=0.6845\n",
            "Epoch[1/2] Step[6184] Loss=0.1470\n",
            "Epoch[1/2] Step[6185] Loss=0.5948\n",
            "Epoch[1/2] Step[6186] Loss=0.1529\n",
            "Epoch[1/2] Step[6187] Loss=0.2414\n",
            "Epoch[1/2] Step[6188] Loss=0.6639\n",
            "Epoch[1/2] Step[6189] Loss=0.2768\n",
            "Epoch[1/2] Step[6190] Loss=0.3442\n",
            "Epoch[1/2] Step[6191] Loss=0.2171\n",
            "Epoch[1/2] Step[6192] Loss=0.2250\n",
            "Epoch[1/2] Step[6193] Loss=0.0426\n",
            "Epoch[1/2] Step[6194] Loss=0.5840\n",
            "Epoch[1/2] Step[6195] Loss=0.1858\n",
            "Epoch[1/2] Step[6196] Loss=0.4124\n",
            "Epoch[1/2] Step[6197] Loss=0.3692\n",
            "Epoch[1/2] Step[6198] Loss=1.0098\n",
            "Epoch[1/2] Step[6199] Loss=0.2943\n",
            "Epoch[1/2] Step[6200] Loss=0.2813\n",
            "Epoch[1/2] Step[6201] Loss=0.5504\n",
            "Epoch[1/2] Step[6202] Loss=0.1292\n",
            "Epoch[1/2] Step[6203] Loss=0.7631\n",
            "Epoch[1/2] Step[6204] Loss=0.3222\n",
            "Epoch[1/2] Step[6205] Loss=0.2056\n",
            "Epoch[1/2] Step[6206] Loss=0.2995\n",
            "Epoch[1/2] Step[6207] Loss=0.4329\n",
            "Epoch[1/2] Step[6208] Loss=0.4415\n",
            "Epoch[1/2] Step[6209] Loss=0.2132\n",
            "Epoch[1/2] Step[6210] Loss=0.1835\n",
            "Epoch[1/2] Step[6211] Loss=0.4985\n",
            "Epoch[1/2] Step[6212] Loss=0.1157\n",
            "Epoch[1/2] Step[6213] Loss=0.0427\n",
            "Epoch[1/2] Step[6214] Loss=0.6022\n",
            "Epoch[1/2] Step[6215] Loss=0.4192\n",
            "Epoch[1/2] Step[6216] Loss=0.4433\n",
            "Epoch[1/2] Step[6217] Loss=0.3854\n",
            "Epoch[1/2] Step[6218] Loss=0.3940\n",
            "Epoch[1/2] Step[6219] Loss=0.3171\n",
            "Epoch[1/2] Step[6220] Loss=0.1521\n",
            "Epoch[1/2] Step[6221] Loss=0.4030\n",
            "Epoch[1/2] Step[6222] Loss=0.4427\n",
            "Epoch[1/2] Step[6223] Loss=0.2921\n",
            "Epoch[1/2] Step[6224] Loss=0.7096\n",
            "Epoch[1/2] Step[6225] Loss=0.3715\n",
            "Epoch[1/2] Step[6226] Loss=0.0709\n",
            "Epoch[1/2] Step[6227] Loss=0.3510\n",
            "Epoch[1/2] Step[6228] Loss=0.3628\n",
            "Epoch[1/2] Step[6229] Loss=0.2680\n",
            "Epoch[1/2] Step[6230] Loss=0.1800\n",
            "Epoch[1/2] Step[6231] Loss=0.1403\n",
            "Epoch[1/2] Step[6232] Loss=0.1533\n",
            "Epoch[1/2] Step[6233] Loss=0.4931\n",
            "Epoch[1/2] Step[6234] Loss=0.1229\n",
            "Epoch[1/2] Step[6235] Loss=0.5888\n",
            "Epoch[1/2] Step[6236] Loss=0.3002\n",
            "Epoch[1/2] Step[6237] Loss=0.5082\n",
            "Epoch[1/2] Step[6238] Loss=0.5051\n",
            "Epoch[1/2] Step[6239] Loss=0.1508\n",
            "Epoch[1/2] Step[6240] Loss=0.2277\n",
            "Epoch[1/2] Step[6241] Loss=0.3225\n",
            "Epoch[1/2] Step[6242] Loss=0.4487\n",
            "Epoch[1/2] Step[6243] Loss=0.4402\n",
            "Epoch[1/2] Step[6244] Loss=0.5775\n",
            "Epoch[1/2] Step[6245] Loss=0.3086\n",
            "Epoch[1/2] Step[6246] Loss=0.2701\n",
            "Epoch[1/2] Step[6247] Loss=0.1072\n",
            "Epoch[1/2] Step[6248] Loss=0.2656\n",
            "Epoch[1/2] Step[6249] Loss=0.1751\n",
            "Epoch[1/2] Step[6250] Loss=1.2837\n",
            "Epoch[1/2] Step[6251] Loss=0.4067\n",
            "Epoch[1/2] Step[6252] Loss=0.2618\n",
            "Epoch[1/2] Step[6253] Loss=0.3235\n",
            "Epoch[1/2] Step[6254] Loss=0.3834\n",
            "Epoch[1/2] Step[6255] Loss=0.3588\n",
            "Epoch[1/2] Step[6256] Loss=0.3762\n",
            "Epoch[1/2] Step[6257] Loss=0.2998\n",
            "Epoch[1/2] Step[6258] Loss=0.5530\n",
            "Epoch[1/2] Step[6259] Loss=0.1881\n",
            "Epoch[1/2] Step[6260] Loss=0.1552\n",
            "Epoch[1/2] Step[6261] Loss=0.2840\n",
            "Epoch[1/2] Step[6262] Loss=0.1570\n",
            "Epoch[1/2] Step[6263] Loss=0.2009\n",
            "Epoch[1/2] Step[6264] Loss=0.2551\n",
            "Epoch[1/2] Step[6265] Loss=0.4547\n",
            "Epoch[1/2] Step[6266] Loss=0.1182\n",
            "Epoch[1/2] Step[6267] Loss=0.0817\n",
            "Epoch[1/2] Step[6268] Loss=0.2000\n",
            "Epoch[1/2] Step[6269] Loss=0.2962\n",
            "Epoch[1/2] Step[6270] Loss=0.3457\n",
            "Epoch[1/2] Step[6271] Loss=0.2253\n",
            "Epoch[1/2] Step[6272] Loss=0.2739\n",
            "Epoch[1/2] Step[6273] Loss=0.1296\n",
            "Epoch[1/2] Step[6274] Loss=0.2508\n",
            "Epoch[1/2] Step[6275] Loss=0.0428\n",
            "Epoch[1/2] Step[6276] Loss=0.4729\n",
            "Epoch[1/2] Step[6277] Loss=0.3210\n",
            "Epoch[1/2] Step[6278] Loss=0.1229\n",
            "Epoch[1/2] Step[6279] Loss=0.4131\n",
            "Epoch[1/2] Step[6280] Loss=0.0627\n",
            "Epoch[1/2] Step[6281] Loss=0.6654\n",
            "Epoch[1/2] Step[6282] Loss=0.2153\n",
            "Epoch[1/2] Step[6283] Loss=0.7809\n",
            "Epoch[1/2] Step[6284] Loss=0.1728\n",
            "Epoch[1/2] Step[6285] Loss=0.3107\n",
            "Epoch[1/2] Step[6286] Loss=0.1558\n",
            "Epoch[1/2] Step[6287] Loss=0.2820\n",
            "Epoch[1/2] Step[6288] Loss=0.3333\n",
            "Epoch[1/2] Step[6289] Loss=0.1327\n",
            "Epoch[1/2] Step[6290] Loss=0.4221\n",
            "Epoch[1/2] Step[6291] Loss=0.3436\n",
            "Epoch[1/2] Step[6292] Loss=0.3091\n",
            "Epoch[1/2] Step[6293] Loss=0.2534\n",
            "Epoch[1/2] Step[6294] Loss=0.4232\n",
            "Epoch[1/2] Step[6295] Loss=0.3611\n",
            "Epoch[1/2] Step[6296] Loss=1.0909\n",
            "Epoch[1/2] Step[6297] Loss=0.3506\n",
            "Epoch[1/2] Step[6298] Loss=0.1848\n",
            "Epoch[1/2] Step[6299] Loss=0.1630\n",
            "Epoch[1/2] Step[6300] Loss=0.1833\n",
            "Epoch[1/2] Step[6301] Loss=0.1272\n",
            "Epoch[1/2] Step[6302] Loss=0.1102\n",
            "Epoch[1/2] Step[6303] Loss=0.2827\n",
            "Epoch[1/2] Step[6304] Loss=0.9317\n",
            "Epoch[1/2] Step[6305] Loss=0.3948\n",
            "Epoch[1/2] Step[6306] Loss=0.2683\n",
            "Epoch[1/2] Step[6307] Loss=0.2384\n",
            "Epoch[1/2] Step[6308] Loss=0.4469\n",
            "Epoch[1/2] Step[6309] Loss=0.3070\n",
            "Epoch[1/2] Step[6310] Loss=0.2845\n",
            "Epoch[1/2] Step[6311] Loss=0.4066\n",
            "Epoch[1/2] Step[6312] Loss=0.1636\n",
            "Epoch[1/2] Step[6313] Loss=0.5943\n",
            "Epoch[1/2] Step[6314] Loss=0.8031\n",
            "Epoch[1/2] Step[6315] Loss=0.1468\n",
            "Epoch[1/2] Step[6316] Loss=0.1798\n",
            "Epoch[1/2] Step[6317] Loss=0.1430\n",
            "Epoch[1/2] Step[6318] Loss=0.2750\n",
            "Epoch[1/2] Step[6319] Loss=0.2283\n",
            "Epoch[1/2] Step[6320] Loss=0.4580\n",
            "Epoch[1/2] Step[6321] Loss=0.3808\n",
            "Epoch[1/2] Step[6322] Loss=0.6650\n",
            "Epoch[1/2] Step[6323] Loss=0.2094\n",
            "Epoch[1/2] Step[6324] Loss=0.1311\n",
            "Epoch[1/2] Step[6325] Loss=0.2288\n",
            "Epoch[1/2] Step[6326] Loss=0.4042\n",
            "Epoch[1/2] Step[6327] Loss=0.3830\n",
            "Epoch[1/2] Step[6328] Loss=0.2017\n",
            "Epoch[1/2] Step[6329] Loss=0.6904\n",
            "Epoch[1/2] Step[6330] Loss=0.1457\n",
            "Epoch[1/2] Step[6331] Loss=0.0652\n",
            "Epoch[1/2] Step[6332] Loss=0.4447\n",
            "Epoch[1/2] Step[6333] Loss=0.1471\n",
            "Epoch[1/2] Step[6334] Loss=0.5479\n",
            "Epoch[1/2] Step[6335] Loss=0.1067\n",
            "Epoch[1/2] Step[6336] Loss=0.2808\n",
            "Epoch[1/2] Step[6337] Loss=0.5225\n",
            "Epoch[1/2] Step[6338] Loss=0.2436\n",
            "Epoch[1/2] Step[6339] Loss=0.1001\n",
            "Epoch[1/2] Step[6340] Loss=0.3409\n",
            "Epoch[1/2] Step[6341] Loss=0.3205\n",
            "Epoch[1/2] Step[6342] Loss=0.2460\n",
            "Epoch[1/2] Step[6343] Loss=0.3560\n",
            "Epoch[1/2] Step[6344] Loss=0.6097\n",
            "Epoch[1/2] Step[6345] Loss=0.7361\n",
            "Epoch[1/2] Step[6346] Loss=0.2545\n",
            "Epoch[1/2] Step[6347] Loss=0.3386\n",
            "Epoch[1/2] Step[6348] Loss=0.2922\n",
            "Epoch[1/2] Step[6349] Loss=0.1526\n",
            "Epoch[1/2] Step[6350] Loss=0.5816\n",
            "Epoch[1/2] Step[6351] Loss=0.2743\n",
            "Epoch[1/2] Step[6352] Loss=0.6731\n",
            "Epoch[1/2] Step[6353] Loss=0.1398\n",
            "Epoch[1/2] Step[6354] Loss=0.1880\n",
            "Epoch[1/2] Step[6355] Loss=0.1703\n",
            "Epoch[1/2] Step[6356] Loss=0.2162\n",
            "Epoch[1/2] Step[6357] Loss=0.2341\n",
            "Epoch[1/2] Step[6358] Loss=0.4371\n",
            "Epoch[1/2] Step[6359] Loss=0.8753\n",
            "Epoch[1/2] Step[6360] Loss=0.3470\n",
            "Epoch[1/2] Step[6361] Loss=0.8085\n",
            "Epoch[1/2] Step[6362] Loss=0.2706\n",
            "Epoch[1/2] Step[6363] Loss=0.6334\n",
            "Epoch[1/2] Step[6364] Loss=0.2746\n",
            "Epoch[1/2] Step[6365] Loss=0.3560\n",
            "Epoch[1/2] Step[6366] Loss=0.1491\n",
            "Epoch[1/2] Step[6367] Loss=0.2431\n",
            "Epoch[1/2] Step[6368] Loss=0.4296\n",
            "Epoch[1/2] Step[6369] Loss=0.1424\n",
            "Epoch[1/2] Step[6370] Loss=0.4957\n",
            "Epoch[1/2] Step[6371] Loss=0.5170\n",
            "Epoch[1/2] Step[6372] Loss=0.4733\n",
            "Epoch[1/2] Step[6373] Loss=0.4539\n",
            "Epoch[1/2] Step[6374] Loss=0.1168\n",
            "Epoch[1/2] Step[6375] Loss=0.5295\n",
            "Epoch[1/2] Step[6376] Loss=0.9165\n",
            "Epoch[1/2] Step[6377] Loss=0.4018\n",
            "Epoch[1/2] Step[6378] Loss=0.5765\n",
            "Epoch[1/2] Step[6379] Loss=0.1162\n",
            "Epoch[1/2] Step[6380] Loss=0.4863\n",
            "Epoch[1/2] Step[6381] Loss=0.0872\n",
            "Epoch[1/2] Step[6382] Loss=0.2496\n",
            "Epoch[1/2] Step[6383] Loss=0.3828\n",
            "Epoch[1/2] Step[6384] Loss=0.3584\n",
            "Epoch[1/2] Step[6385] Loss=0.1724\n",
            "Epoch[1/2] Step[6386] Loss=0.1169\n",
            "Epoch[1/2] Step[6387] Loss=0.3847\n",
            "Epoch[1/2] Step[6388] Loss=0.5031\n",
            "Epoch[1/2] Step[6389] Loss=0.3206\n",
            "Epoch[1/2] Step[6390] Loss=0.2633\n",
            "Epoch[1/2] Step[6391] Loss=0.9951\n",
            "Epoch[1/2] Step[6392] Loss=0.2650\n",
            "Epoch[1/2] Step[6393] Loss=0.0785\n",
            "Epoch[1/2] Step[6394] Loss=0.1356\n",
            "Epoch[1/2] Step[6395] Loss=0.3063\n",
            "Epoch[1/2] Step[6396] Loss=0.0611\n",
            "Epoch[1/2] Step[6397] Loss=0.0587\n",
            "Epoch[1/2] Step[6398] Loss=0.1155\n",
            "Epoch[1/2] Step[6399] Loss=0.3099\n",
            "Epoch[1/2] Step[6400] Loss=0.1715\n",
            "Epoch[1/2] Step[6401] Loss=0.2857\n",
            "Epoch[1/2] Step[6402] Loss=0.1463\n",
            "Epoch[1/2] Step[6403] Loss=0.1929\n",
            "Epoch[1/2] Step[6404] Loss=0.3429\n",
            "Epoch[1/2] Step[6405] Loss=0.1818\n",
            "Epoch[1/2] Step[6406] Loss=0.2072\n",
            "Epoch[1/2] Step[6407] Loss=0.3144\n",
            "Epoch[1/2] Step[6408] Loss=0.3213\n",
            "Epoch[1/2] Step[6409] Loss=0.2252\n",
            "Epoch[1/2] Step[6410] Loss=0.5040\n",
            "Epoch[1/2] Step[6411] Loss=0.3217\n",
            "Epoch[1/2] Step[6412] Loss=0.4770\n",
            "Epoch[1/2] Step[6413] Loss=0.4395\n",
            "Epoch[1/2] Step[6414] Loss=0.1109\n",
            "Epoch[1/2] Step[6415] Loss=0.1801\n",
            "Epoch[1/2] Step[6416] Loss=0.2264\n",
            "Epoch[1/2] Step[6417] Loss=0.1866\n",
            "Epoch[1/2] Step[6418] Loss=0.3875\n",
            "Epoch[1/2] Step[6419] Loss=0.8181\n",
            "Epoch[1/2] Step[6420] Loss=0.0876\n",
            "Epoch[1/2] Step[6421] Loss=0.2939\n",
            "Epoch[1/2] Step[6422] Loss=0.1483\n",
            "Epoch[1/2] Step[6423] Loss=0.6750\n",
            "Epoch[1/2] Step[6424] Loss=0.4047\n",
            "Epoch[1/2] Step[6425] Loss=0.2575\n",
            "Epoch[1/2] Step[6426] Loss=0.1236\n",
            "Epoch[1/2] Step[6427] Loss=0.1354\n",
            "Epoch[1/2] Step[6428] Loss=0.0706\n",
            "Epoch[1/2] Step[6429] Loss=0.0989\n",
            "Epoch[1/2] Step[6430] Loss=0.1113\n",
            "Epoch[1/2] Step[6431] Loss=0.2898\n",
            "Epoch[1/2] Step[6432] Loss=0.1756\n",
            "Epoch[1/2] Step[6433] Loss=0.0765\n",
            "Epoch[1/2] Step[6434] Loss=0.4982\n",
            "Epoch[1/2] Step[6435] Loss=0.4508\n",
            "Epoch[1/2] Step[6436] Loss=0.5063\n",
            "Epoch[1/2] Step[6437] Loss=0.2625\n",
            "Epoch[1/2] Step[6438] Loss=0.4267\n",
            "Epoch[1/2] Step[6439] Loss=0.0396\n",
            "Epoch[1/2] Step[6440] Loss=0.2941\n",
            "Epoch[1/2] Step[6441] Loss=0.2645\n",
            "Epoch[1/2] Step[6442] Loss=0.0685\n",
            "Epoch[1/2] Step[6443] Loss=0.3774\n",
            "Epoch[1/2] Step[6444] Loss=0.1469\n",
            "Epoch[1/2] Step[6445] Loss=0.3205\n",
            "Epoch[1/2] Step[6446] Loss=0.1478\n",
            "Epoch[1/2] Step[6447] Loss=0.1509\n",
            "Epoch[1/2] Step[6448] Loss=0.2193\n",
            "Epoch[1/2] Step[6449] Loss=0.2398\n",
            "Epoch[1/2] Step[6450] Loss=0.1360\n",
            "Epoch[1/2] Step[6451] Loss=0.0614\n",
            "Epoch[1/2] Step[6452] Loss=0.2188\n",
            "Epoch[1/2] Step[6453] Loss=0.5294\n",
            "Epoch[1/2] Step[6454] Loss=0.1623\n",
            "Epoch[1/2] Step[6455] Loss=0.1698\n",
            "Epoch[1/2] Step[6456] Loss=0.0749\n",
            "Epoch[1/2] Step[6457] Loss=0.3202\n",
            "Epoch[1/2] Step[6458] Loss=0.3759\n",
            "Epoch[1/2] Step[6459] Loss=0.1931\n",
            "Epoch[1/2] Step[6460] Loss=0.1565\n",
            "Epoch[1/2] Step[6461] Loss=0.0966\n",
            "Epoch[1/2] Step[6462] Loss=0.4752\n",
            "Epoch[1/2] Step[6463] Loss=0.1795\n",
            "Epoch[1/2] Step[6464] Loss=0.3848\n",
            "Epoch[1/2] Step[6465] Loss=0.0747\n",
            "Epoch[1/2] Step[6466] Loss=0.5321\n",
            "Epoch[1/2] Step[6467] Loss=0.6542\n",
            "Epoch[1/2] Step[6468] Loss=0.8264\n",
            "Epoch[1/2] Step[6469] Loss=0.0631\n",
            "Epoch[1/2] Step[6470] Loss=0.5438\n",
            "Epoch[1/2] Step[6471] Loss=0.1673\n",
            "Epoch[1/2] Step[6472] Loss=0.4528\n",
            "Epoch[1/2] Step[6473] Loss=0.4993\n",
            "Epoch[1/2] Step[6474] Loss=0.0744\n",
            "Epoch[1/2] Step[6475] Loss=0.7022\n",
            "Epoch[1/2] Step[6476] Loss=0.7311\n",
            "Epoch[1/2] Step[6477] Loss=0.0548\n",
            "Epoch[1/2] Step[6478] Loss=0.2042\n",
            "Epoch[1/2] Step[6479] Loss=0.1818\n",
            "Epoch[1/2] Step[6480] Loss=0.2198\n",
            "Epoch[1/2] Step[6481] Loss=0.0762\n",
            "Epoch[1/2] Step[6482] Loss=0.7642\n",
            "Epoch[1/2] Step[6483] Loss=0.4551\n",
            "Epoch[1/2] Step[6484] Loss=0.1067\n",
            "Epoch[1/2] Step[6485] Loss=0.2544\n",
            "Epoch[1/2] Step[6486] Loss=0.0506\n",
            "Epoch[1/2] Step[6487] Loss=0.0544\n",
            "Epoch[1/2] Step[6488] Loss=0.4012\n",
            "Epoch[1/2] Step[6489] Loss=0.3190\n",
            "Epoch[1/2] Step[6490] Loss=0.2727\n",
            "Epoch[1/2] Step[6491] Loss=0.4625\n",
            "Epoch[1/2] Step[6492] Loss=0.4513\n",
            "Epoch[1/2] Step[6493] Loss=0.2006\n",
            "Epoch[1/2] Step[6494] Loss=0.3858\n",
            "Epoch[1/2] Step[6495] Loss=0.0795\n",
            "Epoch[1/2] Step[6496] Loss=0.3962\n",
            "Epoch[1/2] Step[6497] Loss=0.0902\n",
            "Epoch[1/2] Step[6498] Loss=0.2232\n",
            "Epoch[1/2] Step[6499] Loss=0.6797\n",
            "Epoch[1/2] Step[6500] Loss=0.3827\n",
            "Epoch[1/2] Step[6501] Loss=0.0774\n",
            "Epoch[1/2] Step[6502] Loss=0.2711\n",
            "Epoch[1/2] Step[6503] Loss=0.2030\n",
            "Epoch[1/2] Step[6504] Loss=0.5322\n",
            "Epoch[1/2] Step[6505] Loss=0.0974\n",
            "Epoch[1/2] Step[6506] Loss=0.1820\n",
            "Epoch[1/2] Step[6507] Loss=0.1751\n",
            "Epoch[1/2] Step[6508] Loss=0.2580\n",
            "Epoch[1/2] Step[6509] Loss=0.3448\n",
            "Epoch[1/2] Step[6510] Loss=0.2551\n",
            "Epoch[1/2] Step[6511] Loss=0.0492\n",
            "Epoch[1/2] Step[6512] Loss=0.4760\n",
            "Epoch[1/2] Step[6513] Loss=0.4132\n",
            "Epoch[1/2] Step[6514] Loss=0.1224\n",
            "Epoch[1/2] Step[6515] Loss=0.3780\n",
            "Epoch[1/2] Step[6516] Loss=0.3531\n",
            "Epoch[1/2] Step[6517] Loss=0.2508\n",
            "Epoch[1/2] Step[6518] Loss=0.4356\n",
            "Epoch[1/2] Step[6519] Loss=0.2209\n",
            "Epoch[1/2] Step[6520] Loss=0.3073\n",
            "Epoch[1/2] Step[6521] Loss=0.1481\n",
            "Epoch[1/2] Step[6522] Loss=0.2786\n",
            "Epoch[1/2] Step[6523] Loss=0.2779\n",
            "Epoch[1/2] Step[6524] Loss=0.2301\n",
            "Epoch[1/2] Step[6525] Loss=0.4750\n",
            "Epoch[1/2] Step[6526] Loss=0.2162\n",
            "Epoch[1/2] Step[6527] Loss=0.3155\n",
            "Epoch[1/2] Step[6528] Loss=0.3572\n",
            "Epoch[1/2] Step[6529] Loss=0.4237\n",
            "Epoch[1/2] Step[6530] Loss=0.5186\n",
            "Epoch[1/2] Step[6531] Loss=0.3855\n",
            "Epoch[1/2] Step[6532] Loss=0.1229\n",
            "Epoch[1/2] Step[6533] Loss=0.1400\n",
            "Epoch[1/2] Step[6534] Loss=0.4939\n",
            "Epoch[1/2] Step[6535] Loss=0.4318\n",
            "Epoch[1/2] Step[6536] Loss=0.0317\n",
            "Epoch[1/2] Step[6537] Loss=0.4798\n",
            "Epoch[1/2] Step[6538] Loss=0.1985\n",
            "Epoch[1/2] Step[6539] Loss=0.2578\n",
            "Epoch[1/2] Step[6540] Loss=0.4754\n",
            "Epoch[1/2] Step[6541] Loss=0.6506\n",
            "Epoch[1/2] Step[6542] Loss=0.1897\n",
            "Epoch[1/2] Step[6543] Loss=0.6055\n",
            "Epoch[1/2] Step[6544] Loss=0.1045\n",
            "Epoch[1/2] Step[6545] Loss=0.1133\n",
            "Epoch[1/2] Step[6546] Loss=0.2149\n",
            "Epoch[1/2] Step[6547] Loss=0.1505\n",
            "Epoch[1/2] Step[6548] Loss=0.1016\n",
            "Epoch[1/2] Step[6549] Loss=1.1988\n",
            "Epoch[1/2] Step[6550] Loss=0.1834\n",
            "Epoch[1/2] Step[6551] Loss=0.3130\n",
            "Epoch[1/2] Step[6552] Loss=0.2332\n",
            "Epoch[1/2] Step[6553] Loss=0.3223\n",
            "Epoch[1/2] Step[6554] Loss=0.3793\n",
            "Epoch[1/2] Step[6555] Loss=0.1768\n",
            "Epoch[1/2] Step[6556] Loss=0.6633\n",
            "Epoch[1/2] Step[6557] Loss=0.3806\n",
            "Epoch[1/2] Step[6558] Loss=0.0923\n",
            "Epoch[1/2] Step[6559] Loss=0.0992\n",
            "Epoch[1/2] Step[6560] Loss=0.2207\n",
            "Epoch[1/2] Step[6561] Loss=0.1011\n",
            "Epoch[1/2] Step[6562] Loss=0.5893\n",
            "Epoch[1/2] Step[6563] Loss=0.0456\n",
            "Epoch[1/2] Step[6564] Loss=0.4588\n",
            "Epoch[1/2] Step[6565] Loss=0.2513\n",
            "Epoch[1/2] Step[6566] Loss=0.3125\n",
            "Epoch[1/2] Step[6567] Loss=0.5846\n",
            "Epoch[1/2] Step[6568] Loss=0.3066\n",
            "Epoch[1/2] Step[6569] Loss=0.7505\n",
            "Epoch[1/2] Step[6570] Loss=0.7025\n",
            "Epoch[1/2] Step[6571] Loss=0.4733\n",
            "Epoch[1/2] Step[6572] Loss=0.3797\n",
            "Epoch[1/2] Step[6573] Loss=0.6136\n",
            "Epoch[1/2] Step[6574] Loss=0.6489\n",
            "Epoch[1/2] Step[6575] Loss=0.2499\n",
            "Epoch[1/2] Step[6576] Loss=0.4437\n",
            "Epoch[1/2] Step[6577] Loss=0.0563\n",
            "Epoch[1/2] Step[6578] Loss=0.0911\n",
            "Epoch[1/2] Step[6579] Loss=0.1810\n",
            "Epoch[1/2] Step[6580] Loss=0.3325\n",
            "Epoch[1/2] Step[6581] Loss=0.3302\n",
            "Epoch[1/2] Step[6582] Loss=0.1948\n",
            "Epoch[1/2] Step[6583] Loss=0.1495\n",
            "Epoch[1/2] Step[6584] Loss=0.1430\n",
            "Epoch[1/2] Step[6585] Loss=0.2457\n",
            "Epoch[1/2] Step[6586] Loss=0.1800\n",
            "Epoch[1/2] Step[6587] Loss=0.3401\n",
            "Epoch[1/2] Step[6588] Loss=0.2222\n",
            "Epoch[1/2] Step[6589] Loss=0.2042\n",
            "Epoch[1/2] Step[6590] Loss=0.1571\n",
            "Epoch[1/2] Step[6591] Loss=0.2765\n",
            "Epoch[1/2] Step[6592] Loss=0.1102\n",
            "Epoch[1/2] Step[6593] Loss=0.2195\n",
            "Epoch[1/2] Step[6594] Loss=0.5605\n",
            "Epoch[1/2] Step[6595] Loss=0.1821\n",
            "Epoch[1/2] Step[6596] Loss=0.9180\n",
            "Epoch[1/2] Step[6597] Loss=0.0889\n",
            "Epoch[1/2] Step[6598] Loss=0.1606\n",
            "Epoch[1/2] Step[6599] Loss=0.1992\n",
            "Epoch[1/2] Step[6600] Loss=0.6871\n",
            "Epoch[1/2] Step[6601] Loss=0.2105\n",
            "Epoch[1/2] Step[6602] Loss=0.6511\n",
            "Epoch[1/2] Step[6603] Loss=0.0391\n",
            "Epoch[1/2] Step[6604] Loss=0.2903\n",
            "Epoch[1/2] Step[6605] Loss=1.0088\n",
            "Epoch[1/2] Step[6606] Loss=0.6145\n",
            "Epoch[1/2] Step[6607] Loss=0.1387\n",
            "Epoch[1/2] Step[6608] Loss=0.5188\n",
            "Epoch[1/2] Step[6609] Loss=0.1734\n",
            "Epoch[1/2] Step[6610] Loss=0.2346\n",
            "Epoch[1/2] Step[6611] Loss=0.1422\n",
            "Epoch[1/2] Step[6612] Loss=0.2145\n",
            "Epoch[1/2] Step[6613] Loss=0.1392\n",
            "Epoch[1/2] Step[6614] Loss=0.2708\n",
            "Epoch[1/2] Step[6615] Loss=0.2696\n",
            "Epoch[1/2] Step[6616] Loss=0.0559\n",
            "Epoch[1/2] Step[6617] Loss=0.1568\n",
            "Epoch[1/2] Step[6618] Loss=0.2916\n",
            "Epoch[1/2] Step[6619] Loss=0.0697\n",
            "Epoch[1/2] Step[6620] Loss=0.0851\n",
            "Epoch[1/2] Step[6621] Loss=0.2486\n",
            "Epoch[1/2] Step[6622] Loss=0.2702\n",
            "Epoch[1/2] Step[6623] Loss=0.6328\n",
            "Epoch[1/2] Step[6624] Loss=0.2043\n",
            "Epoch[1/2] Step[6625] Loss=0.5404\n",
            "Epoch[1/2] Step[6626] Loss=0.5048\n",
            "Epoch[1/2] Step[6627] Loss=0.0624\n",
            "Epoch[1/2] Step[6628] Loss=0.1549\n",
            "Epoch[1/2] Step[6629] Loss=0.3321\n",
            "Epoch[1/2] Step[6630] Loss=0.1444\n",
            "Epoch[1/2] Step[6631] Loss=0.3349\n",
            "Epoch[1/2] Step[6632] Loss=0.2625\n",
            "Epoch[1/2] Step[6633] Loss=0.1933\n",
            "Epoch[1/2] Step[6634] Loss=0.2252\n",
            "Epoch[1/2] Step[6635] Loss=0.3760\n",
            "Epoch[1/2] Step[6636] Loss=0.2529\n",
            "Epoch[1/2] Step[6637] Loss=0.1163\n",
            "Epoch[1/2] Step[6638] Loss=0.2304\n",
            "Epoch[1/2] Step[6639] Loss=0.2068\n",
            "Epoch[1/2] Step[6640] Loss=0.2971\n",
            "Epoch[1/2] Step[6641] Loss=0.3722\n",
            "Epoch[1/2] Step[6642] Loss=0.7562\n",
            "Epoch[1/2] Step[6643] Loss=0.7497\n",
            "Epoch[1/2] Step[6644] Loss=0.3468\n",
            "Epoch[1/2] Step[6645] Loss=0.1083\n",
            "Epoch[1/2] Step[6646] Loss=0.0790\n",
            "Epoch[1/2] Step[6647] Loss=0.1094\n",
            "Epoch[1/2] Step[6648] Loss=0.6022\n",
            "Epoch[1/2] Step[6649] Loss=0.3963\n",
            "Epoch[1/2] Step[6650] Loss=1.3569\n",
            "Epoch[1/2] Step[6651] Loss=0.2400\n",
            "Epoch[1/2] Step[6652] Loss=0.5612\n",
            "Epoch[1/2] Step[6653] Loss=0.1197\n",
            "Epoch[1/2] Step[6654] Loss=0.2093\n",
            "Epoch[1/2] Step[6655] Loss=0.7728\n",
            "Epoch[1/2] Step[6656] Loss=0.1701\n",
            "Epoch[1/2] Step[6657] Loss=0.1209\n",
            "Epoch[1/2] Step[6658] Loss=0.4042\n",
            "Epoch[1/2] Step[6659] Loss=0.3554\n",
            "Epoch[1/2] Step[6660] Loss=0.3189\n",
            "Epoch[1/2] Step[6661] Loss=0.6183\n",
            "Epoch[1/2] Step[6662] Loss=0.2601\n",
            "Epoch[1/2] Step[6663] Loss=0.0461\n",
            "Epoch[1/2] Step[6664] Loss=0.1295\n",
            "Epoch[1/2] Step[6665] Loss=0.1201\n",
            "Epoch[1/2] Step[6666] Loss=0.1800\n",
            "Epoch[1/2] Step[6667] Loss=0.3631\n",
            "Epoch[1/2] Step[6668] Loss=0.7405\n",
            "Epoch[1/2] Step[6669] Loss=0.0923\n",
            "Epoch[1/2] Step[6670] Loss=0.5601\n",
            "Epoch[1/2] Step[6671] Loss=0.2211\n",
            "Epoch[1/2] Step[6672] Loss=0.4123\n",
            "Epoch[1/2] Step[6673] Loss=0.1616\n",
            "Epoch[1/2] Step[6674] Loss=0.2317\n",
            "Epoch[1/2] Step[6675] Loss=0.4746\n",
            "Epoch[1/2] Step[6676] Loss=0.5880\n",
            "Epoch[1/2] Step[6677] Loss=0.3225\n",
            "Epoch[1/2] Step[6678] Loss=0.0868\n",
            "Epoch[1/2] Step[6679] Loss=0.3364\n",
            "Epoch[1/2] Step[6680] Loss=0.0687\n",
            "Epoch[1/2] Step[6681] Loss=0.3179\n",
            "Epoch[1/2] Step[6682] Loss=0.6515\n",
            "Epoch[1/2] Step[6683] Loss=0.1692\n",
            "Epoch[1/2] Step[6684] Loss=0.0637\n",
            "Epoch[1/2] Step[6685] Loss=0.7242\n",
            "Epoch[1/2] Step[6686] Loss=0.7319\n",
            "Epoch[1/2] Step[6687] Loss=0.2151\n",
            "Epoch[1/2] Step[6688] Loss=0.1015\n",
            "Epoch[1/2] Step[6689] Loss=0.1758\n",
            "Epoch[1/2] Step[6690] Loss=0.3986\n",
            "Epoch[1/2] Step[6691] Loss=0.3247\n",
            "Epoch[1/2] Step[6692] Loss=0.8078\n",
            "Epoch[1/2] Step[6693] Loss=0.6590\n",
            "Epoch[1/2] Step[6694] Loss=0.3984\n",
            "Epoch[1/2] Step[6695] Loss=0.3599\n",
            "Epoch[1/2] Step[6696] Loss=0.5225\n",
            "Epoch[1/2] Step[6697] Loss=0.4814\n",
            "Epoch[1/2] Step[6698] Loss=0.2789\n",
            "Epoch[1/2] Step[6699] Loss=0.2665\n",
            "Epoch[1/2] Step[6700] Loss=0.5154\n",
            "Epoch[1/2] Step[6701] Loss=0.2986\n",
            "Epoch[1/2] Step[6702] Loss=0.7966\n",
            "Epoch[1/2] Step[6703] Loss=0.6967\n",
            "Epoch[1/2] Step[6704] Loss=0.3200\n",
            "Epoch[1/2] Step[6705] Loss=0.1900\n",
            "Epoch[1/2] Step[6706] Loss=0.2904\n",
            "Epoch[1/2] Step[6707] Loss=0.4375\n",
            "Epoch[1/2] Step[6708] Loss=0.4477\n",
            "Epoch[1/2] Step[6709] Loss=0.8846\n",
            "Epoch[1/2] Step[6710] Loss=0.5109\n",
            "Epoch[1/2] Step[6711] Loss=0.3125\n",
            "Epoch[1/2] Step[6712] Loss=0.2069\n",
            "Epoch[1/2] Step[6713] Loss=0.4107\n",
            "Epoch[1/2] Step[6714] Loss=0.7660\n",
            "Epoch[1/2] Step[6715] Loss=0.1635\n",
            "Epoch[1/2] Step[6716] Loss=0.1325\n",
            "Epoch[1/2] Step[6717] Loss=0.6438\n",
            "Epoch[1/2] Step[6718] Loss=0.1801\n",
            "Epoch[1/2] Step[6719] Loss=0.2841\n",
            "Epoch[1/2] Step[6720] Loss=0.3168\n",
            "Epoch[1/2] Step[6721] Loss=0.2287\n",
            "Epoch[1/2] Step[6722] Loss=0.0334\n",
            "Epoch[1/2] Step[6723] Loss=0.3810\n",
            "Epoch[1/2] Step[6724] Loss=0.7693\n",
            "Epoch[1/2] Step[6725] Loss=0.0860\n",
            "Epoch[1/2] Step[6726] Loss=0.8137\n",
            "Epoch[1/2] Step[6727] Loss=0.1603\n",
            "Epoch[1/2] Step[6728] Loss=0.2976\n",
            "Epoch[1/2] Step[6729] Loss=0.1021\n",
            "Epoch[1/2] Step[6730] Loss=0.2898\n",
            "Epoch[1/2] Step[6731] Loss=0.1780\n",
            "Epoch[1/2] Step[6732] Loss=0.2359\n",
            "Epoch[1/2] Step[6733] Loss=0.1682\n",
            "Epoch[1/2] Step[6734] Loss=0.1042\n",
            "Epoch[1/2] Step[6735] Loss=0.0839\n",
            "Epoch[1/2] Step[6736] Loss=0.2171\n",
            "Epoch[1/2] Step[6737] Loss=0.1619\n",
            "Epoch[1/2] Step[6738] Loss=0.1528\n",
            "Epoch[1/2] Step[6739] Loss=0.1037\n",
            "Epoch[1/2] Step[6740] Loss=0.3246\n",
            "Epoch[1/2] Step[6741] Loss=0.1855\n",
            "Epoch[1/2] Step[6742] Loss=0.2963\n",
            "Epoch[1/2] Step[6743] Loss=0.2341\n",
            "Epoch[1/2] Step[6744] Loss=0.4656\n",
            "Epoch[1/2] Step[6745] Loss=0.1085\n",
            "Epoch[1/2] Step[6746] Loss=0.2132\n",
            "Epoch[1/2] Step[6747] Loss=0.1281\n",
            "Epoch[1/2] Step[6748] Loss=0.5188\n",
            "Epoch[1/2] Step[6749] Loss=0.3391\n",
            "Epoch[1/2] Step[6750] Loss=0.3812\n",
            "Epoch[1/2] Step[6751] Loss=0.1696\n",
            "Epoch[1/2] Step[6752] Loss=0.2760\n",
            "Epoch[1/2] Step[6753] Loss=1.0769\n",
            "Epoch[1/2] Step[6754] Loss=0.2973\n",
            "Epoch[1/2] Step[6755] Loss=0.2742\n",
            "Epoch[1/2] Step[6756] Loss=0.1028\n",
            "Epoch[1/2] Step[6757] Loss=0.3518\n",
            "Epoch[1/2] Step[6758] Loss=0.1038\n",
            "Epoch[1/2] Step[6759] Loss=0.6731\n",
            "Epoch[1/2] Step[6760] Loss=0.3418\n",
            "Epoch[1/2] Step[6761] Loss=0.2885\n",
            "Epoch[1/2] Step[6762] Loss=0.1714\n",
            "Epoch[1/2] Step[6763] Loss=0.0657\n",
            "Epoch[1/2] Step[6764] Loss=0.5618\n",
            "Epoch[1/2] Step[6765] Loss=0.4276\n",
            "Epoch[1/2] Step[6766] Loss=0.2909\n",
            "Epoch[1/2] Step[6767] Loss=0.4457\n",
            "Epoch[1/2] Step[6768] Loss=0.0618\n",
            "Epoch[1/2] Step[6769] Loss=0.5398\n",
            "Epoch[1/2] Step[6770] Loss=0.0816\n",
            "Epoch[1/2] Step[6771] Loss=0.3264\n",
            "Epoch[1/2] Step[6772] Loss=0.6673\n",
            "Epoch[1/2] Step[6773] Loss=0.2437\n",
            "Epoch[1/2] Step[6774] Loss=0.0721\n",
            "Epoch[1/2] Step[6775] Loss=0.3787\n",
            "Epoch[1/2] Step[6776] Loss=0.0520\n",
            "Epoch[1/2] Step[6777] Loss=0.2960\n",
            "Epoch[1/2] Step[6778] Loss=0.1485\n",
            "Epoch[1/2] Step[6779] Loss=0.2209\n",
            "Epoch[1/2] Step[6780] Loss=0.6547\n",
            "Epoch[1/2] Step[6781] Loss=0.6180\n",
            "Epoch[1/2] Step[6782] Loss=0.1730\n",
            "Epoch[1/2] Step[6783] Loss=1.0790\n",
            "Epoch[1/2] Step[6784] Loss=0.4154\n",
            "Epoch[1/2] Step[6785] Loss=0.2241\n",
            "Epoch[1/2] Step[6786] Loss=0.4706\n",
            "Epoch[1/2] Step[6787] Loss=0.1808\n",
            "Epoch[1/2] Step[6788] Loss=0.2546\n",
            "Epoch[1/2] Step[6789] Loss=0.5407\n",
            "Epoch[1/2] Step[6790] Loss=0.1235\n",
            "Epoch[1/2] Step[6791] Loss=0.0979\n",
            "Epoch[1/2] Step[6792] Loss=0.1045\n",
            "Epoch[1/2] Step[6793] Loss=0.1248\n",
            "Epoch[1/2] Step[6794] Loss=0.3029\n",
            "Epoch[1/2] Step[6795] Loss=0.1323\n",
            "Epoch[1/2] Step[6796] Loss=0.1485\n",
            "Epoch[1/2] Step[6797] Loss=0.4182\n",
            "Epoch[1/2] Step[6798] Loss=0.3223\n",
            "Epoch[1/2] Step[6799] Loss=0.3946\n",
            "Epoch[1/2] Step[6800] Loss=0.8870\n",
            "Epoch[1/2] Step[6801] Loss=0.0704\n",
            "Epoch[1/2] Step[6802] Loss=0.4050\n",
            "Epoch[1/2] Step[6803] Loss=0.1193\n",
            "Epoch[1/2] Step[6804] Loss=0.2524\n",
            "Epoch[1/2] Step[6805] Loss=0.2823\n",
            "Epoch[1/2] Step[6806] Loss=0.1497\n",
            "Epoch[1/2] Step[6807] Loss=0.0892\n",
            "Epoch[1/2] Step[6808] Loss=0.2778\n",
            "Epoch[1/2] Step[6809] Loss=0.4619\n",
            "Epoch[1/2] Step[6810] Loss=0.2118\n",
            "Epoch[1/2] Step[6811] Loss=0.2368\n",
            "Epoch[1/2] Step[6812] Loss=0.7826\n",
            "Epoch[1/2] Step[6813] Loss=0.1386\n",
            "Epoch[1/2] Step[6814] Loss=0.1938\n",
            "Epoch[1/2] Step[6815] Loss=0.2259\n",
            "Epoch[1/2] Step[6816] Loss=0.1773\n",
            "Epoch[1/2] Step[6817] Loss=0.4668\n",
            "Epoch[1/2] Step[6818] Loss=0.4469\n",
            "Epoch[1/2] Step[6819] Loss=0.6334\n",
            "Epoch[1/2] Step[6820] Loss=0.0810\n",
            "Epoch[1/2] Step[6821] Loss=0.2631\n",
            "Epoch[1/2] Step[6822] Loss=1.0485\n",
            "Epoch[1/2] Step[6823] Loss=0.2617\n",
            "Epoch[1/2] Step[6824] Loss=0.2191\n",
            "Epoch[1/2] Step[6825] Loss=0.1596\n",
            "Epoch[1/2] Step[6826] Loss=0.0281\n",
            "Epoch[1/2] Step[6827] Loss=0.0968\n",
            "Epoch[1/2] Step[6828] Loss=0.3198\n",
            "Epoch[1/2] Step[6829] Loss=0.5749\n",
            "Epoch[1/2] Step[6830] Loss=0.5418\n",
            "Epoch[1/2] Step[6831] Loss=0.1529\n",
            "Epoch[1/2] Step[6832] Loss=0.1416\n",
            "Epoch[1/2] Step[6833] Loss=0.3268\n",
            "Epoch[1/2] Step[6834] Loss=0.4457\n",
            "Epoch[1/2] Step[6835] Loss=0.4283\n",
            "Epoch[1/2] Step[6836] Loss=0.1189\n",
            "Epoch[1/2] Step[6837] Loss=0.0979\n",
            "Epoch[1/2] Step[6838] Loss=0.3632\n",
            "Epoch[1/2] Step[6839] Loss=0.1172\n",
            "Epoch[1/2] Step[6840] Loss=0.2743\n",
            "Epoch[1/2] Step[6841] Loss=0.2015\n",
            "Epoch[1/2] Step[6842] Loss=0.2109\n",
            "Epoch[1/2] Step[6843] Loss=0.1599\n",
            "Epoch[1/2] Step[6844] Loss=0.1535\n",
            "Epoch[1/2] Step[6845] Loss=0.0405\n",
            "Epoch[1/2] Step[6846] Loss=0.6297\n",
            "Epoch[1/2] Step[6847] Loss=0.2271\n",
            "Epoch[1/2] Step[6848] Loss=0.5804\n",
            "Epoch[1/2] Step[6849] Loss=0.2308\n",
            "Epoch[1/2] Step[6850] Loss=0.4094\n",
            "Epoch[1/2] Step[6851] Loss=0.4506\n",
            "Epoch[1/2] Step[6852] Loss=0.6771\n",
            "Epoch[1/2] Step[6853] Loss=0.4226\n",
            "Epoch[1/2] Step[6854] Loss=0.3947\n",
            "Epoch[1/2] Step[6855] Loss=0.2345\n",
            "Epoch[1/2] Step[6856] Loss=0.2756\n",
            "Epoch[1/2] Step[6857] Loss=0.5342\n",
            "Epoch[1/2] Step[6858] Loss=0.2148\n",
            "Epoch[1/2] Step[6859] Loss=0.1515\n",
            "Epoch[1/2] Step[6860] Loss=0.0753\n",
            "Epoch[1/2] Step[6861] Loss=0.1663\n",
            "Epoch[1/2] Step[6862] Loss=0.6022\n",
            "Epoch[1/2] Step[6863] Loss=0.3011\n",
            "Epoch[1/2] Step[6864] Loss=0.2097\n",
            "Epoch[1/2] Step[6865] Loss=0.4132\n",
            "Epoch[1/2] Step[6866] Loss=0.1324\n",
            "Epoch[1/2] Step[6867] Loss=0.2361\n",
            "Epoch[1/2] Step[6868] Loss=0.1960\n",
            "Epoch[1/2] Step[6869] Loss=0.2709\n",
            "Epoch[1/2] Step[6870] Loss=0.3619\n",
            "Epoch[1/2] Step[6871] Loss=0.7577\n",
            "Epoch[1/2] Step[6872] Loss=0.3639\n",
            "Epoch[1/2] Step[6873] Loss=0.2739\n",
            "Epoch[1/2] Step[6874] Loss=0.2717\n",
            "Epoch[1/2] Step[6875] Loss=0.1254\n",
            "Epoch[1/2] Step[6876] Loss=0.2358\n",
            "Epoch[1/2] Step[6877] Loss=0.0672\n",
            "Epoch[1/2] Step[6878] Loss=0.4445\n",
            "Epoch[1/2] Step[6879] Loss=0.3943\n",
            "Epoch[1/2] Step[6880] Loss=0.2250\n",
            "Epoch[1/2] Step[6881] Loss=0.1134\n",
            "Epoch[1/2] Step[6882] Loss=0.2063\n",
            "Epoch[1/2] Step[6883] Loss=0.1822\n",
            "Epoch[1/2] Step[6884] Loss=0.1385\n",
            "Epoch[1/2] Step[6885] Loss=0.1496\n",
            "Epoch[1/2] Step[6886] Loss=0.1378\n",
            "Epoch[1/2] Step[6887] Loss=0.0263\n",
            "Epoch[1/2] Step[6888] Loss=0.1536\n",
            "Epoch[1/2] Step[6889] Loss=0.6465\n",
            "Epoch[1/2] Step[6890] Loss=0.4172\n",
            "Epoch[1/2] Step[6891] Loss=0.4308\n",
            "Epoch[1/2] Step[6892] Loss=0.2486\n",
            "Epoch[1/2] Step[6893] Loss=0.1559\n",
            "Epoch[1/2] Step[6894] Loss=0.0818\n",
            "Epoch[1/2] Step[6895] Loss=0.1287\n",
            "Epoch[1/2] Step[6896] Loss=0.0313\n",
            "Epoch[1/2] Step[6897] Loss=0.1729\n",
            "Epoch[1/2] Step[6898] Loss=0.2438\n",
            "Epoch[1/2] Step[6899] Loss=0.4131\n",
            "Epoch[1/2] Step[6900] Loss=0.1007\n",
            "Epoch[1/2] Step[6901] Loss=0.1818\n",
            "Epoch[1/2] Step[6902] Loss=0.3909\n",
            "Epoch[1/2] Step[6903] Loss=0.0597\n",
            "Epoch[1/2] Step[6904] Loss=0.2129\n",
            "Epoch[1/2] Step[6905] Loss=0.1874\n",
            "Epoch[1/2] Step[6906] Loss=0.4001\n",
            "Epoch[1/2] Step[6907] Loss=0.2005\n",
            "Epoch[1/2] Step[6908] Loss=0.2950\n",
            "Epoch[1/2] Step[6909] Loss=0.4841\n",
            "Epoch[1/2] Step[6910] Loss=0.2722\n",
            "Epoch[1/2] Step[6911] Loss=0.4390\n",
            "Epoch[1/2] Step[6912] Loss=0.1797\n",
            "Epoch[1/2] Step[6913] Loss=0.4001\n",
            "Epoch[1/2] Step[6914] Loss=0.1903\n",
            "Epoch[1/2] Step[6915] Loss=0.7114\n",
            "Epoch[1/2] Step[6916] Loss=0.2575\n",
            "Epoch[1/2] Step[6917] Loss=0.0878\n",
            "Epoch[1/2] Step[6918] Loss=0.2143\n",
            "Epoch[1/2] Step[6919] Loss=0.3274\n",
            "Epoch[1/2] Step[6920] Loss=0.2568\n",
            "Epoch[1/2] Step[6921] Loss=0.3688\n",
            "Epoch[1/2] Step[6922] Loss=0.6319\n",
            "Epoch[1/2] Step[6923] Loss=0.4543\n",
            "Epoch[1/2] Step[6924] Loss=0.2555\n",
            "Epoch[1/2] Step[6925] Loss=0.0761\n",
            "Epoch[1/2] Step[6926] Loss=0.2048\n",
            "Epoch[1/2] Step[6927] Loss=0.1574\n",
            "Epoch[1/2] Step[6928] Loss=0.1438\n",
            "Epoch[1/2] Step[6929] Loss=0.0916\n",
            "Epoch[1/2] Step[6930] Loss=0.1145\n",
            "Epoch[1/2] Step[6931] Loss=0.2526\n",
            "Epoch[1/2] Step[6932] Loss=0.5030\n",
            "Epoch[1/2] Step[6933] Loss=0.3846\n",
            "Epoch[1/2] Step[6934] Loss=1.2578\n",
            "Epoch[1/2] Step[6935] Loss=0.6102\n",
            "Epoch[1/2] Step[6936] Loss=0.5788\n",
            "Epoch[1/2] Step[6937] Loss=0.0707\n",
            "Epoch[1/2] Step[6938] Loss=0.3365\n",
            "Epoch[1/2] Step[6939] Loss=0.2586\n",
            "Epoch[1/2] Step[6940] Loss=0.2688\n",
            "Epoch[1/2] Step[6941] Loss=0.2645\n",
            "Epoch[1/2] Step[6942] Loss=0.1760\n",
            "Epoch[1/2] Step[6943] Loss=0.2883\n",
            "Epoch[1/2] Step[6944] Loss=0.2388\n",
            "Epoch[1/2] Step[6945] Loss=0.1499\n",
            "Epoch[1/2] Step[6946] Loss=0.3058\n",
            "Epoch[1/2] Step[6947] Loss=0.1451\n",
            "Epoch[1/2] Step[6948] Loss=0.2367\n",
            "Epoch[1/2] Step[6949] Loss=0.1101\n",
            "Epoch[1/2] Step[6950] Loss=0.3754\n",
            "Epoch[1/2] Step[6951] Loss=0.0852\n",
            "Epoch[1/2] Step[6952] Loss=0.3616\n",
            "Epoch[1/2] Step[6953] Loss=0.3039\n",
            "Epoch[1/2] Step[6954] Loss=0.0556\n",
            "Epoch[1/2] Step[6955] Loss=0.4908\n",
            "Epoch[1/2] Step[6956] Loss=0.0420\n",
            "Epoch[1/2] Step[6957] Loss=0.1909\n",
            "Epoch[1/2] Step[6958] Loss=0.1621\n",
            "Epoch[1/2] Step[6959] Loss=0.0871\n",
            "Epoch[1/2] Step[6960] Loss=0.0860\n",
            "Epoch[1/2] Step[6961] Loss=0.3388\n",
            "Epoch[1/2] Step[6962] Loss=0.5028\n",
            "Epoch[1/2] Step[6963] Loss=0.3696\n",
            "Epoch[1/2] Step[6964] Loss=0.0990\n",
            "Epoch[1/2] Step[6965] Loss=0.3508\n",
            "Epoch[1/2] Step[6966] Loss=0.2162\n",
            "Epoch[1/2] Step[6967] Loss=0.6967\n",
            "Epoch[1/2] Step[6968] Loss=0.2236\n",
            "Epoch[1/2] Step[6969] Loss=0.4713\n",
            "Epoch[1/2] Step[6970] Loss=0.2235\n",
            "Epoch[1/2] Step[6971] Loss=0.6282\n",
            "Epoch[1/2] Step[6972] Loss=0.3916\n",
            "Epoch[1/2] Step[6973] Loss=0.0632\n",
            "Epoch[1/2] Step[6974] Loss=0.2160\n",
            "Epoch[1/2] Step[6975] Loss=0.2162\n",
            "Epoch[1/2] Step[6976] Loss=0.3675\n",
            "Epoch[1/2] Step[6977] Loss=0.1050\n",
            "Epoch[1/2] Step[6978] Loss=0.4820\n",
            "Epoch[1/2] Step[6979] Loss=0.3035\n",
            "Epoch[1/2] Step[6980] Loss=0.2777\n",
            "Epoch[1/2] Step[6981] Loss=0.4016\n",
            "Epoch[1/2] Step[6982] Loss=0.3829\n",
            "Epoch[1/2] Step[6983] Loss=0.5516\n",
            "Epoch[1/2] Step[6984] Loss=0.1641\n",
            "Epoch[1/2] Step[6985] Loss=0.5034\n",
            "Epoch[1/2] Step[6986] Loss=0.1481\n",
            "Epoch[1/2] Step[6987] Loss=0.0869\n",
            "Epoch[1/2] Step[6988] Loss=0.4009\n",
            "Epoch[1/2] Step[6989] Loss=0.2349\n",
            "Epoch[1/2] Step[6990] Loss=0.3887\n",
            "Epoch[1/2] Step[6991] Loss=0.1766\n",
            "Epoch[1/2] Step[6992] Loss=0.4041\n",
            "Epoch[1/2] Step[6993] Loss=0.9214\n",
            "Epoch[1/2] Step[6994] Loss=0.3669\n",
            "Epoch[1/2] Step[6995] Loss=0.2055\n",
            "Epoch[1/2] Step[6996] Loss=0.2596\n",
            "Epoch[1/2] Step[6997] Loss=0.1370\n",
            "Epoch[1/2] Step[6998] Loss=0.3965\n",
            "Epoch[1/2] Step[6999] Loss=0.1504\n",
            "Epoch[1/2] Step[7000] Loss=0.3010\n",
            "Epoch[1/2] Step[7001] Loss=0.1018\n",
            "Epoch[1/2] Step[7002] Loss=0.1806\n",
            "Epoch[1/2] Step[7003] Loss=0.0940\n",
            "Epoch[1/2] Step[7004] Loss=0.3651\n",
            "Epoch[1/2] Step[7005] Loss=0.2219\n",
            "Epoch[1/2] Step[7006] Loss=0.8292\n",
            "Epoch[1/2] Step[7007] Loss=0.0827\n",
            "Epoch[1/2] Step[7008] Loss=0.1442\n",
            "Epoch[1/2] Step[7009] Loss=0.4002\n",
            "Epoch[1/2] Step[7010] Loss=0.1839\n",
            "Epoch[1/2] Step[7011] Loss=0.0905\n",
            "Epoch[1/2] Step[7012] Loss=0.3178\n",
            "Epoch[1/2] Step[7013] Loss=0.3965\n",
            "Epoch[1/2] Step[7014] Loss=0.4403\n",
            "Epoch[1/2] Step[7015] Loss=0.3325\n",
            "Epoch[1/2] Step[7016] Loss=0.1698\n",
            "Epoch[1/2] Step[7017] Loss=0.2739\n",
            "Epoch[1/2] Step[7018] Loss=0.0799\n",
            "Epoch[1/2] Step[7019] Loss=0.1575\n",
            "Epoch[1/2] Step[7020] Loss=0.0824\n",
            "Epoch[1/2] Step[7021] Loss=0.4567\n",
            "Epoch[1/2] Step[7022] Loss=0.1968\n",
            "Epoch[1/2] Step[7023] Loss=0.1691\n",
            "Epoch[1/2] Step[7024] Loss=0.0701\n",
            "Epoch[1/2] Step[7025] Loss=0.1315\n",
            "Epoch[1/2] Step[7026] Loss=0.1844\n",
            "Epoch[1/2] Step[7027] Loss=0.5018\n",
            "Epoch[1/2] Step[7028] Loss=0.9004\n",
            "Epoch[1/2] Step[7029] Loss=0.2383\n",
            "Epoch[1/2] Step[7030] Loss=0.0989\n",
            "Epoch[1/2] Step[7031] Loss=0.5784\n",
            "Epoch[1/2] Step[7032] Loss=0.3763\n",
            "Epoch[1/2] Step[7033] Loss=0.1772\n",
            "Epoch[1/2] Step[7034] Loss=0.2992\n",
            "Epoch[1/2] Step[7035] Loss=0.1796\n",
            "Epoch[1/2] Step[7036] Loss=0.4836\n",
            "Epoch[1/2] Step[7037] Loss=0.3443\n",
            "Epoch[1/2] Step[7038] Loss=0.5776\n",
            "Epoch[1/2] Step[7039] Loss=0.3353\n",
            "Epoch[1/2] Step[7040] Loss=0.4309\n",
            "Epoch[1/2] Step[7041] Loss=0.5738\n",
            "Epoch[1/2] Step[7042] Loss=0.2711\n",
            "Epoch[1/2] Step[7043] Loss=0.5402\n",
            "Epoch[1/2] Step[7044] Loss=0.0964\n",
            "Epoch[1/2] Step[7045] Loss=0.1367\n",
            "Epoch[1/2] Step[7046] Loss=0.2383\n",
            "Epoch[1/2] Step[7047] Loss=0.1111\n",
            "Epoch[1/2] Step[7048] Loss=0.4862\n",
            "Epoch[1/2] Step[7049] Loss=0.1793\n",
            "Epoch[1/2] Step[7050] Loss=0.3881\n",
            "Epoch[1/2] Step[7051] Loss=0.0873\n",
            "Epoch[1/2] Step[7052] Loss=0.3821\n",
            "Epoch[1/2] Step[7053] Loss=0.3726\n",
            "Epoch[1/2] Step[7054] Loss=0.3242\n",
            "Epoch[1/2] Step[7055] Loss=0.3145\n",
            "Epoch[1/2] Step[7056] Loss=0.1878\n",
            "Epoch[1/2] Step[7057] Loss=0.2570\n",
            "Epoch[1/2] Step[7058] Loss=0.1534\n",
            "Epoch[1/2] Step[7059] Loss=0.1927\n",
            "Epoch[1/2] Step[7060] Loss=0.1982\n",
            "Epoch[1/2] Step[7061] Loss=0.1378\n",
            "Epoch[1/2] Step[7062] Loss=0.2144\n",
            "Epoch[1/2] Step[7063] Loss=0.4083\n",
            "Epoch[1/2] Step[7064] Loss=0.8490\n",
            "Epoch[1/2] Step[7065] Loss=0.3755\n",
            "Epoch[1/2] Step[7066] Loss=0.2547\n",
            "Epoch[1/2] Step[7067] Loss=0.1333\n",
            "Epoch[1/2] Step[7068] Loss=0.2213\n",
            "Epoch[1/2] Step[7069] Loss=0.1841\n",
            "Epoch[1/2] Step[7070] Loss=0.1110\n",
            "Epoch[1/2] Step[7071] Loss=0.2733\n",
            "Epoch[1/2] Step[7072] Loss=0.3989\n",
            "Epoch[1/2] Step[7073] Loss=0.2252\n",
            "Epoch[1/2] Step[7074] Loss=0.1420\n",
            "Epoch[1/2] Step[7075] Loss=0.7089\n",
            "Epoch[1/2] Step[7076] Loss=0.2290\n",
            "Epoch[1/2] Step[7077] Loss=0.1551\n",
            "Epoch[1/2] Step[7078] Loss=0.2228\n",
            "Epoch[1/2] Step[7079] Loss=0.5570\n",
            "Epoch[1/2] Step[7080] Loss=0.0998\n",
            "Epoch[1/2] Step[7081] Loss=0.3160\n",
            "Epoch[1/2] Step[7082] Loss=0.5182\n",
            "Epoch[1/2] Step[7083] Loss=0.2802\n",
            "Epoch[1/2] Step[7084] Loss=0.3287\n",
            "Epoch[1/2] Step[7085] Loss=0.1552\n",
            "Epoch[1/2] Step[7086] Loss=0.2843\n",
            "Epoch[1/2] Step[7087] Loss=0.5562\n",
            "Epoch[1/2] Step[7088] Loss=0.6640\n",
            "Epoch[1/2] Step[7089] Loss=0.4644\n",
            "Epoch[1/2] Step[7090] Loss=0.2242\n",
            "Epoch[1/2] Step[7091] Loss=0.3434\n",
            "Epoch[1/2] Step[7092] Loss=0.1401\n",
            "Epoch[1/2] Step[7093] Loss=0.1844\n",
            "Epoch[1/2] Step[7094] Loss=0.4303\n",
            "Epoch[1/2] Step[7095] Loss=0.5244\n",
            "Epoch[1/2] Step[7096] Loss=0.6044\n",
            "Epoch[1/2] Step[7097] Loss=0.5093\n",
            "Epoch[1/2] Step[7098] Loss=0.2478\n",
            "Epoch[1/2] Step[7099] Loss=0.1194\n",
            "Epoch[1/2] Step[7100] Loss=0.9452\n",
            "Epoch[1/2] Step[7101] Loss=0.5089\n",
            "Epoch[1/2] Step[7102] Loss=0.4403\n",
            "Epoch[1/2] Step[7103] Loss=0.8069\n",
            "Epoch[1/2] Step[7104] Loss=0.1119\n",
            "Epoch[1/2] Step[7105] Loss=0.6864\n",
            "Epoch[1/2] Step[7106] Loss=0.2496\n",
            "Epoch[1/2] Step[7107] Loss=0.4365\n",
            "Epoch[1/2] Step[7108] Loss=0.1327\n",
            "Epoch[1/2] Step[7109] Loss=0.0500\n",
            "Epoch[1/2] Step[7110] Loss=0.3534\n",
            "Epoch[1/2] Step[7111] Loss=0.1971\n",
            "Epoch[1/2] Step[7112] Loss=0.3503\n",
            "Epoch[1/2] Step[7113] Loss=0.1471\n",
            "Epoch[1/2] Step[7114] Loss=0.0664\n",
            "Epoch[1/2] Step[7115] Loss=0.1080\n",
            "Epoch[1/2] Step[7116] Loss=1.0002\n",
            "Epoch[1/2] Step[7117] Loss=0.0580\n",
            "Epoch[1/2] Step[7118] Loss=0.2055\n",
            "Epoch[1/2] Step[7119] Loss=0.2172\n",
            "Epoch[1/2] Step[7120] Loss=0.0658\n",
            "Epoch[1/2] Step[7121] Loss=0.1747\n",
            "Epoch[1/2] Step[7122] Loss=0.3618\n",
            "Epoch[1/2] Step[7123] Loss=0.5766\n",
            "Epoch[1/2] Step[7124] Loss=0.1267\n",
            "Epoch[1/2] Step[7125] Loss=0.3143\n",
            "Epoch[1/2] Step[7126] Loss=0.2310\n",
            "Epoch[1/2] Step[7127] Loss=0.2937\n",
            "Epoch[1/2] Step[7128] Loss=0.2084\n",
            "Epoch[1/2] Step[7129] Loss=0.4950\n",
            "Epoch[1/2] Step[7130] Loss=0.2324\n",
            "Epoch[1/2] Step[7131] Loss=0.2146\n",
            "Epoch[1/2] Step[7132] Loss=0.2303\n",
            "Epoch[1/2] Step[7133] Loss=0.1947\n",
            "Epoch[1/2] Step[7134] Loss=0.2000\n",
            "Epoch[1/2] Step[7135] Loss=0.2050\n",
            "Epoch[1/2] Step[7136] Loss=0.3132\n",
            "Epoch[1/2] Step[7137] Loss=0.4524\n",
            "Epoch[1/2] Step[7138] Loss=0.3496\n",
            "Epoch[1/2] Step[7139] Loss=0.2164\n",
            "Epoch[1/2] Step[7140] Loss=0.5636\n",
            "Epoch[1/2] Step[7141] Loss=0.4151\n",
            "Epoch[1/2] Step[7142] Loss=0.3644\n",
            "Epoch[1/2] Step[7143] Loss=0.1153\n",
            "Epoch[1/2] Step[7144] Loss=0.6627\n",
            "Epoch[1/2] Step[7145] Loss=0.1927\n",
            "Epoch[1/2] Step[7146] Loss=0.0664\n",
            "Epoch[1/2] Step[7147] Loss=0.2732\n",
            "Epoch[1/2] Step[7148] Loss=0.4053\n",
            "Epoch[1/2] Step[7149] Loss=0.3408\n",
            "Epoch[1/2] Step[7150] Loss=0.2138\n",
            "Epoch[1/2] Step[7151] Loss=0.1731\n",
            "Epoch[1/2] Step[7152] Loss=0.2423\n",
            "Epoch[1/2] Step[7153] Loss=0.4017\n",
            "Epoch[1/2] Step[7154] Loss=0.2833\n",
            "Epoch[1/2] Step[7155] Loss=0.1167\n",
            "Epoch[1/2] Step[7156] Loss=0.1258\n",
            "Epoch[1/2] Step[7157] Loss=0.2021\n",
            "Epoch[1/2] Step[7158] Loss=0.2615\n",
            "Epoch[1/2] Step[7159] Loss=0.3557\n",
            "Epoch[1/2] Step[7160] Loss=0.0664\n",
            "Epoch[1/2] Step[7161] Loss=0.2511\n",
            "Epoch[1/2] Step[7162] Loss=0.0835\n",
            "Epoch[1/2] Step[7163] Loss=0.0843\n",
            "Epoch[1/2] Step[7164] Loss=0.1082\n",
            "Epoch[1/2] Step[7165] Loss=0.2829\n",
            "Epoch[1/2] Step[7166] Loss=0.5807\n",
            "Epoch[1/2] Step[7167] Loss=0.4927\n",
            "Epoch[1/2] Step[7168] Loss=0.1902\n",
            "Epoch[1/2] Step[7169] Loss=0.2635\n",
            "Epoch[1/2] Step[7170] Loss=0.2433\n",
            "Epoch[1/2] Step[7171] Loss=0.3721\n",
            "Epoch[1/2] Step[7172] Loss=0.0864\n",
            "Epoch[1/2] Step[7173] Loss=0.4452\n",
            "Epoch[1/2] Step[7174] Loss=0.1759\n",
            "Epoch[1/2] Step[7175] Loss=0.1257\n",
            "Epoch[1/2] Step[7176] Loss=0.5571\n",
            "Epoch[1/2] Step[7177] Loss=0.2414\n",
            "Epoch[1/2] Step[7178] Loss=0.2944\n",
            "Epoch[1/2] Step[7179] Loss=0.1131\n",
            "Epoch[1/2] Step[7180] Loss=0.1832\n",
            "Epoch[1/2] Step[7181] Loss=0.1373\n",
            "Epoch[1/2] Step[7182] Loss=0.4171\n",
            "Epoch[1/2] Step[7183] Loss=0.1016\n",
            "Epoch[1/2] Step[7184] Loss=0.3626\n",
            "Epoch[1/2] Step[7185] Loss=0.0595\n",
            "Epoch[1/2] Step[7186] Loss=0.6226\n",
            "Epoch[1/2] Step[7187] Loss=0.7540\n",
            "Epoch[1/2] Step[7188] Loss=0.4516\n",
            "Epoch[1/2] Step[7189] Loss=0.0762\n",
            "Epoch[1/2] Step[7190] Loss=0.4943\n",
            "Epoch[1/2] Step[7191] Loss=0.5864\n",
            "Epoch[1/2] Step[7192] Loss=0.2173\n",
            "Epoch[1/2] Step[7193] Loss=0.2974\n",
            "Epoch[1/2] Step[7194] Loss=0.7661\n",
            "Epoch[1/2] Step[7195] Loss=0.5737\n",
            "Epoch[1/2] Step[7196] Loss=0.1870\n",
            "Epoch[1/2] Step[7197] Loss=0.2993\n",
            "Epoch[1/2] Step[7198] Loss=0.2135\n",
            "Epoch[1/2] Step[7199] Loss=0.3179\n",
            "Epoch[1/2] Step[7200] Loss=0.2843\n",
            "Epoch[1/2] Step[7201] Loss=0.2783\n",
            "Epoch[1/2] Step[7202] Loss=0.4378\n",
            "Epoch[1/2] Step[7203] Loss=0.4681\n",
            "Epoch[1/2] Step[7204] Loss=0.2959\n",
            "Epoch[1/2] Step[7205] Loss=0.4561\n",
            "Epoch[1/2] Step[7206] Loss=0.1090\n",
            "Epoch[1/2] Step[7207] Loss=0.3300\n",
            "Epoch[1/2] Step[7208] Loss=0.4242\n",
            "Epoch[1/2] Step[7209] Loss=0.1137\n",
            "Epoch[1/2] Step[7210] Loss=0.0392\n",
            "Epoch[1/2] Step[7211] Loss=0.2314\n",
            "Epoch[1/2] Step[7212] Loss=0.1689\n",
            "Epoch[1/2] Step[7213] Loss=0.6170\n",
            "Epoch[1/2] Step[7214] Loss=0.3348\n",
            "Epoch[1/2] Step[7215] Loss=0.2338\n",
            "Epoch[1/2] Step[7216] Loss=0.2974\n",
            "Epoch[1/2] Step[7217] Loss=0.1160\n",
            "Epoch[1/2] Step[7218] Loss=0.6053\n",
            "Epoch[1/2] Step[7219] Loss=0.3902\n",
            "Epoch[1/2] Step[7220] Loss=0.3988\n",
            "Epoch[1/2] Step[7221] Loss=0.2659\n",
            "Epoch[1/2] Step[7222] Loss=0.1218\n",
            "Epoch[1/2] Step[7223] Loss=0.2647\n",
            "Epoch[1/2] Step[7224] Loss=0.4933\n",
            "Epoch[1/2] Step[7225] Loss=0.2906\n",
            "Epoch[1/2] Step[7226] Loss=0.2072\n",
            "Epoch[1/2] Step[7227] Loss=0.0493\n",
            "Epoch[1/2] Step[7228] Loss=0.1540\n",
            "Epoch[1/2] Step[7229] Loss=0.8201\n",
            "Epoch[1/2] Step[7230] Loss=0.5736\n",
            "Epoch[1/2] Step[7231] Loss=0.0937\n",
            "Epoch[1/2] Step[7232] Loss=0.0593\n",
            "Epoch[1/2] Step[7233] Loss=0.4044\n",
            "Epoch[1/2] Step[7234] Loss=0.2429\n",
            "Epoch[1/2] Step[7235] Loss=0.4699\n",
            "Epoch[1/2] Step[7236] Loss=0.4673\n",
            "Epoch[1/2] Step[7237] Loss=0.4133\n",
            "Epoch[1/2] Step[7238] Loss=0.2981\n",
            "Epoch[1/2] Step[7239] Loss=1.5198\n",
            "Epoch[1/2] Step[7240] Loss=0.1506\n",
            "Epoch[1/2] Step[7241] Loss=0.2332\n",
            "Epoch[1/2] Step[7242] Loss=0.3929\n",
            "Epoch[1/2] Step[7243] Loss=0.0985\n",
            "Epoch[1/2] Step[7244] Loss=0.0559\n",
            "Epoch[1/2] Step[7245] Loss=0.2982\n",
            "Epoch[1/2] Step[7246] Loss=0.1593\n",
            "Epoch[1/2] Step[7247] Loss=0.2802\n",
            "Epoch[1/2] Step[7248] Loss=0.5953\n",
            "Epoch[1/2] Step[7249] Loss=0.0660\n",
            "Epoch[1/2] Step[7250] Loss=0.0926\n",
            "Epoch[1/2] Step[7251] Loss=0.1073\n",
            "Epoch[1/2] Step[7252] Loss=0.3001\n",
            "Epoch[1/2] Step[7253] Loss=0.9523\n",
            "Epoch[1/2] Step[7254] Loss=0.1578\n",
            "Epoch[1/2] Step[7255] Loss=0.4541\n",
            "Epoch[1/2] Step[7256] Loss=0.7860\n",
            "Epoch[1/2] Step[7257] Loss=0.6107\n",
            "Epoch[1/2] Step[7258] Loss=0.1609\n",
            "Epoch[1/2] Step[7259] Loss=0.2512\n",
            "Epoch[1/2] Step[7260] Loss=0.0737\n",
            "Epoch[1/2] Step[7261] Loss=0.2907\n",
            "Epoch[1/2] Step[7262] Loss=0.3240\n",
            "Epoch[1/2] Step[7263] Loss=0.2476\n",
            "Epoch[1/2] Step[7264] Loss=0.5175\n",
            "Epoch[1/2] Step[7265] Loss=0.1552\n",
            "Epoch[1/2] Step[7266] Loss=0.6526\n",
            "Epoch[1/2] Step[7267] Loss=0.0374\n",
            "Epoch[1/2] Step[7268] Loss=0.6210\n",
            "Epoch[1/2] Step[7269] Loss=0.2729\n",
            "Epoch[1/2] Step[7270] Loss=0.2276\n",
            "Epoch[1/2] Step[7271] Loss=0.1360\n",
            "Epoch[1/2] Step[7272] Loss=0.0712\n",
            "Epoch[1/2] Step[7273] Loss=0.4951\n",
            "Epoch[1/2] Step[7274] Loss=0.0754\n",
            "Epoch[1/2] Step[7275] Loss=0.2783\n",
            "Epoch[1/2] Step[7276] Loss=0.0523\n",
            "Epoch[1/2] Step[7277] Loss=0.0868\n",
            "Epoch[1/2] Step[7278] Loss=0.2872\n",
            "Epoch[1/2] Step[7279] Loss=0.2179\n",
            "Epoch[1/2] Step[7280] Loss=0.1973\n",
            "Epoch[1/2] Step[7281] Loss=0.2338\n",
            "Epoch[1/2] Step[7282] Loss=0.4570\n",
            "Epoch[1/2] Step[7283] Loss=0.0979\n",
            "Epoch[1/2] Step[7284] Loss=0.1562\n",
            "Epoch[1/2] Step[7285] Loss=0.5202\n",
            "Epoch[1/2] Step[7286] Loss=0.2296\n",
            "Epoch[1/2] Step[7287] Loss=0.2486\n",
            "Epoch[1/2] Step[7288] Loss=0.1718\n",
            "Epoch[1/2] Step[7289] Loss=0.0697\n",
            "Epoch[1/2] Step[7290] Loss=0.4474\n",
            "Epoch[1/2] Step[7291] Loss=0.0380\n",
            "Epoch[1/2] Step[7292] Loss=0.4408\n",
            "Epoch[1/2] Step[7293] Loss=0.2169\n",
            "Epoch[1/2] Step[7294] Loss=0.2581\n",
            "Epoch[1/2] Step[7295] Loss=0.1218\n",
            "Epoch[1/2] Step[7296] Loss=0.2906\n",
            "Epoch[1/2] Step[7297] Loss=0.2960\n",
            "Epoch[1/2] Step[7298] Loss=0.5378\n",
            "Epoch[1/2] Step[7299] Loss=0.2918\n",
            "Epoch[1/2] Step[7300] Loss=0.6781\n",
            "Epoch[1/2] Step[7301] Loss=0.1988\n",
            "Epoch[1/2] Step[7302] Loss=0.3154\n",
            "Epoch[1/2] Step[7303] Loss=0.4203\n",
            "Epoch[1/2] Step[7304] Loss=0.4109\n",
            "Epoch[1/2] Step[7305] Loss=0.0861\n",
            "Epoch[1/2] Step[7306] Loss=0.1455\n",
            "Epoch[1/2] Step[7307] Loss=0.4740\n",
            "Epoch[1/2] Step[7308] Loss=0.4874\n",
            "Epoch[1/2] Step[7309] Loss=0.2080\n",
            "Epoch[1/2] Step[7310] Loss=0.2149\n",
            "Epoch[1/2] Step[7311] Loss=0.3722\n",
            "Epoch[1/2] Step[7312] Loss=0.1949\n",
            "Epoch[1/2] Step[7313] Loss=0.1237\n",
            "Epoch[1/2] Step[7314] Loss=0.1109\n",
            "Epoch[1/2] Step[7315] Loss=0.0730\n",
            "Epoch[1/2] Step[7316] Loss=0.4092\n",
            "Epoch[1/2] Step[7317] Loss=0.2182\n",
            "Epoch[1/2] Step[7318] Loss=0.0997\n",
            "Epoch[1/2] Step[7319] Loss=0.0699\n",
            "Epoch[1/2] Step[7320] Loss=0.3315\n",
            "Epoch[1/2] Step[7321] Loss=0.2196\n",
            "Epoch[1/2] Step[7322] Loss=0.0863\n",
            "Epoch[1/2] Step[7323] Loss=1.0557\n",
            "Epoch[1/2] Step[7324] Loss=0.3215\n",
            "Epoch[1/2] Step[7325] Loss=0.3967\n",
            "Epoch[1/2] Step[7326] Loss=0.1481\n",
            "Epoch[1/2] Step[7327] Loss=0.4817\n",
            "Epoch[1/2] Step[7328] Loss=0.7990\n",
            "Epoch[1/2] Step[7329] Loss=0.4287\n",
            "Epoch[1/2] Step[7330] Loss=0.1199\n",
            "Epoch[1/2] Step[7331] Loss=0.4645\n",
            "Epoch[1/2] Step[7332] Loss=0.2043\n",
            "Epoch[1/2] Step[7333] Loss=0.2601\n",
            "Epoch[1/2] Step[7334] Loss=0.4231\n",
            "Epoch[1/2] Step[7335] Loss=0.0604\n",
            "Epoch[1/2] Step[7336] Loss=0.1222\n",
            "Epoch[1/2] Step[7337] Loss=0.3517\n",
            "Epoch[1/2] Step[7338] Loss=0.1124\n",
            "Epoch[1/2] Step[7339] Loss=0.0648\n",
            "Epoch[1/2] Step[7340] Loss=0.1118\n",
            "Epoch[1/2] Step[7341] Loss=0.9930\n",
            "Epoch[1/2] Step[7342] Loss=0.0892\n",
            "Epoch[1/2] Step[7343] Loss=0.0793\n",
            "Epoch[1/2] Step[7344] Loss=0.3017\n",
            "Epoch[1/2] Step[7345] Loss=0.1971\n",
            "Epoch[1/2] Step[7346] Loss=0.6094\n",
            "Epoch[1/2] Step[7347] Loss=0.1199\n",
            "Epoch[1/2] Step[7348] Loss=0.2602\n",
            "Epoch[1/2] Step[7349] Loss=0.6315\n",
            "Epoch[1/2] Step[7350] Loss=0.2888\n",
            "Epoch[1/2] Step[7351] Loss=0.3628\n",
            "Epoch[1/2] Step[7352] Loss=0.3557\n",
            "Epoch[1/2] Step[7353] Loss=0.0937\n",
            "Epoch[1/2] Step[7354] Loss=0.4919\n",
            "Epoch[1/2] Step[7355] Loss=0.0396\n",
            "Epoch[1/2] Step[7356] Loss=0.1768\n",
            "Epoch[1/2] Step[7357] Loss=0.2285\n",
            "Epoch[1/2] Step[7358] Loss=0.0881\n",
            "Epoch[1/2] Step[7359] Loss=0.4063\n",
            "Epoch[1/2] Step[7360] Loss=0.3181\n",
            "Epoch[1/2] Step[7361] Loss=0.1067\n",
            "Epoch[1/2] Step[7362] Loss=0.1491\n",
            "Epoch[1/2] Step[7363] Loss=0.4302\n",
            "Epoch[1/2] Step[7364] Loss=0.3288\n",
            "Epoch[1/2] Step[7365] Loss=0.0593\n",
            "Epoch[1/2] Step[7366] Loss=0.1505\n",
            "Epoch[1/2] Step[7367] Loss=0.3294\n",
            "Epoch[1/2] Step[7368] Loss=0.3266\n",
            "Epoch[1/2] Step[7369] Loss=0.1213\n",
            "Epoch[1/2] Step[7370] Loss=0.1630\n",
            "Epoch[1/2] Step[7371] Loss=0.4333\n",
            "Epoch[1/2] Step[7372] Loss=0.4268\n",
            "Epoch[1/2] Step[7373] Loss=0.4087\n",
            "Epoch[1/2] Step[7374] Loss=0.1644\n",
            "Epoch[1/2] Step[7375] Loss=0.1812\n",
            "Epoch[1/2] Step[7376] Loss=0.7445\n",
            "Epoch[1/2] Step[7377] Loss=0.0336\n",
            "Epoch[1/2] Step[7378] Loss=0.2393\n",
            "Epoch[1/2] Step[7379] Loss=1.3484\n",
            "Epoch[1/2] Step[7380] Loss=0.1254\n",
            "Epoch[1/2] Step[7381] Loss=0.6305\n",
            "Epoch[1/2] Step[7382] Loss=0.1401\n",
            "Epoch[1/2] Step[7383] Loss=0.1619\n",
            "Epoch[1/2] Step[7384] Loss=0.5160\n",
            "Epoch[1/2] Step[7385] Loss=0.1767\n",
            "Epoch[1/2] Step[7386] Loss=0.3118\n",
            "Epoch[1/2] Step[7387] Loss=0.2110\n",
            "Epoch[1/2] Step[7388] Loss=0.3227\n",
            "Epoch[1/2] Step[7389] Loss=0.4036\n",
            "Epoch[1/2] Step[7390] Loss=0.5918\n",
            "Epoch[1/2] Step[7391] Loss=0.4025\n",
            "Epoch[1/2] Step[7392] Loss=0.2110\n",
            "Epoch[1/2] Step[7393] Loss=0.0953\n",
            "Epoch[1/2] Step[7394] Loss=0.2556\n",
            "Epoch[1/2] Step[7395] Loss=0.7701\n",
            "Epoch[1/2] Step[7396] Loss=0.4201\n",
            "Epoch[1/2] Step[7397] Loss=0.0363\n",
            "Epoch[1/2] Step[7398] Loss=0.0768\n",
            "Epoch[1/2] Step[7399] Loss=0.4031\n",
            "Epoch[1/2] Step[7400] Loss=0.0746\n",
            "Epoch[1/2] Step[7401] Loss=0.0824\n",
            "Epoch[1/2] Step[7402] Loss=0.1126\n",
            "Epoch[1/2] Step[7403] Loss=0.1338\n",
            "Epoch[1/2] Step[7404] Loss=0.3332\n",
            "Epoch[1/2] Step[7405] Loss=0.0619\n",
            "Epoch[1/2] Step[7406] Loss=0.1659\n",
            "Epoch[1/2] Step[7407] Loss=0.2815\n",
            "Epoch[1/2] Step[7408] Loss=0.2599\n",
            "Epoch[1/2] Step[7409] Loss=0.5417\n",
            "Epoch[1/2] Step[7410] Loss=0.1513\n",
            "Epoch[1/2] Step[7411] Loss=0.1985\n",
            "Epoch[1/2] Step[7412] Loss=0.1861\n",
            "Epoch[1/2] Step[7413] Loss=0.2336\n",
            "Epoch[1/2] Step[7414] Loss=0.3743\n",
            "Epoch[1/2] Step[7415] Loss=0.4957\n",
            "Epoch[1/2] Step[7416] Loss=0.0746\n",
            "Epoch[1/2] Step[7417] Loss=0.0807\n",
            "Epoch[1/2] Step[7418] Loss=0.1393\n",
            "Epoch[1/2] Step[7419] Loss=0.5681\n",
            "Epoch[1/2] Step[7420] Loss=0.3157\n",
            "Epoch[1/2] Step[7421] Loss=0.0784\n",
            "Epoch[1/2] Step[7422] Loss=0.1231\n",
            "Epoch[1/2] Step[7423] Loss=0.0994\n",
            "Epoch[1/2] Step[7424] Loss=0.0620\n",
            "Epoch[1/2] Step[7425] Loss=0.2408\n",
            "Epoch[1/2] Step[7426] Loss=0.3911\n",
            "Epoch[1/2] Step[7427] Loss=0.1756\n",
            "Epoch[1/2] Step[7428] Loss=0.2341\n",
            "Epoch[1/2] Step[7429] Loss=0.3202\n",
            "Epoch[1/2] Step[7430] Loss=0.3092\n",
            "Epoch[1/2] Step[7431] Loss=0.2209\n",
            "Epoch[1/2] Step[7432] Loss=0.2889\n",
            "Epoch[1/2] Step[7433] Loss=0.1632\n",
            "Epoch[1/2] Step[7434] Loss=0.3027\n",
            "Epoch[1/2] Step[7435] Loss=0.4140\n",
            "Epoch[1/2] Step[7436] Loss=0.7212\n",
            "Epoch[1/2] Step[7437] Loss=0.0547\n",
            "Epoch[1/2] Step[7438] Loss=0.1209\n",
            "Epoch[1/2] Step[7439] Loss=0.7126\n",
            "Epoch[1/2] Step[7440] Loss=0.1725\n",
            "Epoch[1/2] Step[7441] Loss=0.2248\n",
            "Epoch[1/2] Step[7442] Loss=0.3181\n",
            "Epoch[1/2] Step[7443] Loss=0.1764\n",
            "Epoch[1/2] Step[7444] Loss=0.4283\n",
            "Epoch[1/2] Step[7445] Loss=0.3078\n",
            "Epoch[1/2] Step[7446] Loss=0.0431\n",
            "Epoch[1/2] Step[7447] Loss=0.1418\n",
            "Epoch[1/2] Step[7448] Loss=0.0939\n",
            "Epoch[1/2] Step[7449] Loss=0.2498\n",
            "Epoch[1/2] Step[7450] Loss=0.3780\n",
            "Epoch[1/2] Step[7451] Loss=0.3404\n",
            "Epoch[1/2] Step[7452] Loss=0.4148\n",
            "Epoch[1/2] Step[7453] Loss=0.1728\n",
            "Epoch[1/2] Step[7454] Loss=0.0609\n",
            "Epoch[1/2] Step[7455] Loss=0.8937\n",
            "Epoch[1/2] Step[7456] Loss=0.0804\n",
            "Epoch[1/2] Step[7457] Loss=0.2649\n",
            "Epoch[1/2] Step[7458] Loss=0.0734\n",
            "Epoch[1/2] Step[7459] Loss=0.1968\n",
            "Epoch[1/2] Step[7460] Loss=0.2848\n",
            "Epoch[1/2] Step[7461] Loss=0.1942\n",
            "Epoch[1/2] Step[7462] Loss=0.1744\n",
            "Epoch[1/2] Step[7463] Loss=0.0975\n",
            "Epoch[1/2] Step[7464] Loss=0.3240\n",
            "Epoch[1/2] Step[7465] Loss=0.3332\n",
            "Epoch[1/2] Step[7466] Loss=0.1546\n",
            "Epoch[1/2] Step[7467] Loss=0.3999\n",
            "Epoch[1/2] Step[7468] Loss=0.2349\n",
            "Epoch[1/2] Step[7469] Loss=0.7273\n",
            "Epoch[1/2] Step[7470] Loss=0.3334\n",
            "Epoch[1/2] Step[7471] Loss=0.3520\n",
            "Epoch[1/2] Step[7472] Loss=0.0375\n",
            "Epoch[1/2] Step[7473] Loss=0.2460\n",
            "Epoch[1/2] Step[7474] Loss=0.3012\n",
            "Epoch[1/2] Step[7475] Loss=0.2338\n",
            "Epoch[1/2] Step[7476] Loss=0.1141\n",
            "Epoch[1/2] Step[7477] Loss=0.3758\n",
            "Epoch[1/2] Step[7478] Loss=0.4625\n",
            "Epoch[1/2] Step[7479] Loss=0.1341\n",
            "Epoch[1/2] Step[7480] Loss=0.5583\n",
            "Epoch[1/2] Step[7481] Loss=0.3307\n",
            "Epoch[1/2] Step[7482] Loss=0.3031\n",
            "Epoch[1/2] Step[7483] Loss=0.4394\n",
            "Epoch[1/2] Step[7484] Loss=0.1014\n",
            "Epoch[1/2] Step[7485] Loss=0.2731\n",
            "Epoch[1/2] Step[7486] Loss=0.4285\n",
            "Epoch[1/2] Step[7487] Loss=0.1083\n",
            "Epoch[1/2] Step[7488] Loss=0.1885\n",
            "Epoch[1/2] Step[7489] Loss=0.2712\n",
            "Epoch[1/2] Step[7490] Loss=0.4861\n",
            "Epoch[1/2] Step[7491] Loss=0.1823\n",
            "Epoch[1/2] Step[7492] Loss=0.1914\n",
            "Epoch[1/2] Step[7493] Loss=0.3856\n",
            "Epoch[1/2] Step[7494] Loss=0.1831\n",
            "Epoch[1/2] Step[7495] Loss=0.3981\n",
            "Epoch[1/2] Step[7496] Loss=0.2352\n",
            "Epoch[1/2] Step[7497] Loss=0.3243\n",
            "Epoch[1/2] Step[7498] Loss=0.3351\n",
            "Epoch[1/2] Step[7499] Loss=0.0754\n",
            "Epoch[1/2] Step[7500] Loss=0.0993\n",
            "Epoch 2/2 => TrainLoss=0.3298 TestLoss=0.2693 Acc=92.03%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁█</td></tr><tr><td>test_accuracy</td><td>▁█</td></tr><tr><td>test_loss</td><td>█▁</td></tr><tr><td>train_loss</td><td>█▆▆▇▃▂▅▂▆▂▃▄▂▁▂▃▃▂▂▃▂▂▃▄▁▂▂▁▁▃▁▂▁▄▂▃▃▃▂▃</td></tr><tr><td>train_loss_epoch</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1</td></tr><tr><td>test_accuracy</td><td>92.03</td></tr><tr><td>test_loss</td><td>0.26934</td></tr><tr><td>train_loss</td><td>0.09931</td></tr><tr><td>train_loss_epoch</td><td>0.32975</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">lucky-river-6</strong> at: <a href='https://wandb.ai/marlborough-college-malaysia/AAH-IA__gradient-descent__/runs/7s6krwl6' target=\"_blank\">https://wandb.ai/marlborough-college-malaysia/AAH-IA__gradient-descent__/runs/7s6krwl6</a><br> View project at: <a href='https://wandb.ai/marlborough-college-malaysia/AAH-IA__gradient-descent__' target=\"_blank\">https://wandb.ai/marlborough-college-malaysia/AAH-IA__gradient-descent__</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250115_132045-7s6krwl6/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done with main(). Returning model.\n"
          ]
        }
      ],
      "source": [
        "##################################################\n",
        "# 6) Main\n",
        "##################################################\n",
        "def main(\n",
        "    optimizer_name=\"gd\",\n",
        "    lr=1.0,\n",
        "    epochs=2,\n",
        "    batch_size=16,\n",
        "    wandb_project=\"AAH-IA__newton-rhapson__\",\n",
        "):\n",
        "    hf_token = os.environ.get(\"HF_TOKEN\", None)\n",
        "    wandb_key = os.environ.get(\"wandb\", None)\n",
        "\n",
        "    print(\"HF token:\", bool(hf_token))\n",
        "    print(\"W&B key:\", bool(wandb_key))\n",
        "    print(f\"Using {optimizer_name} with ~9.6k param model. LR={lr}, epochs={epochs}, batch_size={batch_size}\")\n",
        "\n",
        "    model = train_model(\n",
        "        optimizer_name=optimizer_name,\n",
        "        learning_rate=lr,\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        wandb_project=wandb_project\n",
        "    )\n",
        "    print(\"Done with main(). Returning model.\")\n",
        "    return model\n",
        "\n",
        "\n",
        "# Example if we want to run immediately:\n",
        "if __name__ == \"__main__\":\n",
        "    model = main(\n",
        "        optimizer_name=\"gd\",\n",
        "        lr=0.01,\n",
        "        epochs=2,\n",
        "        batch_size=16,\n",
        "        wandb_project=\"AAH-IA__gradient-descent__\"  # or AAH-IA__gradient-descent__\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "SHlkTdAyE9eJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gnhQT3onFx96"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}