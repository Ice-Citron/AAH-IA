{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# INITIAL TEST"
      ],
      "metadata": {
        "id": "eiRTKba4bQw1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "jwVvDUwtaQgE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.optimize import minimize\n",
        "from dataclasses import dataclass\n",
        "from typing import Callable, List, Dict, Optional, Tuple\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import psutil\n",
        "\n",
        "\n",
        "\n",
        "class OptimizationResult:\n",
        "    \"\"\"Enhanced optimization result storage\"\"\"\n",
        "    def __init__(self, **kwargs):\n",
        "        self.x_final = kwargs.get('x_final')\n",
        "        self.f_final = kwargs.get('f_final')\n",
        "        self.success = kwargs.get('success')\n",
        "        self.iterations = kwargs.get('iterations')\n",
        "        self.runtime = kwargs.get('runtime')\n",
        "        self.path = kwargs.get('path', [])\n",
        "        self.f_path = kwargs.get('f_path', [])\n",
        "        self.grad_norm_path = kwargs.get('grad_norm_path', [])\n",
        "        self.timestamps = kwargs.get('timestamps', [])\n",
        "        self.memory_usage = kwargs.get('memory_usage', [])\n",
        "        self.flops_per_step = kwargs.get('flops_per_step', [])\n",
        "        self.method = kwargs.get('method')\n",
        "        self.dimension = kwargs.get('dimension')\n",
        "        self.function_name = kwargs.get('function_name')\n",
        "        self.x_initial = kwargs.get('x_initial')\n",
        "        self.f_initial = kwargs.get('f_initial')\n",
        "        self.grad_initial = kwargs.get('grad_initial')\n",
        "        self.grad_final = kwargs.get('grad_final')\n",
        "\n",
        "        # Calculate distance from global minimum\n",
        "        x_min, f_min = TestFunctions.get_global_minimum(self.function_name, self.dimension)\n",
        "        if x_min is not None and f_min is not None:\n",
        "            self.distance_to_minimum = np.linalg.norm(self.x_final - x_min)\n",
        "            self.f_error = abs(self.f_final - f_min)\n",
        "        else:\n",
        "            self.distance_to_minimum = None\n",
        "            self.f_error = None\n",
        "\n",
        "\n",
        "class FLOPCounter:\n",
        "    \"\"\"Tracks floating point operations\"\"\"\n",
        "    def __init__(self):\n",
        "        self.flops = 0\n",
        "        self.operation_counts = {\n",
        "            'add': 0,\n",
        "            'multiply': 0,\n",
        "            'divide': 0,\n",
        "            'sqrt': 0,\n",
        "            'exp': 0,\n",
        "            'log': 0,\n",
        "            'trig': 0\n",
        "        }\n",
        "\n",
        "    def add_flops(self, operation: str, count: int = 1):\n",
        "        self.operation_counts[operation] += count\n",
        "        # Update total FLOPS based on operation weight\n",
        "        weights = {\n",
        "            'add': 1,\n",
        "            'multiply': 1,\n",
        "            'divide': 4,\n",
        "            'sqrt': 8,\n",
        "            'exp': 10,\n",
        "            'log': 10,\n",
        "            'trig': 15\n",
        "        }\n",
        "        self.flops += weights[operation] * count\n",
        "\n",
        "    def get_summary(self) -> dict:\n",
        "        return {\n",
        "            'total_flops': self.flops,\n",
        "            'operations': self.operation_counts\n",
        "        }\n",
        "\n",
        "class TestFunctions:\n",
        "    \"\"\"Test functions that work with any dimension\"\"\"\n",
        "    @staticmethod\n",
        "    def get_global_minimum(func_name: str, dimension: int = 2) -> tuple:\n",
        "        \"\"\"Get global minimum for a given function and dimension\"\"\"\n",
        "        global_minima = {\n",
        "            'ackley': (np.zeros(dimension), 0.0),\n",
        "            'rastrigin': (np.zeros(dimension), 0.0),\n",
        "            'rosenbrock': (np.ones(dimension), 0.0),\n",
        "            'sphere': (np.zeros(dimension), 0.0),\n",
        "            'michalewicz': (None, None),  # Varies with dimension\n",
        "        }\n",
        "        return global_minima.get(func_name, (None, None))\n",
        "\n",
        "    @staticmethod\n",
        "    def ackley(x: np.ndarray) -> float:\n",
        "        \"\"\"Ackley function for n dimensions\"\"\"\n",
        "        n = len(x)\n",
        "        sum_sq = np.sum(x**2)\n",
        "        sum_cos = np.sum(np.cos(2 * np.pi * x))\n",
        "        return (-20 * np.exp(-0.2 * np.sqrt(sum_sq / n))\n",
        "                - np.exp(sum_cos / n)\n",
        "                + 20 + np.e)\n",
        "\n",
        "    @staticmethod\n",
        "    def ackley_gradient(x: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Gradient of Ackley function\"\"\"\n",
        "        n = len(x)\n",
        "        sum_sq = np.sum(x**2)\n",
        "        sum_cos = np.sum(np.cos(2 * np.pi * x))\n",
        "\n",
        "        term1 = (20 * 0.2 / np.sqrt(n * sum_sq)) * np.exp(-0.2 * np.sqrt(sum_sq / n)) * x\n",
        "        term2 = (2 * np.pi / n) * np.exp(sum_cos / n) * np.sin(2 * np.pi * x)\n",
        "        return term1 + term2\n",
        "\n",
        "    @staticmethod\n",
        "    def ackley_hessian(x: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Numerical approximation of Ackley Hessian\"\"\"\n",
        "        eps = 1e-8\n",
        "        n = len(x)\n",
        "        H = np.zeros((n, n))\n",
        "        grad = TestFunctions.ackley_gradient\n",
        "\n",
        "        for i in range(n):\n",
        "            for j in range(n):\n",
        "                x_ij = x.copy()\n",
        "                x_ij[i] += eps\n",
        "                x_ij[j] += eps\n",
        "                H[i,j] = (grad(x_ij)[i] - grad(x)[i]) / eps\n",
        "\n",
        "        return (H + H.T) / 2  # Ensure symmetry\n",
        "\n",
        "    @staticmethod\n",
        "    def rastrigin(x: np.ndarray) -> float:\n",
        "        \"\"\"Rastrigin function for n dimensions\"\"\"\n",
        "        n = len(x)\n",
        "        return 10 * n + np.sum(x**2 - 10 * np.cos(2 * np.pi * x))\n",
        "\n",
        "    @staticmethod\n",
        "    def rastrigin_gradient(x: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Gradient of Rastrigin function\"\"\"\n",
        "        return 2 * x + 20 * np.pi * np.sin(2 * np.pi * x)\n",
        "\n",
        "    @staticmethod\n",
        "    def rastrigin_hessian(x: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Hessian of Rastrigin function\"\"\"\n",
        "        n = len(x)\n",
        "        return 2 * np.eye(n) + 40 * np.pi**2 * np.diag(np.cos(2 * np.pi * x))\n",
        "\n",
        "    @staticmethod\n",
        "    def sphere(x: np.ndarray) -> float:\n",
        "        \"\"\"Sphere function for n dimensions\"\"\"\n",
        "        return np.sum(x**2)\n",
        "\n",
        "    @staticmethod\n",
        "    def sphere_gradient(x: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Gradient of Sphere function\"\"\"\n",
        "        return 2 * x\n",
        "\n",
        "    @staticmethod\n",
        "    def sphere_hessian(x: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Hessian of Sphere function\"\"\"\n",
        "        n = len(x)\n",
        "        return 2 * np.eye(n)\n",
        "\n",
        "    @staticmethod\n",
        "    def rosenbrock(x: np.ndarray) -> float:\n",
        "        \"\"\"Rosenbrock function for n dimensions\"\"\"\n",
        "        return np.sum(100.0 * (x[1:] - x[:-1]**2)**2 + (1 - x[:-1])**2)\n",
        "\n",
        "    @staticmethod\n",
        "    def rosenbrock_gradient(x: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Gradient of Rosenbrock function\"\"\"\n",
        "        n = len(x)\n",
        "        grad = np.zeros(n)\n",
        "        grad[0] = -400 * x[0] * (x[1] - x[0]**2) - 2 * (1 - x[0])\n",
        "        grad[-1] = 200 * (x[-1] - x[-2]**2)\n",
        "        if n > 2:\n",
        "            grad[1:-1] = 200 * (x[1:-1] - x[:-2]**2) - 400 * x[1:-1] * (x[2:] - x[1:-1]**2) - 2 * (1 - x[1:-1])\n",
        "        return grad\n",
        "\n",
        "    @staticmethod\n",
        "    def rosenbrock_hessian(x: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Numerical approximation of Rosenbrock Hessian\"\"\"\n",
        "        eps = 1e-8\n",
        "        n = len(x)\n",
        "        H = np.zeros((n, n))\n",
        "        grad = TestFunctions.rosenbrock_gradient\n",
        "\n",
        "        for i in range(n):\n",
        "            for j in range(n):\n",
        "                x_ij = x.copy()\n",
        "                x_ij[i] += eps\n",
        "                x_ij[j] += eps\n",
        "                H[i,j] = (grad(x_ij)[i] - grad(x)[i]) / eps\n",
        "\n",
        "        return (H + H.T) / 2  # Ensure symmetry\n",
        "\n",
        "class OptimizationLogger:\n",
        "    \"\"\"Handles logging of optimization progress\"\"\"\n",
        "    def __init__(self, method: str, function_name: str, dimension: int):\n",
        "        self.method = method\n",
        "        self.function_name = function_name\n",
        "        self.dimension = dimension\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.path = []\n",
        "        self.f_path = []\n",
        "        self.grad_norm_path = []\n",
        "        self.step_sizes = []\n",
        "        self.memory_usage = []\n",
        "        self.timestamps = []\n",
        "        self.start_time = time.time()\n",
        "\n",
        "    def log_iteration(self, x: np.ndarray, f: float, grad_norm: float, step_size: float):\n",
        "        self.path.append(x.copy())\n",
        "        self.f_path.append(f)\n",
        "        self.grad_norm_path.append(grad_norm)\n",
        "        self.step_sizes.append(step_size)\n",
        "        self.memory_usage.append(self.get_memory_usage())\n",
        "        self.timestamps.append(time.time() - self.start_time)\n",
        "\n",
        "    @staticmethod\n",
        "    def get_memory_usage() -> float:\n",
        "        \"\"\"Get current memory usage in MB\"\"\"\n",
        "        import psutil\n",
        "        process = psutil.Process()\n",
        "        return process.memory_info().rss / 1024 / 1024\n",
        "\n",
        "    def save_logs(self, base_dir: str):\n",
        "        \"\"\"Save optimization logs to CSV\"\"\"\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        log_dir = os.path.join(base_dir, self.function_name, str(self.dimension) + \"D\", self.method)\n",
        "        os.makedirs(log_dir, exist_ok=True)\n",
        "\n",
        "        log_data = {\n",
        "            'iteration': range(len(self.path)),\n",
        "            'function_value': self.f_path,\n",
        "            'gradient_norm': self.grad_norm_path,\n",
        "            'step_size': self.step_sizes,\n",
        "            'memory_mb': self.memory_usage,\n",
        "            'runtime_seconds': self.timestamps\n",
        "        }\n",
        "\n",
        "        # Add parameter values\n",
        "        for i in range(self.dimension):\n",
        "            log_data[f'x{i+1}'] = [p[i] for p in self.path]\n",
        "\n",
        "        df = pd.DataFrame(log_data)\n",
        "        df.to_csv(os.path.join(log_dir, f'optimization_log_{timestamp}.csv'), index=False)\n",
        "\n",
        "class Visualizer:\n",
        "    \"\"\"Enhanced visualization capabilities\"\"\"\n",
        "    @staticmethod\n",
        "    def plot_optimization_summary(results: Dict[str, OptimizationResult], save_dir: str, function_name: str):\n",
        "        \"\"\"Plot summary comparing initial and final states\"\"\"\n",
        "        if not results:\n",
        "            return\n",
        "\n",
        "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "        methods = list(results.keys())\n",
        "        x = np.arange(len(methods))\n",
        "\n",
        "        # Fix the ticks warning by setting them explicitly\n",
        "        for ax in [ax1, ax2, ax3, ax4]:\n",
        "            ax.set_xticks(x)\n",
        "            ax.set_xticklabels(methods, rotation=45)\n",
        "\n",
        "        # Function Values Plot\n",
        "        initial_values = [result.f_initial for result in results.values()]\n",
        "        final_values = [result.f_final for result in results.values()]\n",
        "        width = 0.35\n",
        "\n",
        "        ax1.bar(x - width/2, initial_values, width, label='Initial', color='lightcoral')\n",
        "        ax1.bar(x + width/2, final_values, width, label='Final', color='lightgreen')\n",
        "        ax1.set_ylabel('Function Value')\n",
        "        ax1.set_title('Initial vs Final Function Values')\n",
        "        ax1.set_xticks(x)\n",
        "        ax1.set_xticklabels(methods, rotation=45)\n",
        "        ax1.legend()\n",
        "        ax1.grid(True)\n",
        "\n",
        "        # Add global minimum line if available\n",
        "        _, f_min = TestFunctions.get_global_minimum(function_name, results[methods[0]].dimension)\n",
        "        if f_min is not None:\n",
        "            ax1.axhline(y=f_min, color='r', linestyle='--', label=f'Global Min ({f_min})')\n",
        "            ax1.legend()\n",
        "\n",
        "        # Gradient Norms Plot\n",
        "        initial_grads = [np.linalg.norm(result.grad_initial) for result in results.values()]\n",
        "        final_grads = [np.linalg.norm(result.grad_final) for result in results.values()]\n",
        "\n",
        "        ax2.bar(x - width/2, initial_grads, width, label='Initial', color='lightcoral')\n",
        "        ax2.bar(x + width/2, final_grads, width, label='Final', color='lightgreen')\n",
        "        ax2.set_ylabel('Gradient Norm')\n",
        "        ax2.set_title('Initial vs Final Gradient Norms')\n",
        "        ax2.set_xticks(x)\n",
        "        ax2.set_xticklabels(methods, rotation=45)\n",
        "        ax2.legend()\n",
        "        ax2.grid(True)\n",
        "\n",
        "        # Runtime Comparison\n",
        "        runtimes = [result.runtime for result in results.values()]\n",
        "        ax3.bar(methods, runtimes, color='skyblue')\n",
        "        ax3.set_ylabel('Runtime (seconds)')\n",
        "        ax3.set_title('Total Runtime by Method')\n",
        "        ax3.set_xticklabels(methods, rotation=45)\n",
        "        ax3.grid(True)\n",
        "\n",
        "        # Iterations Comparison\n",
        "        iterations = [result.iterations for result in results.values()]\n",
        "        ax4.bar(methods, iterations, color='lightgreen')\n",
        "        ax4.set_ylabel('Number of Iterations')\n",
        "        ax4.set_title('Total Iterations by Method')\n",
        "        ax4.set_xticklabels(methods, rotation=45)\n",
        "        ax4.grid(True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(save_dir, f'optimization_summary_{function_name}.png'), dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "    @staticmethod\n",
        "    def plot_convergence(results: Dict[str, OptimizationResult], save_dir: str, function_name: str):\n",
        "        \"\"\"Plot convergence with enhanced information\"\"\"\n",
        "        if not results:  # Skip if no results\n",
        "            return\n",
        "\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "        # Get global minimum if available\n",
        "        x_min, f_min = TestFunctions.get_global_minimum(function_name)\n",
        "        f_min_text = f\"(Global min: {f_min})\" if f_min is not None else \"\"\n",
        "\n",
        "        # Function value convergence\n",
        "        for method, result in results.items():\n",
        "            if result.f_path:  # Only plot if we have data\n",
        "                ax1.semilogy(result.f_path, label=f\"{method}\")\n",
        "        ax1.set_xlabel('Iteration')\n",
        "        ax1.set_ylabel('Function Value (log scale)')\n",
        "        ax1.set_title(f'Function Value Convergence {f_min_text}')\n",
        "        if any(len(result.f_path) > 0 for result in results.values()):\n",
        "            ax1.legend()\n",
        "        ax1.grid(True)\n",
        "\n",
        "        # Gradient norm convergence\n",
        "        for method, result in results.items():\n",
        "            if result.grad_norm_path:  # Only plot if we have data\n",
        "                ax2.semilogy(result.grad_norm_path, label=f\"{method}\")\n",
        "        ax2.set_xlabel('Iteration')\n",
        "        ax2.set_ylabel('Gradient Norm (log scale)')\n",
        "        ax2.set_title('Gradient Norm Convergence')\n",
        "        if any(len(result.grad_norm_path) > 0 for result in results.values()):\n",
        "            ax2.legend()\n",
        "        ax2.grid(True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(save_dir, f'convergence_{function_name}.png'), dpi=300)\n",
        "        plt.close()\n",
        "\n",
        "    @staticmethod\n",
        "    def plot_2d_trajectory(f: Callable, result: OptimizationResult, save_dir: str):\n",
        "        \"\"\"Plot optimization trajectory for 2D problems\"\"\"\n",
        "        if result.dimension != 2:\n",
        "            return\n",
        "\n",
        "        plt.figure(figsize=(10, 8))\n",
        "\n",
        "        # Create contour plot\n",
        "        x_min = min(p[0] for p in result.path) - 0.5\n",
        "        x_max = max(p[0] for p in result.path) + 0.5\n",
        "        y_min = min(p[1] for p in result.path) - 0.5\n",
        "        y_max = max(p[1] for p in result.path) + 0.5\n",
        "\n",
        "        x = np.linspace(x_min, x_max, 100)\n",
        "        y = np.linspace(y_min, y_max, 100)\n",
        "        X, Y = np.meshgrid(x, y)\n",
        "        Z = np.array([[f(np.array([xi, yi])) for xi in x] for yi in y])\n",
        "\n",
        "        plt.contour(X, Y, Z, levels=50)\n",
        "        plt.colorbar(label='Function Value')\n",
        "\n",
        "        # Plot trajectory\n",
        "        path = np.array(result.path)\n",
        "        plt.plot(path[:, 0], path[:, 1], 'r.-', label='Optimization Path', linewidth=1, markersize=2)\n",
        "        plt.plot(path[0, 0], path[0, 1], 'go', label='Start', markersize=8)\n",
        "        plt.plot(path[-1, 0], path[-1, 1], 'ro', label='End', markersize=8)\n",
        "\n",
        "        # Get and plot global minimum if available\n",
        "        x_min, f_min = TestFunctions.get_global_minimum(result.function_name)\n",
        "        if x_min is not None:\n",
        "            plt.plot(x_min[0], x_min[1], 'k*', label='Global Minimum', markersize=10)\n",
        "\n",
        "        plt.title(f'{result.function_name} - {result.method}\\n'\n",
        "                 f'Final value: {result.f_final:.6f}\\n'\n",
        "                 f'Iterations: {result.iterations}')\n",
        "        plt.xlabel('x₁')\n",
        "        plt.ylabel('x₂')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        plt.savefig(os.path.join(save_dir,\n",
        "                                f'trajectory_{result.function_name}_{result.method}.png'),\n",
        "                   dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "    @staticmethod\n",
        "    def plot_computational_metrics(results: Dict[str, OptimizationResult], save_dir: str):\n",
        "        \"\"\"Plot computational metrics over time\"\"\"\n",
        "        if not results:  # Skip if no results\n",
        "            return\n",
        "\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "        # Memory usage over time\n",
        "        for method, result in results.items():\n",
        "            if result.timestamps and result.memory_usage:  # Only plot if we have data\n",
        "                ax1.plot(result.timestamps, result.memory_usage, label=method)\n",
        "        ax1.set_xlabel('Time (seconds)')\n",
        "        ax1.set_ylabel('Memory Usage (MB)')\n",
        "        ax1.set_title('Memory Usage Over Time')\n",
        "        if any(len(result.timestamps) > 0 for result in results.values()):\n",
        "            ax1.legend()\n",
        "        ax1.grid(True)\n",
        "\n",
        "        # FLOPS over time\n",
        "        for method, result in results.items():\n",
        "            if result.timestamps and result.flops_per_step:  # Only plot if we have data\n",
        "                cumulative_flops = np.cumsum(result.flops_per_step)\n",
        "                ax2.plot(result.timestamps, cumulative_flops, label=method)\n",
        "        ax2.set_xlabel('Time (seconds)')\n",
        "        ax2.set_ylabel('Cumulative FLOPS')\n",
        "        ax2.set_title('Computational Cost Over Time')\n",
        "        if any(len(result.timestamps) > 0 for result in results.values()):\n",
        "            ax2.legend()\n",
        "        ax2.grid(True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(save_dir, 'computational_metrics.png'), dpi=300)\n",
        "        plt.close()\n",
        "\n",
        "def get_memory_usage() -> float:\n",
        "    \"\"\"Get current memory usage in MB\"\"\"\n",
        "    process = psutil.Process()\n",
        "    return process.memory_info().rss / 1024 / 1024\n",
        "\n",
        "def run_optimization(f: Callable,\n",
        "                    grad: Callable,\n",
        "                    hess: Callable,\n",
        "                    x0: np.ndarray,\n",
        "                    method: str,\n",
        "                    function_name: str) -> OptimizationResult:\n",
        "    \"\"\"Enhanced optimization runner with detailed metrics\"\"\"\n",
        "    start_time = time.time()\n",
        "    flop_counter = FLOPCounter()\n",
        "\n",
        "    # Calculate initial metrics\n",
        "    f_initial = f(x0)\n",
        "    grad_initial = grad(x0)\n",
        "\n",
        "    # Storage for metrics\n",
        "    path = [x0.copy()]  # Start with initial point\n",
        "    f_path = [f_initial]\n",
        "    grad_norm_path = [np.linalg.norm(grad_initial)]\n",
        "    timestamps = [0.0]\n",
        "    memory_usage = [get_memory_usage()]\n",
        "    flops_per_step = [0]\n",
        "\n",
        "    def callback(xk):\n",
        "        current_time = time.time() - start_time\n",
        "\n",
        "        # Calculate metrics\n",
        "        f_val = f(xk)\n",
        "        grad_val = grad(xk)\n",
        "        grad_norm = np.linalg.norm(grad_val)\n",
        "\n",
        "        # Store metrics\n",
        "        path.append(xk.copy())\n",
        "        f_path.append(f_val)\n",
        "        grad_norm_path.append(grad_norm)\n",
        "        timestamps.append(current_time)\n",
        "        memory_usage.append(get_memory_usage())\n",
        "        flops_per_step.append(flop_counter.flops)\n",
        "\n",
        "    try:\n",
        "        # Run optimization with method-specific settings\n",
        "        if method == 'BFGS':\n",
        "            result = minimize(f, x0, method=method, jac=grad, callback=callback)\n",
        "        elif method == 'newton-cg':\n",
        "            result = minimize(f, x0, method=method, jac=grad, hess=hess, callback=callback)\n",
        "        elif method in ['trust-exact', 'trust-krylov']:\n",
        "            result = minimize(f, x0, method=method, jac=grad, hess=hess, callback=callback)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported method: {method}\")\n",
        "\n",
        "        # Calculate final gradient\n",
        "        grad_final = grad(result.x)\n",
        "\n",
        "        return OptimizationResult(\n",
        "            x_final=result.x,\n",
        "            f_final=result.fun,\n",
        "            success=result.success,\n",
        "            iterations=result.nit,\n",
        "            runtime=time.time() - start_time,\n",
        "            path=path,\n",
        "            f_path=f_path,\n",
        "            grad_norm_path=grad_norm_path,\n",
        "            timestamps=timestamps,\n",
        "            memory_usage=memory_usage,\n",
        "            flops_per_step=flops_per_step,\n",
        "            method=method,\n",
        "            dimension=len(x0),\n",
        "            function_name=function_name,\n",
        "            x_initial=x0,\n",
        "            f_initial=f_initial,\n",
        "            grad_initial=grad_initial,\n",
        "            grad_final=grad_final\n",
        "        )\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Optimization failed: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    base_dir = \"optimization_results\"\n",
        "    os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "    test_functions = {\n",
        "        'ackley': (\n",
        "            TestFunctions.ackley,\n",
        "            TestFunctions.ackley_gradient,\n",
        "            TestFunctions.ackley_hessian\n",
        "        ),\n",
        "        'rastrigin': (\n",
        "            TestFunctions.rastrigin,\n",
        "            TestFunctions.rastrigin_gradient,\n",
        "            TestFunctions.rastrigin_hessian\n",
        "        ),\n",
        "        'sphere': (\n",
        "            TestFunctions.sphere,\n",
        "            TestFunctions.sphere_gradient,\n",
        "            TestFunctions.sphere_hessian\n",
        "        ),\n",
        "        'rosenbrock': (\n",
        "            TestFunctions.rosenbrock,\n",
        "            TestFunctions.rosenbrock_gradient,\n",
        "            TestFunctions.rosenbrock_hessian\n",
        "        )\n",
        "    }\n",
        "\n",
        "    methods = ['BFGS', 'newton-cg', 'trust-exact', 'trust-krylov']\n",
        "    dimensions = [2, 4, 8, 12]\n",
        "\n",
        "    # Summary data\n",
        "    summary_data = []\n",
        "\n",
        "    for func_name, (f, grad, hess) in test_functions.items():\n",
        "        print(f\"\\nTesting {func_name} function:\")\n",
        "\n",
        "        for dim in dimensions:\n",
        "            print(f\"\\nDimension: {dim}\")\n",
        "\n",
        "            # Set random seed for reproducibility\n",
        "            np.random.seed(42)\n",
        "            x0 = np.random.uniform(-4, 4, dim)\n",
        "\n",
        "            results = {}\n",
        "            for method in methods:\n",
        "                print(f\"\\nRunning {method}...\")\n",
        "                try:\n",
        "                    result = run_optimization(f, grad, hess, x0, method, func_name)\n",
        "                    results[method] = result\n",
        "\n",
        "                    # Add to summary\n",
        "                    summary_data.append({\n",
        "                        'function': func_name,\n",
        "                        'dimension': dim,\n",
        "                        'method': method,\n",
        "                        'final_value': result.f_final,\n",
        "                        'iterations': result.iterations,\n",
        "                        'runtime': result.runtime,\n",
        "                        'total_flops': result.flops_per_step[-1],\n",
        "                        'success': result.success,\n",
        "                        'distance_to_minimum': result.distance_to_minimum,\n",
        "                        'f_error': result.f_error\n",
        "                    })\n",
        "\n",
        "                    print(f\"Final value: {result.f_final:.6f}\")\n",
        "                    print(f\"Success: {result.success}\")\n",
        "                    print(f\"Runtime: {result.runtime:.2f} seconds\")\n",
        "                    print(f\"Total FLOPS: {result.flops_per_step[-1]}\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Error running {method}: {e}\")\n",
        "                    continue\n",
        "\n",
        "            # Generate visualizations\n",
        "            save_dir = os.path.join(base_dir, func_name, f\"{dim}D\")\n",
        "            os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "            # Only plot if we have valid results\n",
        "            if any(result is not None for result in results.values()):\n",
        "                Visualizer.plot_convergence(results, save_dir, func_name)\n",
        "                Visualizer.plot_computational_metrics(results, save_dir)\n",
        "                Visualizer.plot_optimization_summary(results, save_dir, func_name)\n",
        "\n",
        "                if dim == 2:\n",
        "                  trajectory_dir = os.path.join(save_dir, 'trajectories')\n",
        "                  os.makedirs(trajectory_dir, exist_ok=True)\n",
        "                  for method, result in results.items():\n",
        "                      if result is not None:\n",
        "                          Visualizer.plot_2d_trajectory(f, result, trajectory_dir)\n",
        "\n",
        "    # Save summary as CSV\n",
        "    pd.DataFrame(summary_data).to_csv(\n",
        "        os.path.join(base_dir, 'optimization_summary.csv'),\n",
        "        index=False\n",
        "    )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqoSGTWxadj1",
        "outputId": "1befa1fb-3bd7-4630-9904-76d110640dd9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing ackley function:\n",
            "\n",
            "Dimension: 2\n",
            "\n",
            "Running BFGS...\n",
            "Final value: 8.813152\n",
            "Success: True\n",
            "Runtime: 0.01 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Running newton-cg...\n",
            "Final value: 8.813152\n",
            "Success: True\n",
            "Runtime: 0.01 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Running trust-exact...\n",
            "Final value: 8.813152\n",
            "Success: True\n",
            "Runtime: 0.02 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Running trust-krylov...\n",
            "Final value: 8.813152\n",
            "Success: True\n",
            "Runtime: 0.02 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Dimension: 4\n",
            "\n",
            "Running BFGS...\n",
            "Final value: 7.458366\n",
            "Success: True\n",
            "Runtime: 0.01 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Running newton-cg...\n",
            "Final value: 7.458366\n",
            "Success: True\n",
            "Runtime: 0.03 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Running trust-exact...\n",
            "Final value: 7.458366\n",
            "Success: True\n",
            "Runtime: 0.05 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Running trust-krylov...\n",
            "Final value: 7.458366\n",
            "Success: True\n",
            "Runtime: 0.05 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Dimension: 8\n",
            "\n",
            "Running BFGS...\n",
            "Final value: 8.302047\n",
            "Success: True\n",
            "Runtime: 0.01 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Running newton-cg...\n",
            "Final value: 8.302047\n",
            "Success: True\n",
            "Runtime: 0.12 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Running trust-exact...\n",
            "Final value: 8.302047\n",
            "Success: True\n",
            "Runtime: 0.22 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Running trust-krylov...\n",
            "Final value: 8.302047\n",
            "Success: True\n",
            "Runtime: 0.23 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Dimension: 12\n",
            "\n",
            "Running BFGS...\n",
            "Final value: 8.582518\n",
            "Success: True\n",
            "Runtime: 0.01 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Running newton-cg...\n",
            "Final value: 8.582518\n",
            "Success: True\n",
            "Runtime: 0.09 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Running trust-exact...\n",
            "Final value: 8.582518\n",
            "Success: True\n",
            "Runtime: 0.66 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Running trust-krylov...\n",
            "Final value: 8.582518\n",
            "Success: True\n",
            "Runtime: 0.64 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Testing rastrigin function:\n",
            "\n",
            "Dimension: 2\n",
            "\n",
            "Running BFGS...\n",
            "Final value: 16.914203\n",
            "Success: True\n",
            "Runtime: 0.00 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Running newton-cg...\n",
            "Final value: 16.914203\n",
            "Success: True\n",
            "Runtime: 0.00 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Running trust-exact...\n",
            "Final value: 16.914203\n",
            "Success: True\n",
            "Runtime: 0.00 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Running trust-krylov...\n",
            "Final value: 16.914203\n",
            "Success: True\n",
            "Runtime: 0.00 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Dimension: 4\n",
            "\n",
            "Running BFGS...\n",
            "Final value: 21.888993\n",
            "Success: True\n",
            "Runtime: 0.01 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Running newton-cg...\n",
            "Final value: 21.888993\n",
            "Success: True\n",
            "Runtime: 0.00 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Running trust-exact...\n",
            "Final value: 21.888993\n",
            "Success: True\n",
            "Runtime: 0.00 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Running trust-krylov...\n",
            "Final value: 21.888993\n",
            "Success: True\n",
            "Runtime: 0.00 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Dimension: 8\n",
            "\n",
            "Running BFGS...\n",
            "Final value: 64.672041\n",
            "Success: True\n",
            "Runtime: 0.01 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Running newton-cg...\n",
            "Final value: 64.672041\n",
            "Success: True\n",
            "Runtime: 0.00 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Running trust-exact...\n",
            "Final value: 57.707398\n",
            "Success: True\n",
            "Runtime: 0.00 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Running trust-krylov...\n",
            "Final value: 64.672041\n",
            "Success: True\n",
            "Runtime: 0.00 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Dimension: 12\n",
            "\n",
            "Running BFGS...\n",
            "Final value: 101.485318\n",
            "Success: True\n",
            "Runtime: 0.01 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Running newton-cg...\n",
            "Final value: 101.485318\n",
            "Success: True\n",
            "Runtime: 0.00 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Running trust-exact...\n",
            "Final value: 101.485318\n",
            "Success: True\n",
            "Runtime: 0.01 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Running trust-krylov...\n",
            "Final value: 101.485318\n",
            "Success: True\n",
            "Runtime: 0.00 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Testing sphere function:\n",
            "\n",
            "Dimension: 2\n",
            "\n",
            "Running BFGS...\n",
            "Final value: 0.000000\n",
            "Success: True\n",
            "Runtime: 0.00 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Running newton-cg...\n",
            "Final value: 0.000000\n",
            "Success: True\n",
            "Runtime: 0.00 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Running trust-exact...\n",
            "Final value: 0.000000\n",
            "Success: True\n",
            "Runtime: 0.00 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Running trust-krylov...\n",
            "Final value: 0.000000\n",
            "Success: True\n",
            "Runtime: 0.00 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Dimension: 4\n",
            "\n",
            "Running BFGS...\n",
            "Final value: 0.000000\n",
            "Success: True\n",
            "Runtime: 0.00 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Running newton-cg...\n",
            "Final value: 0.000000\n",
            "Success: True\n",
            "Runtime: 0.00 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Running trust-exact...\n",
            "Final value: 0.000000\n",
            "Success: True\n",
            "Runtime: 0.00 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Running trust-krylov...\n",
            "Final value: 0.000000\n",
            "Success: True\n",
            "Runtime: 0.00 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Dimension: 8\n",
            "\n",
            "Running BFGS...\n",
            "Final value: 0.000000\n",
            "Success: True\n",
            "Runtime: 0.00 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Running newton-cg...\n",
            "Final value: 0.000000\n",
            "Success: True\n",
            "Runtime: 0.00 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Running trust-exact...\n",
            "Final value: 0.000000\n",
            "Success: True\n",
            "Runtime: 0.00 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Running trust-krylov...\n",
            "Final value: 0.000000\n",
            "Success: True\n",
            "Runtime: 0.00 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Dimension: 12\n",
            "\n",
            "Running BFGS...\n",
            "Final value: 0.000000\n",
            "Success: True\n",
            "Runtime: 0.00 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Running newton-cg...\n",
            "Final value: 0.000000\n",
            "Success: True\n",
            "Runtime: 0.00 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Running trust-exact...\n",
            "Final value: 0.000000\n",
            "Success: True\n",
            "Runtime: 0.00 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Running trust-krylov...\n",
            "Final value: 0.000000\n",
            "Success: True\n",
            "Runtime: 0.00 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Testing rosenbrock function:\n",
            "\n",
            "Dimension: 2\n",
            "\n",
            "Running BFGS...\n",
            "Final value: 0.000000\n",
            "Success: True\n",
            "Runtime: 0.01 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Running newton-cg...\n",
            "Final value: 0.131653\n",
            "Success: False\n",
            "Runtime: 0.11 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Running trust-exact...\n",
            "Final value: 0.161399\n",
            "Success: False\n",
            "Runtime: 0.17 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Running trust-krylov...\n",
            "Final value: 0.236670\n",
            "Success: False\n",
            "Runtime: 0.14 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Dimension: 4\n",
            "\n",
            "Running BFGS...\n",
            "Final value: 3.701429\n",
            "Success: True\n",
            "Runtime: 0.02 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Running newton-cg...\n",
            "Final value: 4.674306\n",
            "Success: False\n",
            "Runtime: 0.53 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Running trust-exact...\n",
            "Final value: 1.140418\n",
            "Success: False\n",
            "Runtime: 0.61 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Running trust-krylov...\n",
            "Final value: 4.446366\n",
            "Success: False\n",
            "Runtime: 0.63 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Dimension: 8\n",
            "\n",
            "Running BFGS...\n",
            "Final value: 0.000000\n",
            "Success: True\n",
            "Runtime: 0.03 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Running newton-cg...\n",
            "Final value: 4.069185\n",
            "Success: False\n",
            "Runtime: 3.11 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Running trust-exact...\n",
            "Final value: 1.604909\n",
            "Success: False\n",
            "Runtime: 3.53 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Running trust-krylov...\n",
            "Final value: 1.480690\n",
            "Success: False\n",
            "Runtime: 3.18 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Dimension: 12\n",
            "\n",
            "Running BFGS...\n",
            "Final value: 0.000000\n",
            "Success: True\n",
            "Runtime: 0.03 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Running newton-cg...\n",
            "Final value: 0.013729\n",
            "Success: True\n",
            "Runtime: 9.56 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Running trust-exact...\n",
            "Final value: 4.020405\n",
            "Success: False\n",
            "Runtime: 10.76 seconds\n",
            "Total FLOPS: 0\n",
            "\n",
            "Running trust-krylov...\n",
            "Final value: 4.167150\n",
            "Success: False\n",
            "Runtime: 9.67 seconds\n",
            "Total FLOPS: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from typing import List, Dict, Tuple\n",
        "import os\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "class ExperimentFramework:\n",
        "    \"\"\"Framework for running multiple optimization experiments\"\"\"\n",
        "    def __init__(self, dimensions: List[int], n_experiments: int = 50,\n",
        "                 min_dist: float = 100, max_dist: float = 1000):\n",
        "        self.dimensions = dimensions\n",
        "        self.n_experiments = n_experiments\n",
        "        self.min_dist = min_dist\n",
        "        self.max_dist = max_dist\n",
        "\n",
        "    def generate_starting_points(self, dimension: int, seed: int = 42) -> np.ndarray:\n",
        "        \"\"\"Generate random starting points with specified distance from origin\"\"\"\n",
        "        np.random.seed(seed)\n",
        "        starting_points = []\n",
        "\n",
        "        for _ in range(self.n_experiments):\n",
        "            # Generate random direction vector\n",
        "            direction = np.random.randn(dimension)\n",
        "            direction = direction / np.linalg.norm(direction)\n",
        "\n",
        "            # Generate random distance within specified range\n",
        "            distance = np.random.uniform(self.min_dist, self.max_dist)\n",
        "\n",
        "            # Create starting point\n",
        "            point = direction * distance\n",
        "            starting_points.append(point)\n",
        "\n",
        "        return np.array(starting_points)\n",
        "\n",
        "    def create_experiment_directory(self, base_dir: str) -> str:\n",
        "        \"\"\"Create directory structure for experiments\"\"\"\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        experiment_dir = os.path.join(base_dir, f\"experiment_{timestamp}\")\n",
        "\n",
        "        # Create main directories\n",
        "        for func_name in test_functions.keys():\n",
        "            for dim in self.dimensions:\n",
        "                # Directory for results\n",
        "                os.makedirs(os.path.join(experiment_dir, func_name, f\"{dim}D\", \"results\"), exist_ok=True)\n",
        "                # Directory for trajectories (2D only)\n",
        "                if dim == 2:\n",
        "                    os.makedirs(os.path.join(experiment_dir, func_name, f\"{dim}D\", \"trajectories\"), exist_ok=True)\n",
        "                # Directory for statistics\n",
        "                os.makedirs(os.path.join(experiment_dir, func_name, f\"{dim}D\", \"statistics\"), exist_ok=True)\n",
        "\n",
        "        return experiment_dir\n",
        "\n",
        "    def run_experiments(self, base_dir: str = \"optimization_experiments\"):\n",
        "        \"\"\"Run all experiments\"\"\"\n",
        "        experiment_dir = self.create_experiment_directory(base_dir)\n",
        "\n",
        "        # DataFrame to store all results\n",
        "        all_results = []\n",
        "\n",
        "        for func_name, (f, grad, hess) in test_functions.items():\n",
        "            print(f\"\\nRunning experiments for {func_name} function\")\n",
        "\n",
        "            for dim in self.dimensions:\n",
        "                print(f\"\\nDimension: {dim}\")\n",
        "\n",
        "                # Generate starting points for this dimension\n",
        "                starting_points = self.generate_starting_points(dim)\n",
        "\n",
        "                # Save starting points\n",
        "                pd.DataFrame(starting_points).to_csv(\n",
        "                    os.path.join(experiment_dir, func_name, f\"{dim}D\", \"starting_points.csv\"),\n",
        "                    index=False\n",
        "                )\n",
        "\n",
        "                for i, x0 in enumerate(starting_points):\n",
        "                    print(f\"Running experiment {i+1}/{self.n_experiments}\")\n",
        "\n",
        "                    experiment_results = {}\n",
        "                    for method in methods:\n",
        "                        result = run_optimization(f, grad, hess, x0, method, func_name)\n",
        "                        if result is not None:\n",
        "                            experiment_results[method] = result\n",
        "\n",
        "                            # Add to results DataFrame\n",
        "                            all_results.append({\n",
        "                                'function': func_name,\n",
        "                                'dimension': dim,\n",
        "                                'experiment': i,\n",
        "                                'method': method,\n",
        "                                'start_distance': np.linalg.norm(x0),\n",
        "                                'final_value': result.f_final,\n",
        "                                'iterations': result.iterations,\n",
        "                                'runtime': result.runtime,\n",
        "                                'success': result.success,\n",
        "                                'distance_to_minimum': result.distance_to_minimum,\n",
        "                                'f_error': result.f_error\n",
        "                            })\n",
        "\n",
        "                    # Save trajectories for 2D\n",
        "                    if dim == 2:\n",
        "                        for method, result in experiment_results.items():\n",
        "                            Visualizer.plot_2d_trajectory(\n",
        "                                f, result,\n",
        "                                os.path.join(experiment_dir, func_name, f\"{dim}D\", \"trajectories\"),\n",
        "                                experiment_num=i\n",
        "                            )\n",
        "\n",
        "                # Generate statistics and plots for this dimension\n",
        "                self.generate_statistics(\n",
        "                    pd.DataFrame(all_results),\n",
        "                    func_name,\n",
        "                    dim,\n",
        "                    os.path.join(experiment_dir, func_name, f\"{dim}D\", \"statistics\")\n",
        "                )\n",
        "\n",
        "        # Save all results\n",
        "        pd.DataFrame(all_results).to_csv(\n",
        "            os.path.join(experiment_dir, \"all_results.csv\"),\n",
        "            index=False\n",
        "        )\n",
        "\n",
        "        # Generate summary statistics\n",
        "        self.generate_summary_statistics(\n",
        "            pd.DataFrame(all_results),\n",
        "            experiment_dir\n",
        "        )\n",
        "\n",
        "    @staticmethod\n",
        "    def generate_statistics(results: pd.DataFrame, func_name: str, dimension: int, save_dir: str):\n",
        "        \"\"\"Generate statistical visualizations\"\"\"\n",
        "        plt.figure(figsize=(12, 6))\n",
        "\n",
        "        # Violin plot of final values\n",
        "        sns.violinplot(data=results[results['function'] == func_name],\n",
        "                      x='method', y='final_value')\n",
        "        plt.title(f'Distribution of Final Values\\n{func_name} {dimension}D')\n",
        "        plt.xticks(rotation=45)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(save_dir, 'final_values_distribution.png'))\n",
        "        plt.close()\n",
        "\n",
        "        # Violin plot of runtimes\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        sns.violinplot(data=results[results['function'] == func_name],\n",
        "                      x='method', y='runtime')\n",
        "        plt.title(f'Distribution of Runtimes\\n{func_name} {dimension}D')\n",
        "        plt.xticks(rotation=45)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(save_dir, 'runtime_distribution.png'))\n",
        "        plt.close()\n",
        "\n",
        "        # Success rate bar plot\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        success_rates = results[results['function'] == func_name].groupby('method')['success'].mean()\n",
        "        success_rates.plot(kind='bar')\n",
        "        plt.title(f'Success Rates\\n{func_name} {dimension}D')\n",
        "        plt.ylabel('Success Rate')\n",
        "        plt.xticks(rotation=45)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(save_dir, 'success_rates.png'))\n",
        "        plt.close()\n",
        "\n",
        "    @staticmethod\n",
        "    def generate_summary_statistics(results: pd.DataFrame, save_dir: str):\n",
        "        \"\"\"Generate overall summary statistics\"\"\"\n",
        "        # Summary by function and method\n",
        "        summary = results.groupby(['function', 'dimension', 'method']).agg({\n",
        "            'final_value': ['mean', 'std', 'min', 'max'],\n",
        "            'runtime': ['mean', 'std'],\n",
        "            'iterations': ['mean', 'std'],\n",
        "            'success': 'mean',\n",
        "            'distance_to_minimum': ['mean', 'std'],\n",
        "            'f_error': ['mean', 'std']\n",
        "        }).reset_index()\n",
        "\n",
        "        # Save summary\n",
        "        summary.to_csv(os.path.join(save_dir, \"experiment_summary.csv\"))\n",
        "\n",
        "# Usage:\n",
        "experiment = ExperimentFramework(dimensions=[2, 4, 8, 12], n_experiments=50)\n",
        "experiment.run_experiments()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "WNdnRF7fh0FN",
        "outputId": "e64e3402-6c5f-4735-8121-9b503ca54b74"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'test_functions' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-fe4ab34704d3>\u001b[0m in \u001b[0;36m<cell line: 181>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;31m# Usage:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0mexperiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExperimentFramework\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdimensions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_experiments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_experiments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-24-fe4ab34704d3>\u001b[0m in \u001b[0;36mrun_experiments\u001b[0;34m(self, base_dir)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_experiments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_dir\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"optimization_experiments\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;34m\"\"\"Run all experiments\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mexperiment_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_experiment_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;31m# DataFrame to store all results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-fe4ab34704d3>\u001b[0m in \u001b[0;36mcreate_experiment_directory\u001b[0;34m(self, base_dir)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m# Create main directories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mfunc_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdimensions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0;31m# Directory for results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'test_functions' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HGcBPbFubQFK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}